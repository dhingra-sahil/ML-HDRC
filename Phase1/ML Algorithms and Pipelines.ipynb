{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b19c7a-583f-4baa-9568-5e03a8ea61df",
   "metadata": {},
   "source": [
    "ML Algorithms and Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ad4f7-59d7-4faf-8d28-095e81e2becf",
   "metadata": {},
   "source": [
    "Some of the considerations are algorithms that involve binary classification as the clients will be classified into one of two groups. The groups consist of clients that can they repay their loans or not and thus a binary solution can be done. SVM, KNN, and Logistic Regression are in being considered with Logistic Regression as the baseline model. \n",
    "\n",
    "The  sklearn.linear_model.LogisticRegression implementation will be used for the baseline model with parameters penalty that can be any one the these l1’, ‘l2’, ‘elasticnet’, a mutli class of 'ovr' to fit each label using a binary problem, and C which is the inverse of regularization strength. Loss of LR will be calculated using with cross entropy loss. \n",
    "The log loss formula for the binary case is as follows : $-\\frac{1}{m}\\sum^m_{i=1}\\left(y_i\\cdot\\:\\log\\:\\left(p_i\\right)\\:+\\:\\left(1-y_i\\right)\\cdot\\log\\left(1-p_i\\right)\\right) $\n",
    "\n",
    "Another algorithm in consideration is sklearn.svm.SVC with hinge loss with a soft margin and hard margin which is determined by the paramter C, the regularization paramter. The value of 1 will indicate a soft margin while a value of 100 will indicate a hard margin. The kernal is another consideration has the options ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’.\n",
    "\n",
    "sklearn.neighbors.KnearestClassifier is the last alogrithm to be considered at this point with the most important parameters being number of nearest neighbors and weights. \n",
    "\n",
    "Some metrics that will be used are \n",
    "\n",
    "\n",
    "$\n",
    "Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}\n",
    "$\n",
    "\n",
    "$\n",
    "Precision = \\frac{TP}{TP+FP}\n",
    "$\n",
    "\n",
    "$\n",
    "Recall = \\frac{TP}{TP+FN}\n",
    "$\n",
    "\n",
    "$\n",
    "F1 = \\frac{2*Precision*Recall}{Precision+Recall} = \\frac{2*TP}{2*TP+FP+FN}\n",
    "$\n",
    "\n",
    "AUC is calculated as the Area Under the $Sensitivity$(TPR)-$(1-Specificity)$(FPR) Curve.\n",
    "\n",
    "Hinge Loss for SVM\n",
    "\n",
    "$\n",
    "max(0, 1 - y \\cdot \\hat{y})\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec349e8b-713a-48e0-a557-7a18ffee725d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
