{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0AG1yF50c0N"
   },
   "source": [
    "# Collinearity Reducer HCDR Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vW-DkS2mTZ69",
    "outputId": "da64d14e-3264-4722-d621-b9abd793a18e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDo68G3t0gxq"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4__MiCS81mGz"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-dlcHT1FvM7",
    "outputId": "6689fd15-395d-4baa-e094-77a1ea0f3bde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available?\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "\n",
    "# system\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import zipfile\n",
    "\n",
    "# data engineering\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# machine learning\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"cuda available?\\n{torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9J-pHtE0jva"
   },
   "source": [
    "### Custom Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AjaTemryA3e5"
   },
   "outputs": [],
   "source": [
    "# transformer reduces the list of columns by a subset\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "# transformer produces a reduced column list by collinearity reduction\n",
    "class CollinearityReducer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    '''\n",
    "    This class reduces features by measuring collinearity between the input variables and target.\n",
    "    Works on numerical features based on the correlations between each variable pair.\n",
    "    Of the var1iable pairs with absolute correlations above the threshold value...\n",
    "    ...the variables with the lowest target variable correlation are dropped from the input X.\n",
    "    The process is repeated until there are no more colinear pairs with absolute correlations above the threshold.\n",
    "    ...Or max_iter. \n",
    "    \n",
    "    The transformation returns a subset of feature names... \n",
    "    ...to be used with the DataFrameSelector() Class. \n",
    "\n",
    "    This class is meant to be run at the end of the numerical pipeline\n",
    "    PRIOR TO THE ACTUAL PIPELINE - only returns subset for DataFrameSelector().\n",
    "\n",
    "    NOTE! The function receives a dataframe structured with the target variable in first column.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, attribute_names, threshold=0.5, max_iter=None):\n",
    "        self.attribute_names = attribute_names\n",
    "        self.threshold = threshold\n",
    "        self.max_iter = max_iter\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None): \n",
    "\n",
    "        # TODO: address dataframe error when used with pytorch model       \n",
    "        dataframe = pd.concat([y, pd.DataFrame(X)], axis=1)\n",
    "        \n",
    "        i = 0\n",
    "        while i <= self.max_iter:\n",
    "\n",
    "            # read-in and assign columns\n",
    "            # gets correlation matrix between variables and pivots to a longer df\n",
    "            # identify target variable\n",
    "            # drop same-name and target correlations pairs\n",
    "              \n",
    "            df = dataframe\n",
    "            features = df.iloc[:,1:].columns\n",
    "            target_name = df.iloc[:,0].name\n",
    "\n",
    "            df = pd.melt(abs(df.corr()).reset_index(), id_vars='index', value_vars=features)\n",
    "            targets = df[df['index']==target_name]\n",
    "            df = df[(df['index'] != df['variable']) & (df['index'] != target_name) & (df['variable'] != target_name)]\n",
    "\n",
    "            # combine the correlated variables into ordered pairs\n",
    "            # aggregate the max correlation and sort pairs\n",
    "            # split out the variables from the pair\n",
    "            # join the target variable correlations for each variable pair, rename columns\n",
    "\n",
    "            df['joined'] = df[['index', 'variable']].apply(lambda row: '::'.join(np.sort(row.values.astype(str))), axis=1)\n",
    "\n",
    "            df = df.groupby('joined', as_index=False) \\\n",
    "                   .agg({'value':'max'}) \\\n",
    "                   .sort_values(by='value', ascending=False)\n",
    "\n",
    "            df[['var_1','var_2']] = df['joined'].str.split(\"::\",expand=True).astype(int)\n",
    "\n",
    "            df = df.merge(targets, how='left', left_on='var_1', right_on='variable') \\\n",
    "                   .merge(targets, how='left', left_on='var_2', right_on='variable')\n",
    "            df.rename(columns = {'value_x':'var_pair_corr', 'value_y':'var_1_target_corr', 'value':'var_2_target_corr'}, inplace = True)\n",
    "\n",
    "            # This section takes all variable pairs with a correlation greater than threshold\n",
    "            # tests to determine which variable has a higher correlation with the target.\n",
    "            # The higher of the two gets marked as a win\n",
    "            # While the other gets marked as a loss\n",
    "            # the wins and losses for each variable are then grouped and summed\n",
    "\n",
    "            exceeds = df[df['var_pair_corr']>self.threshold]\n",
    "\n",
    "            # break if none above threshold\n",
    "            if len(exceeds['var_pair_corr'])==0:\n",
    "                break\n",
    "\n",
    "            # \"correlation competition\"\n",
    "            exceeds['var_1_win'] = exceeds.apply(lambda row: 1 if row[\"var_1_target_corr\"] >= row[\"var_2_target_corr\"] else 0, axis=1)\n",
    "            exceeds['var_1_loss'] = exceeds.apply(lambda row: 1 if row[\"var_2_target_corr\"] >= row[\"var_1_target_corr\"] else 0, axis=1)\n",
    "            exceeds['var_2_win'] = exceeds.apply(lambda row: 1 if row[\"var_1_target_corr\"] < row[\"var_2_target_corr\"] else 0, axis=1)\n",
    "            exceeds['var_2_loss'] = exceeds.apply(lambda row: 1 if row[\"var_2_target_corr\"] < row[\"var_1_target_corr\"] else 0, axis=1)\n",
    "\n",
    "            # aggregate scores\n",
    "            var1 = exceeds[['var_1', 'var_1_win', 'var_1_loss']].groupby('var_1', as_index=False) \\\n",
    "                                                                .agg({'var_1_win':'sum', 'var_1_loss':'sum'})\n",
    "            var1.rename(columns = {'var_1':'var', 'var_1_win':'win', 'var_1_loss':'loss'}, inplace=True)\n",
    "\n",
    "            var2 = exceeds[['var_2', 'var_2_win', 'var_2_loss']].groupby('var_2', as_index=False) \\\n",
    "                                                                .agg({'var_2_win':'sum', 'var_2_loss':'sum'})\n",
    "            var2.rename(columns = {'var_2':'var', 'var_2_win':'win', 'var_2_loss':'loss'}, inplace=True)\n",
    "\n",
    "            corrcomps = pd.concat([var1,var2], axis=0).groupby('var', as_index=False) \\\n",
    "                                                      .agg({'win':'sum', 'loss':'sum'})\n",
    "\n",
    "            # drop variables which had 0 wins - IE collinear variables which were always least related to the target\n",
    "            dropvars = corrcomps[corrcomps['win']==0]['var']\n",
    "\n",
    "            dataframe = dataframe.drop(dropvars, axis=1)  \n",
    "\n",
    "            i += 1  \n",
    "        \n",
    "        X = [self.attribute_names[col] for col in dataframe.columns]\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvEZVk640s23"
   },
   "source": [
    "### Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "70zdSCUMA30F"
   },
   "outputs": [],
   "source": [
    "# function identifies missing data\n",
    "def missing_data(data):\n",
    "    total = data.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent']) \n",
    "\n",
    "\n",
    "# function to identify different feature types and summary EDA\n",
    "def id_num_cat_feature(df,text = True):\n",
    "    numerical = df.select_dtypes(include=np.number).columns\n",
    "    categorical = df.select_dtypes(include=['object', 'bool', 'category']).columns\n",
    "    feat_num = list(numerical)\n",
    "    feat_cat = list(categorical)\n",
    "    \n",
    "    id_cols = ['SK_ID_CURR','SK_ID_BUREAU']\n",
    "    \n",
    "    id_cols = [cols for cols in  list(df.columns.intersection(id_cols))] \n",
    "    features = list(set(df.columns) - set(id_cols))\n",
    "\n",
    "    if text == True:\n",
    "          # print eda\n",
    "        print('--------')\n",
    "        print(f\"# of ID's: {len(id_cols)}\")\n",
    "        print(f\" ID's:\")\n",
    "        print(id_cols)\n",
    "        print('')\n",
    "        print('--------')\n",
    "        print(f\"# All features: {len(features)}\")\n",
    "        print(f\"All features:\")\n",
    "        print(features)\n",
    "        print('')\n",
    "        print(f\"Missing data:\")\n",
    "        print(missing_data(df[features]))\n",
    "        print('')\n",
    "        print('--------')\n",
    "        print(f\"# of Numerical features: {len(feat_num)}\")\n",
    "        print(f\"Numerical features:\")\n",
    "        print(feat_num)\n",
    "        print('')\n",
    "        print(f\"Numerical Statistical Summary:\")\n",
    "        print('')\n",
    "        print(df[feat_num].describe())\n",
    "        print('')\n",
    "        print('--------')\n",
    "        print(f\"# of Categorical features: {len(feat_cat)}\")\n",
    "        print(f\"Categorical features:\")\n",
    "        print(feat_cat)\n",
    "        print('')\n",
    "        print(f\"Categorical Statistical Summary:\")\n",
    "        print('')\n",
    "        #print(df[feat_cat].describe(include='all'))\n",
    "        print('')\n",
    "        print(\"Categories:\")\n",
    "        print('')\n",
    "        print(df[feat_cat].apply(lambda col: col.unique()))\n",
    "        print('')\n",
    "        print('--------')\n",
    "        \n",
    "    return id_cols,feat_num,feat_cat,features\n",
    "\n",
    "\n",
    "# https://pythonsimplified.com/how-to-handle-large-datasets-in-python-with-pandas/\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**3\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**3\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Tu_kiwglMHQa"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Method to create, define and run a deep neural network model\n",
    "#\n",
    "def run_hcdr_model(\n",
    "    hidden_layer_neurons=[32, 16, 8],\n",
    "    opt=optim.SGD,\n",
    "    epochs=5,\n",
    "    learning_rate=1e-3\n",
    "):\n",
    "    \n",
    "    D_in = X_test.shape[1]  # Input layer neurons depend on the input dataset shape\n",
    "    D_out = 2  # Output layer neurons - depend on what you're trying to predict, here, 2 classes: 0 and 1\n",
    "    \n",
    "    str_neurons = [str(h) for h in hidden_layer_neurons]\n",
    "    arch_string = f\"{D_in}-{'-'.join(str_neurons)}-{D_out}\"\n",
    "    \n",
    "    layers = [\n",
    "        torch.nn.Linear(D_in, hidden_layer_neurons[0]),  # X.matmul(W1)\n",
    "        nn.ReLU(),  # ReLU( X.matmul(W1))\n",
    "    ]\n",
    "    \n",
    "    # Add hidden layers\n",
    "    for i in range(1, len(hidden_layer_neurons)):\n",
    "        prev, curr = hidden_layer_neurons[i - 1], hidden_layer_neurons[i]\n",
    "        layers.append(torch.nn.Linear(prev, curr))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "    \n",
    "    # Add final layer\n",
    "    layers.append(nn.Linear(hidden_layer_neurons[-1], D_out)) # Relu( X.matmul(W1)).matmul(W2))\n",
    "    \n",
    "    # Use the nn package to define our model and loss function.\n",
    "    # use the sequential API makes things simple\n",
    "    model = torch.nn.Sequential(*layers)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # use Cross Entropy and SGD optimizer.\n",
    "    loss_fn = nn.CrossEntropyLoss()  #for classficationÂ \n",
    "    optimizer = opt(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #summary(model, (4, 20))\n",
    "    print('-'*50)\n",
    "    print('Model:')\n",
    "    print(model)\n",
    "    print('-'*50)\n",
    "    \n",
    "    '''\n",
    "    Training Process:\n",
    "        Load a batch of data.\n",
    "        Zero the grad.\n",
    "        Predict the batch of the data through net i.e forward pass.\n",
    "        Calculate the loss value by predict value and true value.\n",
    "        Backprop i.e get the gradient with respect to parameters\n",
    "        Update optimizer i.e gradient update\n",
    "    '''\n",
    "\n",
    "    loss_history = []\n",
    "    acc_history = []\n",
    "    def train_epoch(epoch, model, loss_fn, opt, train_loader):\n",
    "        running_loss = 0.0\n",
    "        count = 0\n",
    "        y_prob = []\n",
    "        y_pred = []\n",
    "        epoch_target = []\n",
    "        # dataset API gives us pythonic batching \n",
    "        for batch_id, data in enumerate(train_loader):\n",
    "            # https://stackoverflow.com/questions/69742930/runtimeerror-nll-loss-forward-reduce-cuda-kernel-2d-index-not-implemented-for\n",
    "            inputs, target = data[0], data[1]\n",
    "            target = target.type(torch.LongTensor)   # casting to long\n",
    "            inputs, target = inputs.to(device), target.to(device)        \n",
    "            # 1:zero the grad, 2:forward pass, 3:calculate loss,  and 4:backprop!\n",
    "            opt.zero_grad()\n",
    "            preds = model(inputs.float()) #prediction over the input data\n",
    "\n",
    "            # compute loss and gradients\n",
    "            loss = loss_fn(preds, target)    #mean loss for this batch\n",
    "\n",
    "            loss.backward() #calculate nabla_w\n",
    "            loss_history.append(loss.item())\n",
    "            opt.step()  #update W\n",
    "            \n",
    "            # https://stackoverflow.com/questions/60182984/how-to-get-the-predict-probability\n",
    "            y_prob.extend(F.softmax(preds, dim=1)[:,1].tolist())\n",
    "            y_pred.extend(torch.argmax(preds, dim=1).tolist())\n",
    "            epoch_target.extend(target.tolist())\n",
    "            #from IPython.core.debugger import Pdb as pdb;    pdb().set_trace() #breakpoint; dont forget to quit\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            count += 1\n",
    "\n",
    "        loss = np.round(running_loss/count, 3)\n",
    "        \n",
    "        #accuracy\n",
    "        correct = (np.array(y_pred) == np.array(epoch_target))\n",
    "        accuracy = correct.sum() / correct.size\n",
    "        accuracy = np.round(accuracy, 3)\n",
    "        \n",
    "        # auc\n",
    "        roc_auc = roc_auc_score(np.array(epoch_target),np.array(y_prob))\n",
    "        roc_auc = np.round(roc_auc,3)\n",
    "                           \n",
    "        return loss, accuracy, roc_auc\n",
    "\n",
    "\n",
    "\n",
    "    #from IPython.core.debugger import Pdb as pdb;    pdb().set_trace() #breakpoint; dont forget to quit\n",
    "    def evaluate_model(epoch, model, loss_fn, opt, data_loader, tag = \"Test\"):\n",
    "        overall_loss = 0.0\n",
    "        count = 0\n",
    "        y_prob = []\n",
    "        y_pred = []\n",
    "        epoch_target = []\n",
    "        for i,data in enumerate(data_loader):\n",
    "            # https://stackoverflow.com/questions/69742930/runtimeerror-nll-loss-forward-reduce-cuda-kernel-2d-index-not-implemented-for\n",
    "            inputs, target = data[0], data[1]\n",
    "            target = target.type(torch.LongTensor)   # casting to long\n",
    "            inputs, target = inputs.to(device), target.to(device)                \n",
    "            preds = model(inputs.float())      \n",
    "\n",
    "            loss = loss_fn(preds, target)           # compute loss value\n",
    "\n",
    "            overall_loss += (loss.item())  # compute total loss to save to logs\n",
    "            \n",
    "            y_prob.extend(F.softmax(preds, dim=1)[:,1].tolist())\n",
    "            y_pred.extend(torch.argmax(preds, dim=1).tolist())\n",
    "            epoch_target.extend(target.tolist())\n",
    "            count += 1\n",
    "\n",
    "        # compute mean loss\n",
    "        loss = np.round(overall_loss/count, 3)\n",
    "        #accuracy\n",
    "        correct = (np.array(y_pred) == np.array(epoch_target))\n",
    "        accuracy = correct.sum() / correct.size\n",
    "        accuracy = np.round(accuracy, 3)\n",
    "\n",
    "        # auc\n",
    "        roc_auc = roc_auc_score(np.array(epoch_target),np.array(y_prob))\n",
    "        roc_auc = np.round(roc_auc,3)\n",
    "\n",
    "        return loss, accuracy, roc_auc\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):      \n",
    "        train_loss, train_accuracy, train_auc = train_epoch(epoch, model, loss_fn, optimizer, trainloader_hcdr)\n",
    "        valid_loss, valid_accuracy, valid_auc = evaluate_model(epoch, model, loss_fn, optimizer, validloader_hcdr, tag = \"Validation\")\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        print(f\"----Train Accuracy: {train_accuracy}\\t Validation Accuracy: {valid_accuracy}\")\n",
    "        print(f\"----Train AUC-ROC: {train_auc}\\t Validation AUC-ROC: {valid_auc}\")\n",
    "    print(\"-\"*50)\n",
    "    test_loss, test_accuracy, test_auc = evaluate_model(epoch, model, loss_fn, opt, testloader_hcdr, tag=\"Test\")\n",
    "    \n",
    "    return arch_string, train_accuracy, valid_accuracy, test_accuracy, train_auc, valid_auc, test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY-aqM5W04hl"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZ8dzHAt1pvM"
   },
   "source": [
    "### Read-In and Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWvkmBxpA32r",
    "outputId": "5b4ba3b1-0bee-48ab-bad0-e440612af9dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "application_train\n",
      "Memory usage of dataframe is 0.28 MB\n",
      "Memory usage after optimization is: 0.06 MB\n",
      "Decreased by 79.2%\n",
      "---\n",
      "prevapp_agg_data_tr\n",
      "Memory usage of dataframe is 1.73 MB\n",
      "Memory usage after optimization is: 0.46 MB\n",
      "Decreased by 73.2%\n",
      "---\n",
      "bureau_agg_data_trans_untrans\n",
      "Memory usage of dataframe is 0.72 MB\n",
      "Memory usage after optimization is: 0.21 MB\n",
      "Decreased by 70.6%\n",
      "---\n",
      "ccb_agg_data_tr\n",
      "Memory usage of dataframe is 0.11 MB\n",
      "Memory usage after optimization is: 0.04 MB\n",
      "Decreased by 66.6%\n",
      "---\n",
      "ip_agg_data_tr\n",
      "Memory usage of dataframe is 0.17 MB\n",
      "Memory usage after optimization is: 0.06 MB\n",
      "Decreased by 63.4%\n",
      "---\n",
      "pos_agg_data_tr\n",
      "Memory usage of dataframe is 0.34 MB\n",
      "Memory usage after optimization is: 0.09 MB\n",
      "Decreased by 73.3%\n"
     ]
    }
   ],
   "source": [
    "# read-in\n",
    "DATA_DIR =  \"/drive/MyDrive/ColabNotebooks/\"\n",
    "\n",
    "ds_names = (\n",
    "    # \"application_test\",   \n",
    "    \"application_train\", \"prevapp_agg_data_tr\", \"bureau_agg_data_trans_untrans\",  \n",
    "    \"ccb_agg_data_tr\", \"ip_agg_data_tr\", \"pos_agg_data_tr\"\n",
    ")  \n",
    "\n",
    "datasets_agg = {}\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    print('---')\n",
    "    print(ds_name)\n",
    "    datasets_agg[ds_name] = pd.read_csv(os.getcwd() + DATA_DIR + f'{ds_name}.csv')\n",
    "    datasets_agg[ds_name] = reduce_mem_usage(datasets_agg[ds_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kAs9q2XTUrqA"
   },
   "outputs": [],
   "source": [
    "# denormalize and clean text\n",
    "for ds_name in datasets_agg:\n",
    "    if ds_name == 'application_train':\n",
    "        agg_data = datasets_agg['application_train'].replace(to_replace='\\s+', value='_', regex=True) \\\n",
    "                                                    .replace(to_replace='\\-', value='_', regex=True) \\\n",
    "                                                    .replace(to_replace='\\/', value='_', regex=True) \\\n",
    "                                                    .replace(to_replace='\\(', value='', regex=True) \\\n",
    "                                                    .replace(to_replace='\\)', value='', regex=True) \\\n",
    "                                                    .replace(to_replace='\\:', value='', regex=True) \\\n",
    "                                                    .replace(to_replace='\\,', value='', regex=True)\n",
    "    else:\n",
    "        agg_data = agg_data.merge(datasets_agg[ds_name], on='SK_ID_CURR', how='left')\n",
    "\n",
    "\n",
    "agg_data = agg_data.loc[:,~agg_data.columns.str.startswith('Unnamed:')]\n",
    "agg_data = agg_data.loc[:,~agg_data.columns.str.startswith('SK_ID_PREV')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiZElhxhsMe_",
    "outputId": "8fc0b2e9-602a-488c-f7f0-f6df6e746436"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SK_ID_CURR', 'TARGET', 'NAME_CONTRACT_TYPE', 'CODE_GENDER',\n",
       "       'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL',\n",
       "       'AMT_CREDIT', 'AMT_ANNUITY',\n",
       "       ...\n",
       "       'PS_O_NAME_CONTRACT_STATUS_Signed_median',\n",
       "       'PS_O_NAME_CONTRACT_STATUS_Signed_mean',\n",
       "       'PS_O_NAME_CONTRACT_STATUS_Signed_var',\n",
       "       'PS_O_NAME_CONTRACT_STATUS_Completed_median',\n",
       "       'PS_O_NAME_CONTRACT_STATUS_Completed_mean',\n",
       "       'PS_O_NAME_CONTRACT_STATUS_Completed_var',\n",
       "       'PS_O_NAME_CONTRACT_STATUS_Approved_median',\n",
       "       'PS_O_NAME_CONTRACT_STATUS_Approved_mean',\n",
       "       'PS_O_NAME_CONTRACT_STATUS_Approved_var', 'PS_O_SK_ID_PREV_count_y'],\n",
       "      dtype='object', length=1463)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7gyiRiE1JQC"
   },
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0v9NqWR1SgS"
   },
   "source": [
    "### Setup and Collinearity Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-VtWvcq3773",
    "outputId": "215a4cf4-ea6f-4b61-9560-40ebf878ebc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train           shape: (118084, 1461)\n",
      "X validation      shape: (29521, 1461)\n",
      "X test            shape: (36902, 1461)\n"
     ]
    }
   ],
   "source": [
    "# deep learning model\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# create train, validation, and test sets\n",
    "y = agg_data['TARGET']\n",
    "X = agg_data.drop(['SK_ID_CURR', 'TARGET'], axis = 1) #drop some features with questionable value\n",
    "\n",
    "_, X, _, y = train_test_split(X, y, test_size=0.6, random_state=42, stratify=y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_valid.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "print(f\"X train           shape: {X_train.shape}\")\n",
    "print(f\"X validation      shape: {X_valid.shape}\")\n",
    "print(f\"X test            shape: {X_test.shape}\")\n",
    "\n",
    "# determine feature types\n",
    "id_col, feat_num, feat_cat, feature =  id_num_cat_feature(X, text = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELkXmeHZk0dg",
    "outputId": "42e6335c-8773-4deb-d488-4cd04415837a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collinearity Reduction completed in 3092.4290 seconds.\n",
      "Reduced numerical column count by 0.4809688581314879% through collinearity reduction.\n",
      "From 1445 columns to 695 columns.\n"
     ]
    }
   ],
   "source": [
    "### Collinear Feature Reduction\n",
    "\n",
    "# reduce numerical features by collinearity reduction\n",
    "\n",
    "cr = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    StandardScaler(),    \n",
    "    CollinearityReducer(attribute_names=feat_num, threshold = 0.5, max_iter=10)\n",
    ")\n",
    "\n",
    "tic = time.perf_counter()\n",
    "reduced_feat_num = cr.fit_transform(X_train[feat_num], y_train) \n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f\"Collinearity Reduction completed in {toc - tic:0.4f} seconds.\")\n",
    "print(f'Reduced numerical column count by {len(reduced_feat_num)/len(feat_num)}% through collinearity reduction.')\n",
    "print(f'From {len(feat_num)} columns to {len(reduced_feat_num)} columns.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAqUW765mIe-"
   },
   "source": [
    "### Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zU6rXxnMl94W",
    "outputId": "82d2bb1d-c298-450c-ca18-83e66db892ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118084, 835) (118084,) (36902, 835) (36902,)\n"
     ]
    }
   ],
   "source": [
    "### Main Pipeline\n",
    "\n",
    "# Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(reduced_feat_num)),\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "data_pipeline = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num_pipeline\", num_pipeline, feat_num),\n",
    "        (\"cat_pipeline\", cat_pipeline, feat_cat)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "X_train = data_pipeline.fit_transform(X_train)\n",
    "X_valid = data_pipeline.transform(X_valid) #Transform validation set with the same constants\n",
    "X_test = data_pipeline.transform(X_test) #Transform test set with the same constants\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_valid = y_valid.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# convert numpy arrays to tensors\n",
    "X_train_tensor = torch.from_numpy(X_train)\n",
    "X_valid_tensor = torch.from_numpy(X_valid)\n",
    "X_test_tensor = torch.from_numpy(X_test)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "y_valid_tensor = torch.from_numpy(y_valid)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "\n",
    "# create TensorDataset in PyTorch\n",
    "hcdr_train = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "hcdr_valid = torch.utils.data.TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "hcdr_test = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "# create dataloader\n",
    "# DataLoader is implemented in PyTorch, which will return an iterator to iterate training data by batch.\n",
    "train_batch_size = 96\n",
    "valid_test_batch_size = 64\n",
    "trainloader_hcdr = torch.utils.data.DataLoader(hcdr_train, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "validloader_hcdr = torch.utils.data.DataLoader(hcdr_valid, batch_size=valid_test_batch_size, shuffle=True, num_workers=2)\n",
    "testloader_hcdr = torch.utils.data.DataLoader(hcdr_test, batch_size=valid_test_batch_size, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "id": "YR76icicV_9P",
    "outputId": "c78fdb3f-ea84-4327-c140-b317c3fcee62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Model:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=835, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (9): ReLU()\n",
      "  (10): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (11): ReLU()\n",
      "  (12): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n",
      "--------------------------------------------------\n",
      "Epoch 1\n",
      "----Train Accuracy: 0.918\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.725\t Validation AUC-ROC: 0.758\n",
      "Epoch 2\n",
      "----Train Accuracy: 0.919\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.759\t Validation AUC-ROC: 0.762\n",
      "Epoch 3\n",
      "----Train Accuracy: 0.919\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.768\t Validation AUC-ROC: 0.755\n",
      "Epoch 4\n",
      "----Train Accuracy: 0.92\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.773\t Validation AUC-ROC: 0.766\n",
      "Epoch 5\n",
      "----Train Accuracy: 0.921\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.781\t Validation AUC-ROC: 0.765\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f29be714-74f9-444c-8911-a36603fc224f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Architecture string</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Valid accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Train auc</th>\n",
       "      <th>Valid auc</th>\n",
       "      <th>Test auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6_agg_trans+orig_835_CR:0.5-10</td>\n",
       "      <td>835-256-128-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adamax.Adamax'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004</td>\n",
       "      <td>92.10000000000001%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>78.10000000000001%</td>\n",
       "      <td>76.5%</td>\n",
       "      <td>76.6%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f29be714-74f9-444c-8911-a36603fc224f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f29be714-74f9-444c-8911-a36603fc224f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f29be714-74f9-444c-8911-a36603fc224f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                            Dataset       Architecture string  \\\n",
       "0  0.6_agg_trans+orig_835_CR:0.5-10  835-256-128-64-32-16-4-2   \n",
       "\n",
       "                             Optimizer Epochs Learning Rate  \\\n",
       "0  <class 'torch.optim.adamax.Adamax'>      5         0.004   \n",
       "\n",
       "       Train accuracy Valid accuracy Test accuracy           Train auc  \\\n",
       "0  92.10000000000001%          91.9%         91.9%  78.10000000000001%   \n",
       "\n",
       "  Valid auc Test auc  \n",
       "0     76.5%    76.6%  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#==================================================#\n",
    "#    Modify START   #\n",
    "#==================================================#\n",
    "'''\n",
    "(input_dataset) - description of input data: size_set_transformed_columns_CR\n",
    "(hidden_layers_neurons) - A list of the number of neurons in the hidden layers in order. DEFAULT: [32, 16, 8] => 1st hidden layer: 32 neurons, 2nd: 16, 3rd: 8\n",
    "(opt) - The optimizer function to use: SGD, Adam, etc.,  DEFAULT: optim.SGD\n",
    "(epochs) - The total number of epochs to train your model for,  DEFAULT: 5\n",
    "(learning_rate) - The learning rate to take the gradient descent step with\n",
    "'''\n",
    "input_dataset=\"0.6_agg_trans+orig_835_CR:0.5-10\"\n",
    "hidden_layer_neurons=[256, 128, 64, 32, 16, 4]\n",
    "opt=optim.Adamax\n",
    "epochs=5\n",
    "learning_rate=4e-3\n",
    "\n",
    "#==================================================#\n",
    "#    Modify END #\n",
    "#==================================================#\n",
    "\n",
    "arch_string, train_accuracy, valid_accuracy, test_accuracy, train_auc, valid_auc, test_auc = run_hcdr_model(\n",
    "    hidden_layer_neurons,\n",
    "    opt,\n",
    "    epochs,\n",
    "    learning_rate\n",
    ")\n",
    "    \n",
    "\n",
    "try: hcdrLog \n",
    "except : hcdrLog = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Dataset\",\n",
    "        \"Architecture string\", \n",
    "        \"Optimizer\", \n",
    "        \"Epochs\", \n",
    "        \"Learning Rate\",\n",
    "        \"Train accuracy\",\n",
    "        \"Valid accuracy\",\n",
    "        \"Test accuracy\",\n",
    "        \"Train auc\",\n",
    "        \"Valid auc\",\n",
    "        \"Test auc\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "hcdrLog.loc[len(hcdrLog)] = [\n",
    "    input_dataset,\n",
    "    arch_string, \n",
    "    f\"{opt}\", \n",
    "    f\"{epochs}\", \n",
    "    f\"{learning_rate}\",\n",
    "    f\"{train_accuracy * 100}%\",\n",
    "    f\"{valid_accuracy * 100}%\",\n",
    "    f\"{test_accuracy * 100}%\",\n",
    "    f\"{train_auc * 100}%\",\n",
    "    f\"{valid_auc * 100}%\",\n",
    "    f\"{test_auc * 100}%\",\n",
    "]\n",
    "\n",
    "hcdrLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BrkIsbVX_0zs"
   },
   "outputs": [],
   "source": [
    "# hcdrLog = pd.DataFrame(\n",
    "#     columns=[\n",
    "#         \"Dataset\",\n",
    "#         \"Architecture string\", \n",
    "#         \"Optimizer\", \n",
    "#         \"Epochs\", \n",
    "#         \"Learning Rate\",\n",
    "#         \"Train accuracy\",\n",
    "#         \"Valid accuracy\",\n",
    "#         \"Test accuracy\",\n",
    "#         \"Train auc\",\n",
    "#         \"Valid auc\",\n",
    "#         \"Test auc\"\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Past Experiment Logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YR76icicV_9P",
    "outputId": "b7bbba70-722e-4b1b-cbf7-c8fa8034345d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Model:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1585, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (9): ReLU()\n",
      "  (10): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n",
      "--------------------------------------------------\n",
      "Epoch 1\n",
      "----Train Accuracy: 0.919\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.722\t Validation AUC-ROC: 0.754\n",
      "Epoch 2\n",
      "----Train Accuracy: 0.919\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.765\t Validation AUC-ROC: 0.759\n",
      "Epoch 3\n",
      "----Train Accuracy: 0.92\t Validation Accuracy: 0.918\n",
      "----Train AUC-ROC: 0.777\t Validation AUC-ROC: 0.762\n",
      "Epoch 4\n",
      "----Train Accuracy: 0.92\t Validation Accuracy: 0.916\n",
      "----Train AUC-ROC: 0.787\t Validation AUC-ROC: 0.762\n",
      "Epoch 5\n",
      "----Train Accuracy: 0.922\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.798\t Validation AUC-ROC: 0.761\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-262e864a-3220-4f7b-a698-9523e2910111\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Architecture string</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Valid accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Train auc</th>\n",
       "      <th>Valid auc</th>\n",
       "      <th>Test auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-128-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adagrad.Adagrad'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>76.4%</td>\n",
       "      <td>76.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adagrad.Adagrad'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>80.10000000000001%</td>\n",
       "      <td>76.1%</td>\n",
       "      <td>76.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-256-128-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adagrad.Adagrad'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>80.10000000000001%</td>\n",
       "      <td>76.2%</td>\n",
       "      <td>76.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-256-128-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adagrad.Adagrad'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004</td>\n",
       "      <td>92.0%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>79.9%</td>\n",
       "      <td>76.3%</td>\n",
       "      <td>76.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-256-128-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adadelta.Adadelta'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>56.89999999999999%</td>\n",
       "      <td>59.3%</td>\n",
       "      <td>58.699999999999996%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-128-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adadelta.Adadelta'&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>74.3%</td>\n",
       "      <td>73.8%</td>\n",
       "      <td>73.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adadelta.Adadelta'&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>73.6%</td>\n",
       "      <td>72.5%</td>\n",
       "      <td>72.39999999999999%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adadelta.Adadelta'&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.006</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>73.9%</td>\n",
       "      <td>72.89999999999999%</td>\n",
       "      <td>72.89999999999999%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adamax.Adamax'&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.006</td>\n",
       "      <td>93.0%</td>\n",
       "      <td>91.3%</td>\n",
       "      <td>91.4%</td>\n",
       "      <td>84.7%</td>\n",
       "      <td>73.2%</td>\n",
       "      <td>74.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adamax.Adamax'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004</td>\n",
       "      <td>92.10000000000001%</td>\n",
       "      <td>91.8%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>79.60000000000001%</td>\n",
       "      <td>75.9%</td>\n",
       "      <td>76.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-128-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adamax.Adamax'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004</td>\n",
       "      <td>92.2%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>79.80000000000001%</td>\n",
       "      <td>76.1%</td>\n",
       "      <td>76.2%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-262e864a-3220-4f7b-a698-9523e2910111')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-262e864a-3220-4f7b-a698-9523e2910111 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-262e864a-3220-4f7b-a698-9523e2910111');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                         Dataset        Architecture string  \\\n",
       "0   0.6_agg_trans+orig_1585_noCR      1585-128-64-32-16-4-2   \n",
       "1   0.6_agg_trans+orig_1585_noCR          1585-64-32-16-4-2   \n",
       "2   0.6_agg_trans+orig_1585_noCR  1585-256-128-64-32-16-4-2   \n",
       "3   0.6_agg_trans+orig_1585_noCR  1585-256-128-64-32-16-4-2   \n",
       "4   0.6_agg_trans+orig_1585_noCR  1585-256-128-64-32-16-4-2   \n",
       "5   0.6_agg_trans+orig_1585_noCR      1585-128-64-32-16-4-2   \n",
       "6   0.6_agg_trans+orig_1585_noCR          1585-64-32-16-4-2   \n",
       "7   0.6_agg_trans+orig_1585_noCR          1585-64-32-16-4-2   \n",
       "8   0.6_agg_trans+orig_1585_noCR          1585-64-32-16-4-2   \n",
       "9   0.6_agg_trans+orig_1585_noCR          1585-64-32-16-4-2   \n",
       "10  0.6_agg_trans+orig_1585_noCR      1585-128-64-32-16-4-2   \n",
       "\n",
       "                                  Optimizer Epochs Learning Rate  \\\n",
       "0     <class 'torch.optim.adagrad.Adagrad'>      5         0.005   \n",
       "1     <class 'torch.optim.adagrad.Adagrad'>      5         0.005   \n",
       "2     <class 'torch.optim.adagrad.Adagrad'>      5         0.005   \n",
       "3     <class 'torch.optim.adagrad.Adagrad'>      5         0.004   \n",
       "4   <class 'torch.optim.adadelta.Adadelta'>      5         0.004   \n",
       "5   <class 'torch.optim.adadelta.Adadelta'>     10         0.005   \n",
       "6   <class 'torch.optim.adadelta.Adadelta'>     10         0.005   \n",
       "7   <class 'torch.optim.adadelta.Adadelta'>     10         0.006   \n",
       "8       <class 'torch.optim.adamax.Adamax'>     10         0.006   \n",
       "9       <class 'torch.optim.adamax.Adamax'>      5         0.004   \n",
       "10      <class 'torch.optim.adamax.Adamax'>      5         0.004   \n",
       "\n",
       "        Train accuracy Valid accuracy Test accuracy           Train auc  \\\n",
       "0                91.9%          91.9%         91.9%               79.0%   \n",
       "1                91.9%          91.9%         91.9%  80.10000000000001%   \n",
       "2                91.9%          91.9%         91.9%  80.10000000000001%   \n",
       "3                92.0%          91.9%         91.9%               79.9%   \n",
       "4                91.9%          91.9%         91.9%  56.89999999999999%   \n",
       "5                91.9%          91.9%         91.9%               74.3%   \n",
       "6                91.9%          91.9%         91.9%               73.6%   \n",
       "7                91.9%          91.9%         91.9%               73.9%   \n",
       "8                93.0%          91.3%         91.4%               84.7%   \n",
       "9   92.10000000000001%          91.8%         91.9%  79.60000000000001%   \n",
       "10               92.2%          91.9%         91.9%  79.80000000000001%   \n",
       "\n",
       "             Valid auc             Test auc  \n",
       "0                76.4%                76.6%  \n",
       "1                76.1%                76.2%  \n",
       "2                76.2%                76.7%  \n",
       "3                76.3%                76.7%  \n",
       "4                59.3%  58.699999999999996%  \n",
       "5                73.8%                73.4%  \n",
       "6                72.5%   72.39999999999999%  \n",
       "7   72.89999999999999%   72.89999999999999%  \n",
       "8                73.2%                74.4%  \n",
       "9                75.9%                76.5%  \n",
       "10               76.1%                76.2%  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#==================================================#\n",
    "#    Modify START   #\n",
    "#==================================================#\n",
    "'''\n",
    "(input_dataset) - description of input data: size_set_transformed_columns_CR\n",
    "(hidden_layers_neurons) - A list of the number of neurons in the hidden layers in order. DEFAULT: [32, 16, 8] => 1st hidden layer: 32 neurons, 2nd: 16, 3rd: 8\n",
    "(opt) - The optimizer function to use: SGD, Adam, etc.,  DEFAULT: optim.SGD\n",
    "(epochs) - The total number of epochs to train your model for,  DEFAULT: 5\n",
    "(learning_rate) - The learning rate to take the gradient descent step with\n",
    "'''\n",
    "input_dataset=\"0.6_agg_trans+orig_1585_noCR\"\n",
    "hidden_layer_neurons=[128, 64, 32, 16, 4]\n",
    "opt=optim.Adamax\n",
    "epochs=5\n",
    "learning_rate=4e-3\n",
    "\n",
    "#==================================================#\n",
    "#    Modify END #\n",
    "#==================================================#\n",
    "\n",
    "arch_string, train_accuracy, valid_accuracy, test_accuracy, train_auc, valid_auc, test_auc = run_hcdr_model(\n",
    "    hidden_layer_neurons,\n",
    "    opt,\n",
    "    epochs,\n",
    "    learning_rate\n",
    ")\n",
    "    \n",
    "\n",
    "try: hcdrLog \n",
    "except : hcdrLog = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Dataset\",\n",
    "        \"Architecture string\", \n",
    "        \"Optimizer\", \n",
    "        \"Epochs\", \n",
    "        \"Learning Rate\",\n",
    "        \"Train accuracy\",\n",
    "        \"Valid accuracy\",\n",
    "        \"Test accuracy\",\n",
    "        \"Train auc\",\n",
    "        \"Valid auc\",\n",
    "        \"Test auc\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "hcdrLog.loc[len(hcdrLog)] = [\n",
    "    input_dataset,\n",
    "    arch_string, \n",
    "    f\"{opt}\", \n",
    "    f\"{epochs}\", \n",
    "    f\"{learning_rate}\",\n",
    "    f\"{train_accuracy * 100}%\",\n",
    "    f\"{valid_accuracy * 100}%\",\n",
    "    f\"{test_accuracy * 100}%\",\n",
    "    f\"{train_auc * 100}%\",\n",
    "    f\"{valid_auc * 100}%\",\n",
    "    f\"{test_auc * 100}%\",\n",
    "]\n",
    "\n",
    "hcdrLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YR76icicV_9P",
    "outputId": "b33f4521-5151-41ea-d1f6-5a7746c2b400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Model:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1585, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n",
      "--------------------------------------------------\n",
      "Epoch 1\n",
      "----Train Accuracy: 0.514\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.506\t Validation AUC-ROC: 0.531\n",
      "Epoch 2\n",
      "----Train Accuracy: 0.919\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.56\t Validation AUC-ROC: 0.6\n",
      "Epoch 3\n",
      "----Train Accuracy: 0.919\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.641\t Validation AUC-ROC: 0.66\n",
      "Epoch 4\n",
      "----Train Accuracy: 0.919\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.684\t Validation AUC-ROC: 0.689\n",
      "Epoch 5\n",
      "----Train Accuracy: 0.919\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.703\t Validation AUC-ROC: 0.702\n",
      "Epoch 6\n",
      "----Train Accuracy: 0.919\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.715\t Validation AUC-ROC: 0.712\n",
      "Epoch 7\n",
      "----Train Accuracy: 0.919\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.723\t Validation AUC-ROC: 0.718\n",
      "Epoch 8\n",
      "----Train Accuracy: 0.919\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.729\t Validation AUC-ROC: 0.723\n",
      "Epoch 9\n",
      "----Train Accuracy: 0.919\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.734\t Validation AUC-ROC: 0.728\n",
      "Epoch 10\n",
      "----Train Accuracy: 0.919\t Validation Accuracy: 0.919\n",
      "----Train AUC-ROC: 0.739\t Validation AUC-ROC: 0.729\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-70eeea17-a864-4dc3-9922-0a88e976ac88\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Architecture string</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Train accuracy</th>\n",
       "      <th>Valid accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "      <th>Train auc</th>\n",
       "      <th>Valid auc</th>\n",
       "      <th>Test auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-128-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adagrad.Adagrad'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>79.0%</td>\n",
       "      <td>76.4%</td>\n",
       "      <td>76.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adagrad.Adagrad'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>80.10000000000001%</td>\n",
       "      <td>76.1%</td>\n",
       "      <td>76.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-256-128-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adagrad.Adagrad'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>80.10000000000001%</td>\n",
       "      <td>76.2%</td>\n",
       "      <td>76.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-256-128-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adagrad.Adagrad'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004</td>\n",
       "      <td>92.0%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>79.9%</td>\n",
       "      <td>76.3%</td>\n",
       "      <td>76.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-256-128-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adadelta.Adadelta'&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>56.89999999999999%</td>\n",
       "      <td>59.3%</td>\n",
       "      <td>58.699999999999996%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-128-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adadelta.Adadelta'&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>74.3%</td>\n",
       "      <td>73.8%</td>\n",
       "      <td>73.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adadelta.Adadelta'&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>73.6%</td>\n",
       "      <td>72.5%</td>\n",
       "      <td>72.39999999999999%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6_agg_trans+orig_1585_noCR</td>\n",
       "      <td>1585-64-32-16-4-2</td>\n",
       "      <td>&lt;class 'torch.optim.adadelta.Adadelta'&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.006</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>91.9%</td>\n",
       "      <td>73.9%</td>\n",
       "      <td>72.89999999999999%</td>\n",
       "      <td>72.89999999999999%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70eeea17-a864-4dc3-9922-0a88e976ac88')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-70eeea17-a864-4dc3-9922-0a88e976ac88 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-70eeea17-a864-4dc3-9922-0a88e976ac88');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                        Dataset        Architecture string  \\\n",
       "0  0.6_agg_trans+orig_1585_noCR      1585-128-64-32-16-4-2   \n",
       "1  0.6_agg_trans+orig_1585_noCR          1585-64-32-16-4-2   \n",
       "2  0.6_agg_trans+orig_1585_noCR  1585-256-128-64-32-16-4-2   \n",
       "3  0.6_agg_trans+orig_1585_noCR  1585-256-128-64-32-16-4-2   \n",
       "4  0.6_agg_trans+orig_1585_noCR  1585-256-128-64-32-16-4-2   \n",
       "5  0.6_agg_trans+orig_1585_noCR      1585-128-64-32-16-4-2   \n",
       "6  0.6_agg_trans+orig_1585_noCR          1585-64-32-16-4-2   \n",
       "7  0.6_agg_trans+orig_1585_noCR          1585-64-32-16-4-2   \n",
       "\n",
       "                                 Optimizer Epochs Learning Rate  \\\n",
       "0    <class 'torch.optim.adagrad.Adagrad'>      5         0.005   \n",
       "1    <class 'torch.optim.adagrad.Adagrad'>      5         0.005   \n",
       "2    <class 'torch.optim.adagrad.Adagrad'>      5         0.005   \n",
       "3    <class 'torch.optim.adagrad.Adagrad'>      5         0.004   \n",
       "4  <class 'torch.optim.adadelta.Adadelta'>      5         0.004   \n",
       "5  <class 'torch.optim.adadelta.Adadelta'>     10         0.005   \n",
       "6  <class 'torch.optim.adadelta.Adadelta'>     10         0.005   \n",
       "7  <class 'torch.optim.adadelta.Adadelta'>     10         0.006   \n",
       "\n",
       "  Train accuracy Valid accuracy Test accuracy           Train auc  \\\n",
       "0          91.9%          91.9%         91.9%               79.0%   \n",
       "1          91.9%          91.9%         91.9%  80.10000000000001%   \n",
       "2          91.9%          91.9%         91.9%  80.10000000000001%   \n",
       "3          92.0%          91.9%         91.9%               79.9%   \n",
       "4          91.9%          91.9%         91.9%  56.89999999999999%   \n",
       "5          91.9%          91.9%         91.9%               74.3%   \n",
       "6          91.9%          91.9%         91.9%               73.6%   \n",
       "7          91.9%          91.9%         91.9%               73.9%   \n",
       "\n",
       "            Valid auc             Test auc  \n",
       "0               76.4%                76.6%  \n",
       "1               76.1%                76.2%  \n",
       "2               76.2%                76.7%  \n",
       "3               76.3%                76.7%  \n",
       "4               59.3%  58.699999999999996%  \n",
       "5               73.8%                73.4%  \n",
       "6               72.5%   72.39999999999999%  \n",
       "7  72.89999999999999%   72.89999999999999%  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#==================================================#\n",
    "#    Modify START   #\n",
    "#==================================================#\n",
    "'''\n",
    "(input_dataset) - description of input data: size_set_transformed_columns_CR\n",
    "(hidden_layers_neurons) - A list of the number of neurons in the hidden layers in order. DEFAULT: [32, 16, 8] => 1st hidden layer: 32 neurons, 2nd: 16, 3rd: 8\n",
    "(opt) - The optimizer function to use: SGD, Adam, etc.,  DEFAULT: optim.SGD\n",
    "(epochs) - The total number of epochs to train your model for,  DEFAULT: 5\n",
    "(learning_rate) - The learning rate to take the gradient descent step with\n",
    "'''\n",
    "input_dataset=\"0.6_agg_trans+orig_1585_noCR\"\n",
    "hidden_layer_neurons=[64, 32, 16, 4]\n",
    "opt=optim.Adadelta\n",
    "epochs=10\n",
    "learning_rate=6e-3\n",
    "\n",
    "#==================================================#\n",
    "#    Modify END #\n",
    "#==================================================#\n",
    "\n",
    "arch_string, train_accuracy, valid_accuracy, test_accuracy, train_auc, valid_auc, test_auc = run_hcdr_model(\n",
    "    hidden_layer_neurons,\n",
    "    opt,\n",
    "    epochs,\n",
    "    learning_rate\n",
    ")\n",
    "    \n",
    "\n",
    "try: hcdrLog \n",
    "except : hcdrLog = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Dataset\",\n",
    "        \"Architecture string\", \n",
    "        \"Optimizer\", \n",
    "        \"Epochs\", \n",
    "        \"Learning Rate\",\n",
    "        \"Train accuracy\",\n",
    "        \"Valid accuracy\",\n",
    "        \"Test accuracy\",\n",
    "        \"Train auc\",\n",
    "        \"Valid auc\",\n",
    "        \"Test auc\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "hcdrLog.loc[len(hcdrLog)] = [\n",
    "    input_dataset,\n",
    "    arch_string, \n",
    "    f\"{opt}\", \n",
    "    f\"{epochs}\", \n",
    "    f\"{learning_rate}\",\n",
    "    f\"{train_accuracy * 100}%\",\n",
    "    f\"{valid_accuracy * 100}%\",\n",
    "    f\"{test_accuracy * 100}%\",\n",
    "    f\"{train_auc * 100}%\",\n",
    "    f\"{valid_auc * 100}%\",\n",
    "    f\"{test_auc * 100}%\",\n",
    "]\n",
    "\n",
    "hcdrLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvrG5rkx12sj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
