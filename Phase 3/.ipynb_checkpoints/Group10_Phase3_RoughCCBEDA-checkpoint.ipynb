{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<h2 style=\"text-align:center\">Phase 3: Exploratory Data Analysis</h2>**\n",
    "\n",
    "<h3 style=\"text-align:center\">Home Credit Default Risk</h3>\n",
    "\n",
    "**<h4 style=\"text-align:center\">Group 10</h4>**\n",
    "\n",
    "| | |\n",
    "|:-----:|:-----:|\n",
    "| Mark Green | Pragat Wagle |\n",
    "| [margree@iu.edu](mailto:margree@iu.edu) | [pwagle@iupui.edu](mailto:pwagle@iupui.edu) |\n",
    "| <img src=\"../images/picMark.png\" alt=\"drawing\" width=\"200\"/> | <img src=\"../images/picPragat.jpeg\" alt=\"drawing\" width=\"210\"/> |\n",
    "| <img src=\"../images/picSahil.jpg\" alt=\"drawing\" width=\"200\"/> | <img src=\"../images/picKunal.jpg\" alt=\"drawing\" width=\"230\"/> |\n",
    "| Sahil Dhingra | Kunal Singh |\n",
    "| [sahdhin@iu.edu](mailto:sahdhin@iu.edu) | [singhku@iu.edu](mailto:singhku@iu.edu) |\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "---\n",
    "\n",
    "**<h4 style=\"text-align:left\">Table of Contents</h4>**\n",
    "\n",
    "1. [Phase Leader Table](#phase)\n",
    "2. [Credit Assignment Plan](#credit)\n",
    "3. [Abstract](#abstract)\n",
    "4. [Introduction](#intro)\n",
    "5. [Data Description](#datadesc)\n",
    "6. [Exploratory Data Analysis](#EDA)\n",
    "7. [Visual EDA](#EDAV)\n",
    "8. [Baseline Machine Learning Pipelines](#pipelines)\n",
    "9. [Results and Discussion](#results)\n",
    "10. [Conclusion](#conclusion)\n",
    "11. [Bibliography](#bibliography)\n",
    "12. [Attachment 1 - Data Dictionary](#datadict)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase Leader Table <a name='phase'></a>\n",
    "\n",
    "| Phase | Leader | Phase Description | Completed |\n",
    "|-------|:------:|:------------------|-----------|\n",
    "| 1     | Mark   | **Project Proposal**: Project Plan, Data description, algorithms and metrics, baseline models, pipelines | *11/15/22* | \n",
    "| 2     | Kunal  | **Baseline Report**: EDA, baseline pipeline, feature engineering, video presentation | *11/29/22* | \n",
    "| 3     | Pragat | **Finetuning Model**: Hyperparameter tuning, feature selection, ensemble methods, video presentation | 12/06/22 | \n",
    "| 4     | Sahil  | **Final Report**: Implement neural network, advanced models and loss functions, video presentation | TBD |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Assignment Table <a name='credit'></a>\n",
    "\n",
    "| Phase | Person | Hours | Effort |\n",
    "|:-----:|:-----:|:------:|:-----:|\n",
    "| 3 |   Mark   | 24 | Mark's goal was (1) to transform (IE denormalize) and perform EDA on the `bureau` and `bureau_balance` datasets, (2) to explore multicollinearity between variables in the aggregated dataset, (3) to facilitate production of the document deliverable, and (4) to help develop the summary video. Mark achieved his goal to complete these tasks by 11/29/2022. Mark accomplished these goals by writing code to aggregate and explore the `bureau` and `bureau_bal` tables, combining work from multiple documents into a singular report document and editing/formatting to produce a final draft document in html, pdf, and ipynb formats, and engaging in zoom meetings to facilitate workflow and develop the video. Accomplishing these goals completes a significant piece of the data preparation and provides insights into the `bureau` data and the \"rolled-up\" denormalized data. Accomplishing these goals also ensures we have high-quality deliverables that are suitable for reading by audiences with varied ML backgrounds. |\n",
    "| 3 |   Sahil    | 42 | Sahil’s goal was to write reusable functions like aggregation, summarization, ETL-transformations for EDA and functions like Num plots, categorical plots, NULL count, Dendrograms, histograms, and unique feature plots for EDA visualization. These goals were required to facilitate creation of new features, pre-processing, remove data below a threshold value(0.7), aggregation of hundreds of attributes for POS (POS-CASH Balance) and PREVAPP (previous applications) tables, and then rolling them to the application train and test tables. Helper functions were used for both EDA and visual EDA. Another goal was to publish details which could be added w.r.t functions. Last goal was to have the results and provide the discussion considering the feature engineering and score recorded in the last phase and doing a comparative analysis. This is all to be done before 11/29/2022. Sahil accomplished these goals by running and understanding the starter notebook, research on helpful EDA, EDA visualization, and feature engineering techniques which could be used across tables. Accomplishing these goals will enable Sahil to have better understanding of data visually and statistically. Accomplishing these goals will also provide insight for the next phase of targeted feature engineering and hyper-parameter tuning. |\n",
    "| 3   |  Pragat     | 34 | Pragat’s goal was to create visualizations including correlation plots and numerical plots such as a histogram, barplot, and kernel density tables. Another goal was to roll up the credit card balance table by summarizing and aggregating that data and then merging into the train data. Lastly, to run, train the pipeline on the final aggregated table and test it on the final aggregated test table to measure accuracy of the model on the test set, and submit to Kaggle. This is all to be done before 11/29/2022. Pragat will accomplish this goal by looking at the existing code, reading python documentation, and by using the web to find existing implementations. This goal will help with EDA to eventually create a more improved model from phase 1 to improve test set accuracy on the dataset provided by kaggle. |\n",
    "| 3    | Kunal      | 20 | Kunals goal was to load , transform and perform EDA on “installments payments” table. He explored the collinearity between the variables in the dataset. He also worked for preparing the documentation for Team and Plan updates, Project Abstract and description. He also helped develop the summary video. |\n",
    "| | | |\n",
    "| 2 |   Mark   | 24 | Mark's goal was (1) to transform (IE denormalize) and perform EDA on the `bureau` and `bureau_balance` datasets, (2) to explore multicollinearity between variables in the aggregated dataset, (3) to facilitate production of the document deliverable, and (4) to help develop the summary video. Mark achieved his goal to complete these tasks by 11/29/2022. Mark accomplished these goals by writing code to aggregate and explore the `bureau` and `bureau_bal` tables, combining work from multiple documents into a singular report document and editing/formatting to produce a final draft document in html, pdf, and ipynb formats, and engaging in zoom meetings to facilitate workflow and develop the video. Accomplishing these goals completes a significant piece of the data preparation and provides insights into the `bureau` data and the \"rolled-up\" denormalized data. Accomplishing these goals also ensures we have high-quality deliverables that are suitable for reading by audiences with varied ML backgrounds. |\n",
    "| 2 |   Sahil    | 42 | Sahil’s goal was to write reusable functions like aggregation, summarization, ETL-transformations for EDA and functions like Num plots, categorical plots, NULL count, Dendrograms, histograms, and unique feature plots for EDA visualization. These goals were required to facilitate creation of new features, pre-processing, remove data below a threshold value(0.7), aggregation of hundreds of attributes for POS (POS-CASH Balance) and PREVAPP (previous applications) tables, and then rolling them to the application train and test tables. Helper functions were used for both EDA and visual EDA. Another goal was to publish details which could be added w.r.t functions. Last goal was to have the results and provide the discussion considering the feature engineering and score recorded in the last phase and doing a comparative analysis. This is all to be done before 11/29/2022. Sahil accomplished these goals by running and understanding the starter notebook, research on helpful EDA, EDA visualization, and feature engineering techniques which could be used across tables. Accomplishing these goals will enable Sahil to have better understanding of data visually and statistically. Accomplishing these goals will also provide insight for the next phase of targeted feature engineering and hyper-parameter tuning. |\n",
    "| 2    |  Pragat     | 34 | Pragat’s goal was to create visualizations including correlation plots and numerical plots such as a histogram, barplot, and kernel density tables. Another goal was to roll up the credit card balance table by summarizing and aggregating that data and then merging into the train data. Lastly, to run, train the pipeline on the final aggregated table and test it on the final aggregated test table to measure accuracy of the model on the test set, and submit to Kaggle. This is all to be done before 11/29/2022. Pragat will accomplish this goal by looking at the existing code, reading python documentation, and by using the web to find existing implementations. This goal will help with EDA to eventually create a more improved model from phase 1 to improve test set accuracy on the dataset provided by kaggle. |\n",
    "| 2    | Kunal      | 20 | Kunals goal was to load , transform and perform EDA on “installments payments” table. He explored the collinearity between the variables in the dataset. He also worked for preparing the documentation for Team and Plan updates, Project Abstract and description. He also helped develop the summary video. |\n",
    "| | | |\n",
    "|1  |   Mark   |   16     | Mark's goals were to accomplish exploration and write about the data description, combine project elements developed by team members into a singular document, organize phase leader table, edit document appearance and content, guide discussion, goals, and organize team and resources as Phase 1 Leader, and to collaborate with team members where needed by November 15, 2022. Mark accomplished these goals by stitching together elements into a jupyter notebook and formatting the markdown into a report style, setting up a project Github resource and downloading/democratizing datasource, exploring and describing the data structure, editing the jupyter notebook submittal, being an active leader on team discussions, consulting other team members on writing in the Project Execution Plan, ML Algorithms, and ML Pipelines sections. Accomplishing these goals is key to project delivery in Phase 1 because these tasks complete the logistical elements of report development. They also contribute to the group understanding of the data structure and context. This work also sets precedents and tools for delivering future reports.     |\n",
    "| 1 |   Sahil    |    14     |  Sahil’s goal for this phase was to do EDA, feature engineering, create pipelines, create Block Diagram, conclude results and publish results for the same in Kaggle by 15-NOV-2022. To achieve this, Sahil went through the initial notebook and worked from there to do EDA, feature selection and create pipeline with different attribute list using the knowledge from prior assignments. Accomplishing this goal will help us get us to baseline test score and AUC score which will give us a good idea on our predictions and what more we can do to make better predictions.   |\n",
    "| 1    |  Pragat     |   12     |   Pragat’s goal was to describes the algorithms to be used and work on the getting it done prior to the November 15th deadline. Pragat will accomplish this goal by looking at the implementations on sklearn and the prioritize the most important parameters for each algorithm by looking at existing implementations seen in the documentation. Also by looking at existing implementations he will determine the loss functions and metrics and analysis to be used to measure the accuracy and overall quality of the algorithm. This goal will help to prioritize the most important arguments to consider for hyper-parameter tuning, optimizing the model, and in measuring the overall quality of results.    |\n",
    "| 1    | Kunal      |   10     |  Kunal's was to develop the Abstract and Project Execution plan. He accomplished this by collaborating with team members on regular team calls. This is important for the project as it helps to outline a plan of expectations and summarizes work done this week.|\n",
    "\n",
    "<img src=\"../images/GanttChart.png\" alt=\"drawing\" width=\"1500\"/>\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract <a name='abstract'></a>\n",
    "\n",
    "The Home Credit Group needs a machine learning-based classification model to make accurate lending decisions for individuals by predicting loan default risk using a scope of data beyond just traditional credit history, including loan applicant data encompassing their demographics, social status, employment status, and previous credit history. The seven data tables comprising these information use custom EDA and ETL functions to numerically and visually explore characteristics such as input variable distributions and skewness, inter-variable and target-variable correlation, and multicollinearity. Insights from the data exploration inform the process and decisions necessary to responsibly and accurately denormalize these tables into an ML-model ready input variable. This input variable - now comprised of the entire 2.7 gigabyte dataset - is run through a baseline logistic regression model in `SKLearn` using 1277 input features. Results from modelling on test data indicate the *Wagle-Dhingra-Singh-Green* baseline model achieves AUC-ROC score of approximately 0.7709, with prediction accuracy of approximately 92%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction <a name='intro'></a>\n",
    "\n",
    "Loans have always been an important part of people’s lives. Each individual has different reasons for borrowing a loan. It could be to buy a dream car or a home, to set up a business, or to buy some products. A large part of the population finds it difficult to get their home loans approved due to insufficient or absent credit history. It is a major challenge for banks and other finance lending agencies to decide for which candidates to approve housing loans.\n",
    "\n",
    "The Home Credit organization's mission is to provide responsible lending solutions to people with little to no credit history. Home Credit wants to determine their customer's eligibility for their financial products by determining their risk of default - the risk they will miss payments. **Group 10** has been tasked to evaluate their data and develop a machine learning (\"ML\") classification tool to predict loan default risk which uses more features than just the traditional credit history. Once developed, the *Wagle-Dhingra-Singh-Green model* will eventaully be used as a tool to evaluate future loan candidates. \n",
    "\n",
    "This report discusses the integration of the full normalized dataset into a machine learning model. The Exploratory Data Analysis (*EDA*) performed throughout this process is also presented as a means to familiarize the data and to make informed decisions throughout the data engineering and model integration process. \n",
    "\n",
    "A note on the styling of this report. After Section 5, many sections will be broken up by inline code blocks as the aim of this report is to highlight the exploratory data analysis and the work we are performing. \n",
    "\n",
    "## Phase 2 - Tasks To be Tackled\n",
    "\n",
    "The focus of Phase 2 is Exploratory Data Analysis and integration of the full dataset into a baseline machine learning model. A generalized machine learning project pipeline is outlined in figure 3 below and each step is described in detail in the Phase 1 Project report. The steps relevant to this phase (2, 3, 4) are outlined in detail below. \n",
    "\n",
    "2. **Data Logging and ETL**\n",
    "   + The data is segregated in multiple csv files related to each other by primary and foreign keys. Extract-Transform-Load operations must be performed on the dataset to consolidate the datasources into single denormalized table for efficient analysis.\n",
    "3. **Exploratory Data Analysis**\n",
    "   + While integrating the data, we explore the data with the goal of answering questions like: \n",
    "      + How many features are present?\n",
    "      + How are they correlated to one another and the target? \n",
    "      + How is the data quality? Are there any problems such as high leverage points or multicollinearity?\n",
    "      + What are the data types, missing values, or non-numeric features? \n",
    "      + Are there any patterns between the predictor and response features?\n",
    "   + The denormalized data is explored to find features which have the most impact on predicting the default risk of a loan applicant. Additional feature characteristics such as correlation between features and skewness are also observed and noted at this stage. \n",
    "4. **Feature Engineering**\n",
    "   + Using unnecessary features to train a machine learning model reduces the overall model accuracy and increases the model complexity and bias. To counter these issues, Feature Selection is implemented to reduce the number of input variables for the model by using only features with a relevant effect on predicting the target variable. Some feature selection methods include finding correlation coefficients, forward selection, backward selections, P-value tests, regularization, gradient boosting, and principal components analysis.\n",
    "   + The features also need to be re-engineered for optimal learning. This is accomplished by restructuring the input data such that the gradient surface of the model's objective function is sufficiently convex and of a form sympathetic to gradient descent optimization. Such feature engineering tasks include transforming categorical features into a numerical space, transforming skewed features into a normalized space, or extracting relevant information \"hidden\" within text strings. \n",
    "\n",
    "<br></br>\n",
    "\n",
    "<img src=\"../images/Pipeline.png\" alt=\"drawing\" width=\"1000\"/>\n",
    "\n",
    "**Figure 3: Visualization of key project steps to successfully build a machine learning model application.**\n",
    "\n",
    "## Challenges\n",
    "\n",
    "Challenges encountered during this phase include the following: \n",
    "\n",
    "1. Developing a method to consistently and appropriately aggregate and summarize normalized data into a denormalized input variable. The challenge here was to do this in such a way as to not artificially dilute the data, to avoid choosing \"winners\" and \"losers\" based on arbitrary decisions, and to be systematic and reasoned throughout the process. \n",
    "2. Running the model was challenging given the full raw dataset is approximately 2.7 gb of data. The process of denormalizing this dataset results in a high-dimensional dataset which can be cumbersome for complex models to work on. Local machines were having difficulty running the pipeline on the unrefined denormalized dataset.\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Description <a name='datadesc'></a>\n",
    "\n",
    "Although the Data Description is also discussed in the Phase 1 Proposal Report, a review of the underlying data structure will aid understanding the process by which the data is denormalized and prepared for the ML pipeline. \n",
    "\n",
    "The data provided in the loan applications give insights into an applicant's current demographic and social status. Data from past credit accounts also give insight into an applicant's past financial behaviors. Notably, the primary key for each sample (loan application) is the Loan ID `SK_ID_CURR`. This relates the current loan application to associated loans from Home Credit's past account records, and to associated loans from other institution's that were reported to the Credit Bureaus. The data are stored in 7 different table schemas shown on Figure 2 below. The specific attributes in each table, along with their descriptions, are stored in an addendum table named `HomeCredit_columns_description.csv`. \n",
    "\n",
    "<br></br>\n",
    "\n",
    "<img src=\"../images/home_credit.png\" alt=\"drawing\" width=\"1000\"/>\n",
    "\n",
    "**Figure 2: Entity Relation Diagram for Home Credit Applicant Datatables**\n",
    "\n",
    "<br></br>\n",
    "\n",
    "Home Credit provides three main sources of data upon which to learn the ML model: applicant information, credit bureau information, and Home Credit's account records. The sections below describe the data from these various sources, and some of the key variables.\n",
    "\n",
    "<br></br>\n",
    "\n",
    "## Background on the dataset\n",
    "> Home Credit is a non-banking financial institution, founded in 1997 in the Czech Republic.\n",
    ">\n",
    "> The company operates in 14 countries (including United States, Russia, Kazahstan, Belarus, China, India) and focuses on lending primarily to people with little or no credit history which will either not obtain loans or became victims of untrustworthly lenders.\n",
    ">\n",
    "> Home Credit group has over 29 million customers, total assests of 21 billions Euro, over 160 millions loans, with the majority in Asia and and almost half of them in China (as of 19-05-2018).\n",
    ">\n",
    "> While Home Credit is currently using various statistical and machine learning methods to make these predictions, they're challenging Kagglers to help them unlock the full potential of their data. Doing so will ensure that clients capable of repayment are not rejected and that loans are given with a principal, maturity, and repayment calendar that will empower their clients to be successful.\n",
    ">\n",
    "> *-- From original Jupyter Notebook*\n",
    "\n",
    "## Data files overview\n",
    "> There are 7 different sources of data:\n",
    "\n",
    "> * __application_train/application_test:__ the main training and testing data with information about each loan application at Home Credit. Every loan has its own row and is identified by the feature SK_ID_CURR. The training application data comes with the TARGET indicating __0: the loan was repaid__ or __1: the loan was not repaid__. The target variable defines if the client had payment difficulties meaning he/she had late payment more than X days on at least one of the first Y installments of the loan. Such case is marked as 1 while other all other cases as 0.\n",
    "> * __bureau:__ data concerning client's previous credits from other financial institutions. Each previous credit has its own row in bureau, but one loan in the application data can have multiple previous credits.\n",
    "> * __bureau_balance:__ monthly data about the previous credits in bureau. Each row is one month of a previous credit, and a single previous credit can have multiple rows, one for each month of the credit length.\n",
    "> * __previous_application:__ previous applications for loans at Home Credit of clients who have loans in the application data. Each current loan in the application data can have multiple previous loans. Each previous application has one row and is identified by the feature SK_ID_PREV.\n",
    "> * __POS_CASH_BALANCE:__ monthly data about previous point of sale or cash loans clients have had with Home Credit. Each row is one month of a previous point of sale or cash loan, and a single previous loan can have many rows.\n",
    "> * __credit_card_balance:__ monthly data about previous credit cards clients have had with Home Credit. Each row is one month of a credit card balance, and a single credit card can have many rows.\n",
    "> * __installments_payment:__ payment history for previous loans at Home Credit. There is one row for every made payment and one row for every missed payment.\n",
    ">\n",
    "> *-- From original Jupyter Notebook*\n",
    "\n",
    "## Loan Application Information\n",
    "\n",
    "This is a denormalized pair of tables `application_test|train.csv` with attribute information about the current loan. These attributes describe both the financial instrument itself (the contract type, rate, size of loan, annuity, etc.) and also the demographic information for the applicant (age, gender, income, education, etc.). In addition to these basic demographic data on the applicant, a suite of other very detailed information about the applicant are provided including details on the building/property in which they live, differences in work and home addresses, car ownership, if the applicant's friends recently defaulted on any loans, which documents were turned in, and many more. This table also contains the target variable `TARGET`. This is a binary variable indicating whether or not the client had payment difficulties on the loan.\n",
    "\n",
    "These data are explored and a baseline model is created in the supplementary Baseline Jupyter Notebook in [Section 10](#ipynb). \n",
    "\n",
    "## Credit Bureau Information\n",
    "\n",
    "Some applicants have had loans through other financial institutions which were reported to the Credit Bureaus. Data from these loan applications are available from `bureau.csv` and are related to the current loan application IDs. A monthly time series describing the payment status through loan term is available for each of these related outside institution loans in `bureau_balance.csv`, related to `bureau.csv` by `SK_ID_BUREAU`. The `STATUS` attribute in this table categorically indicates whether a loan has past-due payments on a given statement. These data can be used to evaluate an applicant's past payment behaviors.\n",
    "\n",
    "## Home Credit Previous Records\n",
    "\n",
    "Some applicants have had loans or other financial products through Home Credit in the past. These related financial product applications are made available under `previous_application.csv`. The `SK_ID_PREV` relates these applications to payment and balance information depending on the type of financial product (credit card balances `credit_card_balance.csv`, installment payments `installments_payments.csv`, and loan balances `POS_CASH_balance.csv`). These data can be used to evaluate an applicant's past payment behaviors.\n",
    "\n",
    "The credit card balances table shows detailed statement accounts of an applicants credit card withdrawals, credit limit, and days past due. Similarly, the installment payments and loan balances tables detail the amount prescribed and paid for various loan installments as well as the days past due for any late payments. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis Environment Setup\n",
    "\n",
    "This section is composed of code that sets up the data for exploration, denormaliation, and integration with an ML pipeline. It assumes the `*.csv` files from the Kaggle dataset are stored in a folder at the following directory relative to the path of this notebook:\n",
    "\n",
    "```bash\n",
    "DATA_DIR = \"../Data/\"  \n",
    "```\n",
    "\n",
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pandas.plotting import scatter_matrix\n",
    "import missingno as msno\n",
    "#!pip install msno\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pragatwagle/Desktop/aml hw's/AML556FinalProjectFall2022/Phase 3\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "\n",
    "Creating dictionary for datasets so that we can keep track of datsets and also make them callable to functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "DATA_DIR =  \"/../Data/\"\n",
    "\n",
    "ds_names = (\"application_train\", \"application_test\", \"bureau\",\"bureau_balance\",\n",
    "            \"credit_card_balance\", \"installments_payments\",\"previous_application\",\n",
    "            \"POS_CASH_balance\")\n",
    "\n",
    "datasets = {}\n",
    "datasets_transformed = {}\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    datasets[ds_name] = pd.read_csv(os.getcwd() + DATA_DIR + f'{ds_name}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary, Size, and Overview\n",
    "\n",
    "As part of the data download comes a *Data Dictionary* named `HomeCredit_columns_description.csv` and it is summarized in [Section 11](#datadict) as an attachment to this report. The subsections below give brief table descriptions, variable name overviews, and head views for the attributes in the normalized data tables. Additionally included are information on the size (memory usage) of each table. All together summed the dataset is approximately 2.7 gigabytes large. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application train\n",
    "\n",
    "* __application_train/application_test:__ the main training and testing data with information about each loan application at Home Credit. Every loan has its own row and is identified by the feature SK_ID_CURR. The training application data comes with the TARGET indicating __0: the loan was repaid__ or __1: the loan was not repaid__. The target variable defines if the client had payment difficulties meaning he/she had late payment more than X days on at least one of the first Y installments of the loan. Such case is marked as 1 while other all other cases as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_train: shape is (307511, 122)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 122 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float64(65), int64(41), object(16)\n",
      "memory usage: 286.2+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_data(df,name):\n",
    "    #df = pd.read_csv(in_path)\n",
    "    print(f\"{name}: shape is {df.shape}\")\n",
    "    print(df.info())\n",
    "    display(df.head(5))\n",
    "    return df\n",
    "\n",
    "ds_name = 'application_train'\n",
    "datasets[ds_name]= load_data(datasets[ds_name],ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_test: shape is (48744, 121)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48744 entries, 0 to 48743\n",
      "Columns: 121 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float64(65), int64(40), object(16)\n",
      "memory usage: 45.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "0      100001         Cash loans           F            N               Y   \n",
       "1      100005         Cash loans           M            N               Y   \n",
       "2      100013         Cash loans           M            Y               Y   \n",
       "3      100028         Cash loans           F            N               Y   \n",
       "4      100038         Cash loans           M            Y               N   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          135000.0    568800.0      20560.5         450000.0   \n",
       "1             0           99000.0    222768.0      17370.0         180000.0   \n",
       "2             0          202500.0    663264.0      69777.0         630000.0   \n",
       "3             2          315000.0   1575000.0      49018.5        1575000.0   \n",
       "4             1          180000.0    625500.0      32067.0         625500.0   \n",
       "\n",
       "   ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                0                0                0                0   \n",
       "1  ...                0                0                0                0   \n",
       "2  ...                0                0                0                0   \n",
       "3  ...                0                0                0                0   \n",
       "4  ...                0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         0.0  \n",
       "1                        0.0                         3.0  \n",
       "2                        1.0                         4.0  \n",
       "3                        0.0                         3.0  \n",
       "4                        NaN                         NaN  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_name = 'application_test'\n",
    "datasets[ds_name]= load_data(datasets[ds_name],ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The application dataset has the most information about the client: Gender, Income, Family Status, Education, and others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Other Datasets\n",
    "\n",
    "* __bureau:__ data concerning client's previous credits from other financial institutions. Each previous credit has its own row in bureau but one loan in the application data can have multiple previous credits.\n",
    "* __bureau_balance:__ monthly data about previous credits in bureau. Each row is one month of a previous credit and a single previous credit can have multiple rows, one for each month of the credit length.\n",
    "* __previous_application:__ previous applications for loans at Home Credit of clients who have loans in the application train data. Each current loan in the application train data can have multiple previous loans. Each previous application has one row and is identified by the feature SK_ID_PREV.\n",
    "* __POS_CASH_BALANCE:__ monthly data about previous point of sale or cash loans clients have had with Home Credit. Each row is one month of a previous point of sale or cash loan and a single previous loan can have many rows.\n",
    "* __Credit_card_balance:__ monthly data about previous credit cards clients have had with Home Credit. Each row is one month of a credit card balance and a single credit card can have many rows.\n",
    "* __installments_payment:__ payment history for previous loans at Home Credit. There is one row for every made payment and one row for every missed payment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_train: shape is (307511, 122)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 122 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float64(65), int64(41), object(16)\n",
      "memory usage: 286.2+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_test: shape is (48744, 121)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48744 entries, 0 to 48743\n",
      "Columns: 121 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float64(65), int64(40), object(16)\n",
      "memory usage: 45.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "0      100001         Cash loans           F            N               Y   \n",
       "1      100005         Cash loans           M            N               Y   \n",
       "2      100013         Cash loans           M            Y               Y   \n",
       "3      100028         Cash loans           F            N               Y   \n",
       "4      100038         Cash loans           M            Y               N   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          135000.0    568800.0      20560.5         450000.0   \n",
       "1             0           99000.0    222768.0      17370.0         180000.0   \n",
       "2             0          202500.0    663264.0      69777.0         630000.0   \n",
       "3             2          315000.0   1575000.0      49018.5        1575000.0   \n",
       "4             1          180000.0    625500.0      32067.0         625500.0   \n",
       "\n",
       "   ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                0                0                0                0   \n",
       "1  ...                0                0                0                0   \n",
       "2  ...                0                0                0                0   \n",
       "3  ...                0                0                0                0   \n",
       "4  ...                0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         0.0  \n",
       "1                        0.0                         3.0  \n",
       "2                        1.0                         4.0  \n",
       "3                        0.0                         3.0  \n",
       "4                        NaN                         NaN  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bureau: shape is (1716428, 17)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1716428 entries, 0 to 1716427\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   SK_ID_CURR              int64  \n",
      " 1   SK_ID_BUREAU            int64  \n",
      " 2   CREDIT_ACTIVE           object \n",
      " 3   CREDIT_CURRENCY         object \n",
      " 4   DAYS_CREDIT             int64  \n",
      " 5   CREDIT_DAY_OVERDUE      int64  \n",
      " 6   DAYS_CREDIT_ENDDATE     float64\n",
      " 7   DAYS_ENDDATE_FACT       float64\n",
      " 8   AMT_CREDIT_MAX_OVERDUE  float64\n",
      " 9   CNT_CREDIT_PROLONG      int64  \n",
      " 10  AMT_CREDIT_SUM          float64\n",
      " 11  AMT_CREDIT_SUM_DEBT     float64\n",
      " 12  AMT_CREDIT_SUM_LIMIT    float64\n",
      " 13  AMT_CREDIT_SUM_OVERDUE  float64\n",
      " 14  CREDIT_TYPE             object \n",
      " 15  DAYS_CREDIT_UPDATE      int64  \n",
      " 16  AMT_ANNUITY             float64\n",
      "dtypes: float64(8), int64(6), object(3)\n",
      "memory usage: 222.6+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>SK_ID_BUREAU</th>\n",
       "      <th>CREDIT_ACTIVE</th>\n",
       "      <th>CREDIT_CURRENCY</th>\n",
       "      <th>DAYS_CREDIT</th>\n",
       "      <th>CREDIT_DAY_OVERDUE</th>\n",
       "      <th>DAYS_CREDIT_ENDDATE</th>\n",
       "      <th>DAYS_ENDDATE_FACT</th>\n",
       "      <th>AMT_CREDIT_MAX_OVERDUE</th>\n",
       "      <th>CNT_CREDIT_PROLONG</th>\n",
       "      <th>AMT_CREDIT_SUM</th>\n",
       "      <th>AMT_CREDIT_SUM_DEBT</th>\n",
       "      <th>AMT_CREDIT_SUM_LIMIT</th>\n",
       "      <th>AMT_CREDIT_SUM_OVERDUE</th>\n",
       "      <th>CREDIT_TYPE</th>\n",
       "      <th>DAYS_CREDIT_UPDATE</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215354</td>\n",
       "      <td>5714462</td>\n",
       "      <td>Closed</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>-497</td>\n",
       "      <td>0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>91323.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Consumer credit</td>\n",
       "      <td>-131</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215354</td>\n",
       "      <td>5714463</td>\n",
       "      <td>Active</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>-208</td>\n",
       "      <td>0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>171342.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215354</td>\n",
       "      <td>5714464</td>\n",
       "      <td>Active</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>-203</td>\n",
       "      <td>0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>464323.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Consumer credit</td>\n",
       "      <td>-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215354</td>\n",
       "      <td>5714465</td>\n",
       "      <td>Active</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>-203</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>215354</td>\n",
       "      <td>5714466</td>\n",
       "      <td>Active</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>-629</td>\n",
       "      <td>0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77674.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2700000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Consumer credit</td>\n",
       "      <td>-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  SK_ID_BUREAU CREDIT_ACTIVE CREDIT_CURRENCY  DAYS_CREDIT  \\\n",
       "0      215354       5714462        Closed      currency 1         -497   \n",
       "1      215354       5714463        Active      currency 1         -208   \n",
       "2      215354       5714464        Active      currency 1         -203   \n",
       "3      215354       5714465        Active      currency 1         -203   \n",
       "4      215354       5714466        Active      currency 1         -629   \n",
       "\n",
       "   CREDIT_DAY_OVERDUE  DAYS_CREDIT_ENDDATE  DAYS_ENDDATE_FACT  \\\n",
       "0                   0               -153.0             -153.0   \n",
       "1                   0               1075.0                NaN   \n",
       "2                   0                528.0                NaN   \n",
       "3                   0                  NaN                NaN   \n",
       "4                   0               1197.0                NaN   \n",
       "\n",
       "   AMT_CREDIT_MAX_OVERDUE  CNT_CREDIT_PROLONG  AMT_CREDIT_SUM  \\\n",
       "0                     NaN                   0         91323.0   \n",
       "1                     NaN                   0        225000.0   \n",
       "2                     NaN                   0        464323.5   \n",
       "3                     NaN                   0         90000.0   \n",
       "4                 77674.5                   0       2700000.0   \n",
       "\n",
       "   AMT_CREDIT_SUM_DEBT  AMT_CREDIT_SUM_LIMIT  AMT_CREDIT_SUM_OVERDUE  \\\n",
       "0                  0.0                   NaN                     0.0   \n",
       "1             171342.0                   NaN                     0.0   \n",
       "2                  NaN                   NaN                     0.0   \n",
       "3                  NaN                   NaN                     0.0   \n",
       "4                  NaN                   NaN                     0.0   \n",
       "\n",
       "       CREDIT_TYPE  DAYS_CREDIT_UPDATE  AMT_ANNUITY  \n",
       "0  Consumer credit                -131          NaN  \n",
       "1      Credit card                 -20          NaN  \n",
       "2  Consumer credit                 -16          NaN  \n",
       "3      Credit card                 -16          NaN  \n",
       "4  Consumer credit                 -21          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credit_card_balance: shape is (3840312, 23)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3840312 entries, 0 to 3840311\n",
      "Data columns (total 23 columns):\n",
      " #   Column                      Dtype  \n",
      "---  ------                      -----  \n",
      " 0   SK_ID_PREV                  int64  \n",
      " 1   SK_ID_CURR                  int64  \n",
      " 2   MONTHS_BALANCE              int64  \n",
      " 3   AMT_BALANCE                 float64\n",
      " 4   AMT_CREDIT_LIMIT_ACTUAL     int64  \n",
      " 5   AMT_DRAWINGS_ATM_CURRENT    float64\n",
      " 6   AMT_DRAWINGS_CURRENT        float64\n",
      " 7   AMT_DRAWINGS_OTHER_CURRENT  float64\n",
      " 8   AMT_DRAWINGS_POS_CURRENT    float64\n",
      " 9   AMT_INST_MIN_REGULARITY     float64\n",
      " 10  AMT_PAYMENT_CURRENT         float64\n",
      " 11  AMT_PAYMENT_TOTAL_CURRENT   float64\n",
      " 12  AMT_RECEIVABLE_PRINCIPAL    float64\n",
      " 13  AMT_RECIVABLE               float64\n",
      " 14  AMT_TOTAL_RECEIVABLE        float64\n",
      " 15  CNT_DRAWINGS_ATM_CURRENT    float64\n",
      " 16  CNT_DRAWINGS_CURRENT        int64  \n",
      " 17  CNT_DRAWINGS_OTHER_CURRENT  float64\n",
      " 18  CNT_DRAWINGS_POS_CURRENT    float64\n",
      " 19  CNT_INSTALMENT_MATURE_CUM   float64\n",
      " 20  NAME_CONTRACT_STATUS        object \n",
      " 21  SK_DPD                      int64  \n",
      " 22  SK_DPD_DEF                  int64  \n",
      "dtypes: float64(15), int64(7), object(1)\n",
      "memory usage: 673.9+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>AMT_BALANCE</th>\n",
       "      <th>AMT_CREDIT_LIMIT_ACTUAL</th>\n",
       "      <th>AMT_DRAWINGS_ATM_CURRENT</th>\n",
       "      <th>AMT_DRAWINGS_CURRENT</th>\n",
       "      <th>AMT_DRAWINGS_OTHER_CURRENT</th>\n",
       "      <th>AMT_DRAWINGS_POS_CURRENT</th>\n",
       "      <th>AMT_INST_MIN_REGULARITY</th>\n",
       "      <th>...</th>\n",
       "      <th>AMT_RECIVABLE</th>\n",
       "      <th>AMT_TOTAL_RECEIVABLE</th>\n",
       "      <th>CNT_DRAWINGS_ATM_CURRENT</th>\n",
       "      <th>CNT_DRAWINGS_CURRENT</th>\n",
       "      <th>CNT_DRAWINGS_OTHER_CURRENT</th>\n",
       "      <th>CNT_DRAWINGS_POS_CURRENT</th>\n",
       "      <th>CNT_INSTALMENT_MATURE_CUM</th>\n",
       "      <th>NAME_CONTRACT_STATUS</th>\n",
       "      <th>SK_DPD</th>\n",
       "      <th>SK_DPD_DEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2562384</td>\n",
       "      <td>378907</td>\n",
       "      <td>-6</td>\n",
       "      <td>56.970</td>\n",
       "      <td>135000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>877.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>877.5</td>\n",
       "      <td>1700.325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2582071</td>\n",
       "      <td>363914</td>\n",
       "      <td>-1</td>\n",
       "      <td>63975.555</td>\n",
       "      <td>45000</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.000</td>\n",
       "      <td>...</td>\n",
       "      <td>64875.555</td>\n",
       "      <td>64875.555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1740877</td>\n",
       "      <td>371185</td>\n",
       "      <td>-7</td>\n",
       "      <td>31815.225</td>\n",
       "      <td>450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.000</td>\n",
       "      <td>...</td>\n",
       "      <td>31460.085</td>\n",
       "      <td>31460.085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1389973</td>\n",
       "      <td>337855</td>\n",
       "      <td>-4</td>\n",
       "      <td>236572.110</td>\n",
       "      <td>225000</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11795.760</td>\n",
       "      <td>...</td>\n",
       "      <td>233048.970</td>\n",
       "      <td>233048.970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1891521</td>\n",
       "      <td>126868</td>\n",
       "      <td>-1</td>\n",
       "      <td>453919.455</td>\n",
       "      <td>450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11547.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11547.0</td>\n",
       "      <td>22924.890</td>\n",
       "      <td>...</td>\n",
       "      <td>453919.455</td>\n",
       "      <td>453919.455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_PREV  SK_ID_CURR  MONTHS_BALANCE  AMT_BALANCE  \\\n",
       "0     2562384      378907              -6       56.970   \n",
       "1     2582071      363914              -1    63975.555   \n",
       "2     1740877      371185              -7    31815.225   \n",
       "3     1389973      337855              -4   236572.110   \n",
       "4     1891521      126868              -1   453919.455   \n",
       "\n",
       "   AMT_CREDIT_LIMIT_ACTUAL  AMT_DRAWINGS_ATM_CURRENT  AMT_DRAWINGS_CURRENT  \\\n",
       "0                   135000                       0.0                 877.5   \n",
       "1                    45000                    2250.0                2250.0   \n",
       "2                   450000                       0.0                   0.0   \n",
       "3                   225000                    2250.0                2250.0   \n",
       "4                   450000                       0.0               11547.0   \n",
       "\n",
       "   AMT_DRAWINGS_OTHER_CURRENT  AMT_DRAWINGS_POS_CURRENT  \\\n",
       "0                         0.0                     877.5   \n",
       "1                         0.0                       0.0   \n",
       "2                         0.0                       0.0   \n",
       "3                         0.0                       0.0   \n",
       "4                         0.0                   11547.0   \n",
       "\n",
       "   AMT_INST_MIN_REGULARITY  ...  AMT_RECIVABLE  AMT_TOTAL_RECEIVABLE  \\\n",
       "0                 1700.325  ...          0.000                 0.000   \n",
       "1                 2250.000  ...      64875.555             64875.555   \n",
       "2                 2250.000  ...      31460.085             31460.085   \n",
       "3                11795.760  ...     233048.970            233048.970   \n",
       "4                22924.890  ...     453919.455            453919.455   \n",
       "\n",
       "   CNT_DRAWINGS_ATM_CURRENT  CNT_DRAWINGS_CURRENT  CNT_DRAWINGS_OTHER_CURRENT  \\\n",
       "0                       0.0                     1                         0.0   \n",
       "1                       1.0                     1                         0.0   \n",
       "2                       0.0                     0                         0.0   \n",
       "3                       1.0                     1                         0.0   \n",
       "4                       0.0                     1                         0.0   \n",
       "\n",
       "   CNT_DRAWINGS_POS_CURRENT  CNT_INSTALMENT_MATURE_CUM  NAME_CONTRACT_STATUS  \\\n",
       "0                       1.0                       35.0                Active   \n",
       "1                       0.0                       69.0                Active   \n",
       "2                       0.0                       30.0                Active   \n",
       "3                       0.0                       10.0                Active   \n",
       "4                       1.0                      101.0                Active   \n",
       "\n",
       "   SK_DPD  SK_DPD_DEF  \n",
       "0       0           0  \n",
       "1       0           0  \n",
       "2       0           0  \n",
       "3       0           0  \n",
       "4       0           0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installments_payments: shape is (13605401, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13605401 entries, 0 to 13605400\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   SK_ID_PREV              int64  \n",
      " 1   SK_ID_CURR              int64  \n",
      " 2   NUM_INSTALMENT_VERSION  float64\n",
      " 3   NUM_INSTALMENT_NUMBER   int64  \n",
      " 4   DAYS_INSTALMENT         float64\n",
      " 5   DAYS_ENTRY_PAYMENT      float64\n",
      " 6   AMT_INSTALMENT          float64\n",
      " 7   AMT_PAYMENT             float64\n",
      "dtypes: float64(5), int64(3)\n",
      "memory usage: 830.4 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NUM_INSTALMENT_VERSION</th>\n",
       "      <th>NUM_INSTALMENT_NUMBER</th>\n",
       "      <th>DAYS_INSTALMENT</th>\n",
       "      <th>DAYS_ENTRY_PAYMENT</th>\n",
       "      <th>AMT_INSTALMENT</th>\n",
       "      <th>AMT_PAYMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1054186</td>\n",
       "      <td>161674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-1180.0</td>\n",
       "      <td>-1187.0</td>\n",
       "      <td>6948.360</td>\n",
       "      <td>6948.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330831</td>\n",
       "      <td>151639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>-2156.0</td>\n",
       "      <td>-2156.0</td>\n",
       "      <td>1716.525</td>\n",
       "      <td>1716.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2085231</td>\n",
       "      <td>193053</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>25425.000</td>\n",
       "      <td>25425.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2452527</td>\n",
       "      <td>199697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2418.0</td>\n",
       "      <td>-2426.0</td>\n",
       "      <td>24350.130</td>\n",
       "      <td>24350.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2714724</td>\n",
       "      <td>167756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1383.0</td>\n",
       "      <td>-1366.0</td>\n",
       "      <td>2165.040</td>\n",
       "      <td>2160.585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_PREV  SK_ID_CURR  NUM_INSTALMENT_VERSION  NUM_INSTALMENT_NUMBER  \\\n",
       "0     1054186      161674                     1.0                      6   \n",
       "1     1330831      151639                     0.0                     34   \n",
       "2     2085231      193053                     2.0                      1   \n",
       "3     2452527      199697                     1.0                      3   \n",
       "4     2714724      167756                     1.0                      2   \n",
       "\n",
       "   DAYS_INSTALMENT  DAYS_ENTRY_PAYMENT  AMT_INSTALMENT  AMT_PAYMENT  \n",
       "0          -1180.0             -1187.0        6948.360     6948.360  \n",
       "1          -2156.0             -2156.0        1716.525     1716.525  \n",
       "2            -63.0               -63.0       25425.000    25425.000  \n",
       "3          -2418.0             -2426.0       24350.130    24350.130  \n",
       "4          -1383.0             -1366.0        2165.040     2160.585  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous_application: shape is (1670214, 37)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1670214 entries, 0 to 1670213\n",
      "Data columns (total 37 columns):\n",
      " #   Column                       Non-Null Count    Dtype  \n",
      "---  ------                       --------------    -----  \n",
      " 0   SK_ID_PREV                   1670214 non-null  int64  \n",
      " 1   SK_ID_CURR                   1670214 non-null  int64  \n",
      " 2   NAME_CONTRACT_TYPE           1670214 non-null  object \n",
      " 3   AMT_ANNUITY                  1297979 non-null  float64\n",
      " 4   AMT_APPLICATION              1670214 non-null  float64\n",
      " 5   AMT_CREDIT                   1670213 non-null  float64\n",
      " 6   AMT_DOWN_PAYMENT             774370 non-null   float64\n",
      " 7   AMT_GOODS_PRICE              1284699 non-null  float64\n",
      " 8   WEEKDAY_APPR_PROCESS_START   1670214 non-null  object \n",
      " 9   HOUR_APPR_PROCESS_START      1670214 non-null  int64  \n",
      " 10  FLAG_LAST_APPL_PER_CONTRACT  1670214 non-null  object \n",
      " 11  NFLAG_LAST_APPL_IN_DAY       1670214 non-null  int64  \n",
      " 12  RATE_DOWN_PAYMENT            774370 non-null   float64\n",
      " 13  RATE_INTEREST_PRIMARY        5951 non-null     float64\n",
      " 14  RATE_INTEREST_PRIVILEGED     5951 non-null     float64\n",
      " 15  NAME_CASH_LOAN_PURPOSE       1670214 non-null  object \n",
      " 16  NAME_CONTRACT_STATUS         1670214 non-null  object \n",
      " 17  DAYS_DECISION                1670214 non-null  int64  \n",
      " 18  NAME_PAYMENT_TYPE            1670214 non-null  object \n",
      " 19  CODE_REJECT_REASON           1670214 non-null  object \n",
      " 20  NAME_TYPE_SUITE              849809 non-null   object \n",
      " 21  NAME_CLIENT_TYPE             1670214 non-null  object \n",
      " 22  NAME_GOODS_CATEGORY          1670214 non-null  object \n",
      " 23  NAME_PORTFOLIO               1670214 non-null  object \n",
      " 24  NAME_PRODUCT_TYPE            1670214 non-null  object \n",
      " 25  CHANNEL_TYPE                 1670214 non-null  object \n",
      " 26  SELLERPLACE_AREA             1670214 non-null  int64  \n",
      " 27  NAME_SELLER_INDUSTRY         1670214 non-null  object \n",
      " 28  CNT_PAYMENT                  1297984 non-null  float64\n",
      " 29  NAME_YIELD_GROUP             1670214 non-null  object \n",
      " 30  PRODUCT_COMBINATION          1669868 non-null  object \n",
      " 31  DAYS_FIRST_DRAWING           997149 non-null   float64\n",
      " 32  DAYS_FIRST_DUE               997149 non-null   float64\n",
      " 33  DAYS_LAST_DUE_1ST_VERSION    997149 non-null   float64\n",
      " 34  DAYS_LAST_DUE                997149 non-null   float64\n",
      " 35  DAYS_TERMINATION             997149 non-null   float64\n",
      " 36  NFLAG_INSURED_ON_APPROVAL    997149 non-null   float64\n",
      "dtypes: float64(15), int64(6), object(16)\n",
      "memory usage: 471.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_APPLICATION</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_DOWN_PAYMENT</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>HOUR_APPR_PROCESS_START</th>\n",
       "      <th>...</th>\n",
       "      <th>NAME_SELLER_INDUSTRY</th>\n",
       "      <th>CNT_PAYMENT</th>\n",
       "      <th>NAME_YIELD_GROUP</th>\n",
       "      <th>PRODUCT_COMBINATION</th>\n",
       "      <th>DAYS_FIRST_DRAWING</th>\n",
       "      <th>DAYS_FIRST_DUE</th>\n",
       "      <th>DAYS_LAST_DUE_1ST_VERSION</th>\n",
       "      <th>DAYS_LAST_DUE</th>\n",
       "      <th>DAYS_TERMINATION</th>\n",
       "      <th>NFLAG_INSURED_ON_APPROVAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2030495</td>\n",
       "      <td>271877</td>\n",
       "      <td>Consumer loans</td>\n",
       "      <td>1730.430</td>\n",
       "      <td>17145.0</td>\n",
       "      <td>17145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17145.0</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>Connectivity</td>\n",
       "      <td>12.0</td>\n",
       "      <td>middle</td>\n",
       "      <td>POS mobile with interest</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2802425</td>\n",
       "      <td>108129</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>25188.615</td>\n",
       "      <td>607500.0</td>\n",
       "      <td>679671.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>607500.0</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>36.0</td>\n",
       "      <td>low_action</td>\n",
       "      <td>Cash X-Sell: low</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-134.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2523466</td>\n",
       "      <td>122040</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>15060.735</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>136444.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>TUESDAY</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>high</td>\n",
       "      <td>Cash X-Sell: high</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-271.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2819243</td>\n",
       "      <td>176158</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>47041.335</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>470790.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>middle</td>\n",
       "      <td>Cash X-Sell: middle</td>\n",
       "      <td>365243.0</td>\n",
       "      <td>-482.0</td>\n",
       "      <td>-152.0</td>\n",
       "      <td>-182.0</td>\n",
       "      <td>-177.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1784265</td>\n",
       "      <td>202054</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>31924.395</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>404055.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337500.0</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>24.0</td>\n",
       "      <td>high</td>\n",
       "      <td>Cash Street: high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_PREV  SK_ID_CURR NAME_CONTRACT_TYPE  AMT_ANNUITY  AMT_APPLICATION  \\\n",
       "0     2030495      271877     Consumer loans     1730.430          17145.0   \n",
       "1     2802425      108129         Cash loans    25188.615         607500.0   \n",
       "2     2523466      122040         Cash loans    15060.735         112500.0   \n",
       "3     2819243      176158         Cash loans    47041.335         450000.0   \n",
       "4     1784265      202054         Cash loans    31924.395         337500.0   \n",
       "\n",
       "   AMT_CREDIT  AMT_DOWN_PAYMENT  AMT_GOODS_PRICE WEEKDAY_APPR_PROCESS_START  \\\n",
       "0     17145.0               0.0          17145.0                   SATURDAY   \n",
       "1    679671.0               NaN         607500.0                   THURSDAY   \n",
       "2    136444.5               NaN         112500.0                    TUESDAY   \n",
       "3    470790.0               NaN         450000.0                     MONDAY   \n",
       "4    404055.0               NaN         337500.0                   THURSDAY   \n",
       "\n",
       "   HOUR_APPR_PROCESS_START  ... NAME_SELLER_INDUSTRY  CNT_PAYMENT  \\\n",
       "0                       15  ...         Connectivity         12.0   \n",
       "1                       11  ...                  XNA         36.0   \n",
       "2                       11  ...                  XNA         12.0   \n",
       "3                        7  ...                  XNA         12.0   \n",
       "4                        9  ...                  XNA         24.0   \n",
       "\n",
       "   NAME_YIELD_GROUP       PRODUCT_COMBINATION  DAYS_FIRST_DRAWING  \\\n",
       "0            middle  POS mobile with interest            365243.0   \n",
       "1        low_action          Cash X-Sell: low            365243.0   \n",
       "2              high         Cash X-Sell: high            365243.0   \n",
       "3            middle       Cash X-Sell: middle            365243.0   \n",
       "4              high         Cash Street: high                 NaN   \n",
       "\n",
       "  DAYS_FIRST_DUE DAYS_LAST_DUE_1ST_VERSION  DAYS_LAST_DUE DAYS_TERMINATION  \\\n",
       "0          -42.0                     300.0          -42.0            -37.0   \n",
       "1         -134.0                     916.0       365243.0         365243.0   \n",
       "2         -271.0                      59.0       365243.0         365243.0   \n",
       "3         -482.0                    -152.0         -182.0           -177.0   \n",
       "4            NaN                       NaN            NaN              NaN   \n",
       "\n",
       "  NFLAG_INSURED_ON_APPROVAL  \n",
       "0                       0.0  \n",
       "1                       1.0  \n",
       "2                       1.0  \n",
       "3                       1.0  \n",
       "4                       NaN  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS_CASH_balance: shape is (10001358, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10001358 entries, 0 to 10001357\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   SK_ID_PREV             int64  \n",
      " 1   SK_ID_CURR             int64  \n",
      " 2   MONTHS_BALANCE         int64  \n",
      " 3   CNT_INSTALMENT         float64\n",
      " 4   CNT_INSTALMENT_FUTURE  float64\n",
      " 5   NAME_CONTRACT_STATUS   object \n",
      " 6   SK_DPD                 int64  \n",
      " 7   SK_DPD_DEF             int64  \n",
      "dtypes: float64(2), int64(5), object(1)\n",
      "memory usage: 610.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>CNT_INSTALMENT</th>\n",
       "      <th>CNT_INSTALMENT_FUTURE</th>\n",
       "      <th>NAME_CONTRACT_STATUS</th>\n",
       "      <th>SK_DPD</th>\n",
       "      <th>SK_DPD_DEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1803195</td>\n",
       "      <td>182943</td>\n",
       "      <td>-31</td>\n",
       "      <td>48.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1715348</td>\n",
       "      <td>367990</td>\n",
       "      <td>-33</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1784872</td>\n",
       "      <td>397406</td>\n",
       "      <td>-32</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1903291</td>\n",
       "      <td>269225</td>\n",
       "      <td>-35</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2341044</td>\n",
       "      <td>334279</td>\n",
       "      <td>-35</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_PREV  SK_ID_CURR  MONTHS_BALANCE  CNT_INSTALMENT  \\\n",
       "0     1803195      182943             -31            48.0   \n",
       "1     1715348      367990             -33            36.0   \n",
       "2     1784872      397406             -32            12.0   \n",
       "3     1903291      269225             -35            48.0   \n",
       "4     2341044      334279             -35            36.0   \n",
       "\n",
       "   CNT_INSTALMENT_FUTURE NAME_CONTRACT_STATUS  SK_DPD  SK_DPD_DEF  \n",
       "0                   45.0               Active       0           0  \n",
       "1                   35.0               Active       0           0  \n",
       "2                    9.0               Active       0           0  \n",
       "3                   42.0               Active       0           0  \n",
       "4                   35.0               Active       0           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 235 ms, total: 1.29 s\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds_names = (\"application_train\", \"application_test\", \"bureau\",\"credit_card_balance\",\"installments_payments\",\n",
    "            \"previous_application\",\"POS_CASH_balance\")\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    datasets[ds_name] = load_data(datasets[ds_name], ds_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset application_train       : [    307,511, 122]\n",
      "dataset application_test        : [     48,744, 121]\n",
      "dataset bureau                  : [  1,716,428, 17]\n",
      "dataset bureau_balance          : [ 27,299,925, 3]\n",
      "dataset credit_card_balance     : [  3,840,312, 23]\n",
      "dataset installments_payments   : [ 13,605,401, 8]\n",
      "dataset previous_application    : [  1,670,214, 37]\n",
      "dataset POS_CASH_balance        : [ 10,001,358, 8]\n"
     ]
    }
   ],
   "source": [
    "for ds_name in datasets.keys():\n",
    "    print(f'dataset {ds_name:24}: [ {datasets[ds_name].shape[0]:10,}, {datasets[ds_name].shape[1]}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis <a name='EDA'></a>\n",
    "\n",
    "Exploratory Data Analysis (*EDA*) on the input tables is necessary to understand the data and to make decisions on transforming the data into a format that is ready for the machine learning pipeline. Custom functions are designed and used for each normalized table to explore the data distribution and transform the table. The tables are transformed by aggregating the data into summary statistics for the table so the child tables can be joined to their parent tables, and ultimately rolled into the application_test_train data based on their ID keys (`SK_ID_CURR`, `SK_ID_PREV`, `SK_ID_BUREAU`). The subsections below outline the main functions designed to accomplish the EDA and data transformation, and also the individual steps applied to each table to accomplish this process.  \n",
    "\n",
    "## EDA Functions\n",
    "\n",
    "A number of custom functions were developed to explore and transform the data. Names of the functions and brief descriptions of their usefulness are summarized here:\n",
    "\n",
    "1. Summary Statistics\n",
    "   + This provides an overview of summary statistics on each variable of each table\n",
    "2. Feature Type Extraction\n",
    "   + This function describes numerical and categorical feature types and provides reference lists for other functions in the EDA process\n",
    "3. Missing Data Analysis\n",
    "   + Looks at the missing data rate for a table's columns\n",
    "4. Feature Aggregating\n",
    "   + A function to group the tables by their ID key and aggregate them into their summary statistics\n",
    "5. One-Hot-Encoding Extract-Transform-Load\n",
    "   + An ETL function that one-hot encodes categorical variables so they can be aggregated, and applies the transformation to the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics for All tables\n",
    "\n",
    "__Function Feature Summary:__\n",
    "\n",
    "A summary of each table is provided using the described function below. This function will take a dataframe as input and provide summary statistics for the table. This generic function will help us evaluate each table with just one line of code, improving the reusablity of the code. Summary statistics will show statistics on each dataframe and through that meaningful interpretations were made about the data to further plan EDA on each dataset.\n",
    "\n",
    "Function name: feature_summary \n",
    "\n",
    "Input: Dataframe\n",
    "\n",
    "Output: Dataframe Summary\n",
    "\n",
    "Function output:\n",
    "1. Provide table name for which analysis in progress.\n",
    "2. Shape - provides rows and columns in the data set.\n",
    "3. NULLS - Number of nulls in the column.\n",
    "4. %_NULL - NULL percentage. (nulls/attributes count).\n",
    "5. Unique values - No of unique values for the feature.\n",
    "6. Data Type - Id column numerical or categorical.\n",
    "7. Max/Min - Max and min for the column. This provides idea about scale. helps if need log transformation.\n",
    "8. Mean - Mean of the attribute.\n",
    "9. Std - Standard Deviation of the atttibute.\n",
    "10. Skewness - Skewness, data distribution of transformations.\n",
    "11. Sample values - Sample values for the attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_summary(df_fa):\n",
    "    print('DataFrame shape')\n",
    "    print('Rows:',df_fa.shape[0])\n",
    "    print('Cols:',df_fa.shape[1])\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    \n",
    "    col_list=['Null','%_Null','Unique_Count','Data_type','Max/Min','Mean','Std','Skewness','Sample_values']\n",
    "    df=pd.DataFrame(index=df_fa.columns,columns=col_list)\n",
    "    df['Null']=list([len(df_fa[col][df_fa[col].isnull()]) for i,col in enumerate(df_fa.columns)])\n",
    "    df['%_Null']=round((df_fa.isnull().sum()/df_fa.isnull().count()*100),3).sort_values(ascending = False)\n",
    "    df['Unique_Count']=list([len(df_fa[col].unique()) for i,col in enumerate(df_fa.columns)])\n",
    "    df['Data_type']=list([df_fa[col].dtype for i,col in enumerate(df_fa.columns)])\n",
    "    for i,col in enumerate(df_fa.columns):\n",
    "        if 'float' in str(df_fa[col].dtype) or 'int' in str(df_fa[col].dtype):\n",
    "            df.at[col,'Max/Min']=str(round(df_fa[col].max(),2))+'/'+str(round(df_fa[col].min(),2))\n",
    "            df.at[col,'Mean']=df_fa[col].mean()\n",
    "            df.at[col,'Std']=df_fa[col].std()\n",
    "            df.at[col,'Skewness']=df_fa[col].skew()\n",
    "        df.at[col,'Sample_values']=list(df_fa[col].unique())\n",
    "    print(\"Table Statistics\")\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    display(df.fillna('-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table under consideration: APPLICATION_TRAIN\n",
      "------------------------------------------------------------------------\n",
      "DataFrame shape\n",
      "Rows: 307511\n",
      "Cols: 122\n",
      "------------------------------------------------------------------------\n",
      "Table Statistics\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null</th>\n",
       "      <th>%_Null</th>\n",
       "      <th>Unique_Count</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Max/Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>307511</td>\n",
       "      <td>int64</td>\n",
       "      <td>456255/100002</td>\n",
       "      <td>278180.518577</td>\n",
       "      <td>102790.175348</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>[100002, 100003, 100004, 100006, 100007, 10000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TARGET</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>int64</td>\n",
       "      <td>1/0</td>\n",
       "      <td>0.080729</td>\n",
       "      <td>0.272419</td>\n",
       "      <td>3.078159</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Cash loans, Revolving loans]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[M, F, XNA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[N, Y]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <td>41519</td>\n",
       "      <td>13.502</td>\n",
       "      <td>10</td>\n",
       "      <td>float64</td>\n",
       "      <td>9.0/0.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.110757</td>\n",
       "      <td>27.043505</td>\n",
       "      <td>[0.0, nan, 1.0, 3.0, 2.0, 4.0, 5.0, 6.0, 9.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <td>41519</td>\n",
       "      <td>13.502</td>\n",
       "      <td>10</td>\n",
       "      <td>float64</td>\n",
       "      <td>8.0/0.0</td>\n",
       "      <td>0.034362</td>\n",
       "      <td>0.204685</td>\n",
       "      <td>9.293573</td>\n",
       "      <td>[0.0, nan, 1.0, 3.0, 2.0, 4.0, 5.0, 6.0, 8.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <td>41519</td>\n",
       "      <td>13.502</td>\n",
       "      <td>25</td>\n",
       "      <td>float64</td>\n",
       "      <td>27.0/0.0</td>\n",
       "      <td>0.267395</td>\n",
       "      <td>0.916002</td>\n",
       "      <td>7.804848</td>\n",
       "      <td>[0.0, nan, 1.0, 2.0, 6.0, 5.0, 3.0, 7.0, 9.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <td>41519</td>\n",
       "      <td>13.502</td>\n",
       "      <td>12</td>\n",
       "      <td>float64</td>\n",
       "      <td>261.0/0.0</td>\n",
       "      <td>0.265474</td>\n",
       "      <td>0.794056</td>\n",
       "      <td>134.365776</td>\n",
       "      <td>[0.0, nan, 1.0, 2.0, 4.0, 3.0, 8.0, 5.0, 6.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <td>41519</td>\n",
       "      <td>13.502</td>\n",
       "      <td>26</td>\n",
       "      <td>float64</td>\n",
       "      <td>25.0/0.0</td>\n",
       "      <td>1.899974</td>\n",
       "      <td>1.869295</td>\n",
       "      <td>1.24359</td>\n",
       "      <td>[1.0, 0.0, nan, 2.0, 4.0, 5.0, 3.0, 8.0, 6.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Null  %_Null  Unique_Count Data_type  \\\n",
       "SK_ID_CURR                      0   0.000        307511     int64   \n",
       "TARGET                          0   0.000             2     int64   \n",
       "NAME_CONTRACT_TYPE              0   0.000             2    object   \n",
       "CODE_GENDER                     0   0.000             3    object   \n",
       "FLAG_OWN_CAR                    0   0.000             2    object   \n",
       "...                           ...     ...           ...       ...   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY   41519  13.502            10   float64   \n",
       "AMT_REQ_CREDIT_BUREAU_WEEK  41519  13.502            10   float64   \n",
       "AMT_REQ_CREDIT_BUREAU_MON   41519  13.502            25   float64   \n",
       "AMT_REQ_CREDIT_BUREAU_QRT   41519  13.502            12   float64   \n",
       "AMT_REQ_CREDIT_BUREAU_YEAR  41519  13.502            26   float64   \n",
       "\n",
       "                                  Max/Min           Mean            Std  \\\n",
       "SK_ID_CURR                  456255/100002  278180.518577  102790.175348   \n",
       "TARGET                                1/0       0.080729       0.272419   \n",
       "NAME_CONTRACT_TYPE                      -              -              -   \n",
       "CODE_GENDER                             -              -              -   \n",
       "FLAG_OWN_CAR                            -              -              -   \n",
       "...                                   ...            ...            ...   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY         9.0/0.0          0.007       0.110757   \n",
       "AMT_REQ_CREDIT_BUREAU_WEEK        8.0/0.0       0.034362       0.204685   \n",
       "AMT_REQ_CREDIT_BUREAU_MON        27.0/0.0       0.267395       0.916002   \n",
       "AMT_REQ_CREDIT_BUREAU_QRT       261.0/0.0       0.265474       0.794056   \n",
       "AMT_REQ_CREDIT_BUREAU_YEAR       25.0/0.0       1.899974       1.869295   \n",
       "\n",
       "                              Skewness  \\\n",
       "SK_ID_CURR                     -0.0012   \n",
       "TARGET                        3.078159   \n",
       "NAME_CONTRACT_TYPE                   -   \n",
       "CODE_GENDER                          -   \n",
       "FLAG_OWN_CAR                         -   \n",
       "...                                ...   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY    27.043505   \n",
       "AMT_REQ_CREDIT_BUREAU_WEEK    9.293573   \n",
       "AMT_REQ_CREDIT_BUREAU_MON     7.804848   \n",
       "AMT_REQ_CREDIT_BUREAU_QRT   134.365776   \n",
       "AMT_REQ_CREDIT_BUREAU_YEAR     1.24359   \n",
       "\n",
       "                                                                Sample_values  \n",
       "SK_ID_CURR                  [100002, 100003, 100004, 100006, 100007, 10000...  \n",
       "TARGET                                                                 [1, 0]  \n",
       "NAME_CONTRACT_TYPE                              [Cash loans, Revolving loans]  \n",
       "CODE_GENDER                                                       [M, F, XNA]  \n",
       "FLAG_OWN_CAR                                                           [N, Y]  \n",
       "...                                                                       ...  \n",
       "AMT_REQ_CREDIT_BUREAU_DAY   [0.0, nan, 1.0, 3.0, 2.0, 4.0, 5.0, 6.0, 9.0, ...  \n",
       "AMT_REQ_CREDIT_BUREAU_WEEK  [0.0, nan, 1.0, 3.0, 2.0, 4.0, 5.0, 6.0, 8.0, ...  \n",
       "AMT_REQ_CREDIT_BUREAU_MON   [0.0, nan, 1.0, 2.0, 6.0, 5.0, 3.0, 7.0, 9.0, ...  \n",
       "AMT_REQ_CREDIT_BUREAU_QRT   [0.0, nan, 1.0, 2.0, 4.0, 3.0, 8.0, 5.0, 6.0, ...  \n",
       "AMT_REQ_CREDIT_BUREAU_YEAR  [1.0, 0.0, nan, 2.0, 4.0, 5.0, 3.0, 8.0, 6.0, ...  \n",
       "\n",
       "[122 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Table under consideration: APPLICATION_TEST\n",
      "------------------------------------------------------------------------\n",
      "DataFrame shape\n",
      "Rows: 48744\n",
      "Cols: 121\n",
      "------------------------------------------------------------------------\n",
      "Table Statistics\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null</th>\n",
       "      <th>%_Null</th>\n",
       "      <th>Unique_Count</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Max/Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48744</td>\n",
       "      <td>int64</td>\n",
       "      <td>456250/100001</td>\n",
       "      <td>277796.67635</td>\n",
       "      <td>103169.547296</td>\n",
       "      <td>0.00756</td>\n",
       "      <td>[100001, 100005, 100013, 100028, 100038, 10004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Cash loans, Revolving loans]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[F, M]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[N, Y]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Y, N]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <td>6049</td>\n",
       "      <td>12.41</td>\n",
       "      <td>4</td>\n",
       "      <td>float64</td>\n",
       "      <td>2.0/0.0</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.046132</td>\n",
       "      <td>28.273838</td>\n",
       "      <td>[0.0, nan, 1.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <td>6049</td>\n",
       "      <td>12.41</td>\n",
       "      <td>4</td>\n",
       "      <td>float64</td>\n",
       "      <td>2.0/0.0</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.054037</td>\n",
       "      <td>20.182271</td>\n",
       "      <td>[0.0, nan, 1.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <td>6049</td>\n",
       "      <td>12.41</td>\n",
       "      <td>8</td>\n",
       "      <td>float64</td>\n",
       "      <td>6.0/0.0</td>\n",
       "      <td>0.009299</td>\n",
       "      <td>0.110924</td>\n",
       "      <td>17.270891</td>\n",
       "      <td>[0.0, nan, 1.0, 3.0, 2.0, 6.0, 4.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <td>6049</td>\n",
       "      <td>12.41</td>\n",
       "      <td>9</td>\n",
       "      <td>float64</td>\n",
       "      <td>7.0/0.0</td>\n",
       "      <td>0.546902</td>\n",
       "      <td>0.693305</td>\n",
       "      <td>1.254612</td>\n",
       "      <td>[0.0, 1.0, nan, 3.0, 2.0, 4.0, 5.0, 7.0, 6.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <td>6049</td>\n",
       "      <td>12.41</td>\n",
       "      <td>17</td>\n",
       "      <td>float64</td>\n",
       "      <td>17.0/0.0</td>\n",
       "      <td>1.983769</td>\n",
       "      <td>1.838873</td>\n",
       "      <td>1.065424</td>\n",
       "      <td>[0.0, 3.0, 4.0, nan, 2.0, 1.0, 5.0, 6.0, 7.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Null  %_Null  Unique_Count Data_type  \\\n",
       "SK_ID_CURR                     0    0.00         48744     int64   \n",
       "NAME_CONTRACT_TYPE             0    0.00             2    object   \n",
       "CODE_GENDER                    0    0.00             2    object   \n",
       "FLAG_OWN_CAR                   0    0.00             2    object   \n",
       "FLAG_OWN_REALTY                0    0.00             2    object   \n",
       "...                          ...     ...           ...       ...   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY   6049   12.41             4   float64   \n",
       "AMT_REQ_CREDIT_BUREAU_WEEK  6049   12.41             4   float64   \n",
       "AMT_REQ_CREDIT_BUREAU_MON   6049   12.41             8   float64   \n",
       "AMT_REQ_CREDIT_BUREAU_QRT   6049   12.41             9   float64   \n",
       "AMT_REQ_CREDIT_BUREAU_YEAR  6049   12.41            17   float64   \n",
       "\n",
       "                                  Max/Min          Mean            Std  \\\n",
       "SK_ID_CURR                  456250/100001  277796.67635  103169.547296   \n",
       "NAME_CONTRACT_TYPE                      -             -              -   \n",
       "CODE_GENDER                             -             -              -   \n",
       "FLAG_OWN_CAR                            -             -              -   \n",
       "FLAG_OWN_REALTY                         -             -              -   \n",
       "...                                   ...           ...            ...   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY         2.0/0.0      0.001803       0.046132   \n",
       "AMT_REQ_CREDIT_BUREAU_WEEK        2.0/0.0      0.002787       0.054037   \n",
       "AMT_REQ_CREDIT_BUREAU_MON         6.0/0.0      0.009299       0.110924   \n",
       "AMT_REQ_CREDIT_BUREAU_QRT         7.0/0.0      0.546902       0.693305   \n",
       "AMT_REQ_CREDIT_BUREAU_YEAR       17.0/0.0      1.983769       1.838873   \n",
       "\n",
       "                             Skewness  \\\n",
       "SK_ID_CURR                    0.00756   \n",
       "NAME_CONTRACT_TYPE                  -   \n",
       "CODE_GENDER                         -   \n",
       "FLAG_OWN_CAR                        -   \n",
       "FLAG_OWN_REALTY                     -   \n",
       "...                               ...   \n",
       "AMT_REQ_CREDIT_BUREAU_DAY   28.273838   \n",
       "AMT_REQ_CREDIT_BUREAU_WEEK  20.182271   \n",
       "AMT_REQ_CREDIT_BUREAU_MON   17.270891   \n",
       "AMT_REQ_CREDIT_BUREAU_QRT    1.254612   \n",
       "AMT_REQ_CREDIT_BUREAU_YEAR   1.065424   \n",
       "\n",
       "                                                                Sample_values  \n",
       "SK_ID_CURR                  [100001, 100005, 100013, 100028, 100038, 10004...  \n",
       "NAME_CONTRACT_TYPE                              [Cash loans, Revolving loans]  \n",
       "CODE_GENDER                                                            [F, M]  \n",
       "FLAG_OWN_CAR                                                           [N, Y]  \n",
       "FLAG_OWN_REALTY                                                        [Y, N]  \n",
       "...                                                                       ...  \n",
       "AMT_REQ_CREDIT_BUREAU_DAY                                [0.0, nan, 1.0, 2.0]  \n",
       "AMT_REQ_CREDIT_BUREAU_WEEK                               [0.0, nan, 1.0, 2.0]  \n",
       "AMT_REQ_CREDIT_BUREAU_MON            [0.0, nan, 1.0, 3.0, 2.0, 6.0, 4.0, 5.0]  \n",
       "AMT_REQ_CREDIT_BUREAU_QRT       [0.0, 1.0, nan, 3.0, 2.0, 4.0, 5.0, 7.0, 6.0]  \n",
       "AMT_REQ_CREDIT_BUREAU_YEAR  [0.0, 3.0, 4.0, nan, 2.0, 1.0, 5.0, 6.0, 7.0, ...  \n",
       "\n",
       "[121 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Table under consideration: BUREAU\n",
      "------------------------------------------------------------------------\n",
      "DataFrame shape\n",
      "Rows: 1716428\n",
      "Cols: 17\n",
      "------------------------------------------------------------------------\n",
      "Table Statistics\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null</th>\n",
       "      <th>%_Null</th>\n",
       "      <th>Unique_Count</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Max/Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>305811</td>\n",
       "      <td>int64</td>\n",
       "      <td>456255/100001</td>\n",
       "      <td>278214.933645</td>\n",
       "      <td>102938.558112</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>[215354, 162297, 402440, 238881, 222183, 42615...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_BUREAU</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1716428</td>\n",
       "      <td>int64</td>\n",
       "      <td>6843457/5000000</td>\n",
       "      <td>5924434.489032</td>\n",
       "      <td>532265.728552</td>\n",
       "      <td>-0.007498</td>\n",
       "      <td>[5714462, 5714463, 5714464, 5714465, 5714466, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREDIT_ACTIVE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Closed, Active, Sold, Bad debt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREDIT_CURRENCY</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[currency 1, currency 2, currency 4, currency 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_CREDIT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2923</td>\n",
       "      <td>int64</td>\n",
       "      <td>0/-2922</td>\n",
       "      <td>-1142.107685</td>\n",
       "      <td>795.164928</td>\n",
       "      <td>-0.582349</td>\n",
       "      <td>[-497, -208, -203, -629, -273, -43, -1896, -11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREDIT_DAY_OVERDUE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>942</td>\n",
       "      <td>int64</td>\n",
       "      <td>2792/0</td>\n",
       "      <td>0.818167</td>\n",
       "      <td>36.544428</td>\n",
       "      <td>55.931005</td>\n",
       "      <td>[0, 2603, 6, 30, 2156, 496, 186, 2264, 41, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_CREDIT_ENDDATE</th>\n",
       "      <td>105553</td>\n",
       "      <td>6.150</td>\n",
       "      <td>14097</td>\n",
       "      <td>float64</td>\n",
       "      <td>31199.0/-42060.0</td>\n",
       "      <td>510.517362</td>\n",
       "      <td>4994.219837</td>\n",
       "      <td>5.127134</td>\n",
       "      <td>[-153.0, 1075.0, 528.0, nan, 1197.0, 27460.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_ENDDATE_FACT</th>\n",
       "      <td>633653</td>\n",
       "      <td>36.917</td>\n",
       "      <td>2918</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.0/-42023.0</td>\n",
       "      <td>-1017.437148</td>\n",
       "      <td>714.010626</td>\n",
       "      <td>-0.774754</td>\n",
       "      <td>[-153.0, nan, -1710.0, -840.0, -825.0, -187.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT_MAX_OVERDUE</th>\n",
       "      <td>1124488</td>\n",
       "      <td>65.513</td>\n",
       "      <td>68252</td>\n",
       "      <td>float64</td>\n",
       "      <td>115987185.0/0.0</td>\n",
       "      <td>3825.417661</td>\n",
       "      <td>206031.606207</td>\n",
       "      <td>470.913819</td>\n",
       "      <td>[nan, 77674.5, 0.0, 14985.0, 310.5, 20493.27, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNT_CREDIT_PROLONG</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10</td>\n",
       "      <td>int64</td>\n",
       "      <td>9/0</td>\n",
       "      <td>0.00641</td>\n",
       "      <td>0.096224</td>\n",
       "      <td>20.319277</td>\n",
       "      <td>[0, 2, 1, 4, 3, 5, 9, 8, 6, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT_SUM</th>\n",
       "      <td>13</td>\n",
       "      <td>0.001</td>\n",
       "      <td>236709</td>\n",
       "      <td>float64</td>\n",
       "      <td>585000000.0/0.0</td>\n",
       "      <td>354994.591918</td>\n",
       "      <td>1149811.34398</td>\n",
       "      <td>124.586097</td>\n",
       "      <td>[91323.0, 225000.0, 464323.5, 90000.0, 2700000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT_SUM_DEBT</th>\n",
       "      <td>257669</td>\n",
       "      <td>15.012</td>\n",
       "      <td>226538</td>\n",
       "      <td>float64</td>\n",
       "      <td>170100000.0/-4705600.32</td>\n",
       "      <td>137085.119952</td>\n",
       "      <td>677401.130952</td>\n",
       "      <td>36.414538</td>\n",
       "      <td>[0.0, 171342.0, nan, 71017.38, 42103.8, 76905....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT_SUM_LIMIT</th>\n",
       "      <td>591780</td>\n",
       "      <td>34.477</td>\n",
       "      <td>51727</td>\n",
       "      <td>float64</td>\n",
       "      <td>4705600.32/-586406.11</td>\n",
       "      <td>6229.51498</td>\n",
       "      <td>45032.031476</td>\n",
       "      <td>18.026914</td>\n",
       "      <td>[nan, 108982.62, 0.0, 228320.1, 411.615, 12169...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT_SUM_OVERDUE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1616</td>\n",
       "      <td>float64</td>\n",
       "      <td>3756681.0/0.0</td>\n",
       "      <td>37.912758</td>\n",
       "      <td>5937.650035</td>\n",
       "      <td>403.241858</td>\n",
       "      <td>[0.0, 231.525, 288.0, 58.5, 504.0, 169582.5, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CREDIT_TYPE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Consumer credit, Credit card, Mortgage, Car l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_CREDIT_UPDATE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2982</td>\n",
       "      <td>int64</td>\n",
       "      <td>372/-41947</td>\n",
       "      <td>-593.74832</td>\n",
       "      <td>720.747312</td>\n",
       "      <td>-11.334995</td>\n",
       "      <td>[-131, -20, -16, -21, -31, -22, -1710, -840, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <td>1226791</td>\n",
       "      <td>71.473</td>\n",
       "      <td>40322</td>\n",
       "      <td>float64</td>\n",
       "      <td>118453423.5/0.0</td>\n",
       "      <td>15712.7577</td>\n",
       "      <td>325826.949053</td>\n",
       "      <td>212.543125</td>\n",
       "      <td>[nan, 0.0, 2691.0, 24462.0, 8181.0, 8061.21, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Null  %_Null  Unique_Count Data_type  \\\n",
       "SK_ID_CURR                    0   0.000        305811     int64   \n",
       "SK_ID_BUREAU                  0   0.000       1716428     int64   \n",
       "CREDIT_ACTIVE                 0   0.000             4    object   \n",
       "CREDIT_CURRENCY               0   0.000             4    object   \n",
       "DAYS_CREDIT                   0   0.000          2923     int64   \n",
       "CREDIT_DAY_OVERDUE            0   0.000           942     int64   \n",
       "DAYS_CREDIT_ENDDATE      105553   6.150         14097   float64   \n",
       "DAYS_ENDDATE_FACT        633653  36.917          2918   float64   \n",
       "AMT_CREDIT_MAX_OVERDUE  1124488  65.513         68252   float64   \n",
       "CNT_CREDIT_PROLONG            0   0.000            10     int64   \n",
       "AMT_CREDIT_SUM               13   0.001        236709   float64   \n",
       "AMT_CREDIT_SUM_DEBT      257669  15.012        226538   float64   \n",
       "AMT_CREDIT_SUM_LIMIT     591780  34.477         51727   float64   \n",
       "AMT_CREDIT_SUM_OVERDUE        0   0.000          1616   float64   \n",
       "CREDIT_TYPE                   0   0.000            15    object   \n",
       "DAYS_CREDIT_UPDATE            0   0.000          2982     int64   \n",
       "AMT_ANNUITY             1226791  71.473         40322   float64   \n",
       "\n",
       "                                        Max/Min            Mean  \\\n",
       "SK_ID_CURR                        456255/100001   278214.933645   \n",
       "SK_ID_BUREAU                    6843457/5000000  5924434.489032   \n",
       "CREDIT_ACTIVE                                 -               -   \n",
       "CREDIT_CURRENCY                               -               -   \n",
       "DAYS_CREDIT                             0/-2922    -1142.107685   \n",
       "CREDIT_DAY_OVERDUE                       2792/0        0.818167   \n",
       "DAYS_CREDIT_ENDDATE            31199.0/-42060.0      510.517362   \n",
       "DAYS_ENDDATE_FACT                  0.0/-42023.0    -1017.437148   \n",
       "AMT_CREDIT_MAX_OVERDUE          115987185.0/0.0     3825.417661   \n",
       "CNT_CREDIT_PROLONG                          9/0         0.00641   \n",
       "AMT_CREDIT_SUM                  585000000.0/0.0   354994.591918   \n",
       "AMT_CREDIT_SUM_DEBT     170100000.0/-4705600.32   137085.119952   \n",
       "AMT_CREDIT_SUM_LIMIT      4705600.32/-586406.11      6229.51498   \n",
       "AMT_CREDIT_SUM_OVERDUE            3756681.0/0.0       37.912758   \n",
       "CREDIT_TYPE                                   -               -   \n",
       "DAYS_CREDIT_UPDATE                   372/-41947      -593.74832   \n",
       "AMT_ANNUITY                     118453423.5/0.0      15712.7577   \n",
       "\n",
       "                                  Std    Skewness  \\\n",
       "SK_ID_CURR              102938.558112    0.001063   \n",
       "SK_ID_BUREAU            532265.728552   -0.007498   \n",
       "CREDIT_ACTIVE                       -           -   \n",
       "CREDIT_CURRENCY                     -           -   \n",
       "DAYS_CREDIT                795.164928   -0.582349   \n",
       "CREDIT_DAY_OVERDUE          36.544428   55.931005   \n",
       "DAYS_CREDIT_ENDDATE       4994.219837    5.127134   \n",
       "DAYS_ENDDATE_FACT          714.010626   -0.774754   \n",
       "AMT_CREDIT_MAX_OVERDUE  206031.606207  470.913819   \n",
       "CNT_CREDIT_PROLONG           0.096224   20.319277   \n",
       "AMT_CREDIT_SUM          1149811.34398  124.586097   \n",
       "AMT_CREDIT_SUM_DEBT     677401.130952   36.414538   \n",
       "AMT_CREDIT_SUM_LIMIT     45032.031476   18.026914   \n",
       "AMT_CREDIT_SUM_OVERDUE    5937.650035  403.241858   \n",
       "CREDIT_TYPE                         -           -   \n",
       "DAYS_CREDIT_UPDATE         720.747312  -11.334995   \n",
       "AMT_ANNUITY             325826.949053  212.543125   \n",
       "\n",
       "                                                            Sample_values  \n",
       "SK_ID_CURR              [215354, 162297, 402440, 238881, 222183, 42615...  \n",
       "SK_ID_BUREAU            [5714462, 5714463, 5714464, 5714465, 5714466, ...  \n",
       "CREDIT_ACTIVE                            [Closed, Active, Sold, Bad debt]  \n",
       "CREDIT_CURRENCY          [currency 1, currency 2, currency 4, currency 3]  \n",
       "DAYS_CREDIT             [-497, -208, -203, -629, -273, -43, -1896, -11...  \n",
       "CREDIT_DAY_OVERDUE      [0, 2603, 6, 30, 2156, 496, 186, 2264, 41, 8, ...  \n",
       "DAYS_CREDIT_ENDDATE     [-153.0, 1075.0, 528.0, nan, 1197.0, 27460.0, ...  \n",
       "DAYS_ENDDATE_FACT       [-153.0, nan, -1710.0, -840.0, -825.0, -187.0,...  \n",
       "AMT_CREDIT_MAX_OVERDUE  [nan, 77674.5, 0.0, 14985.0, 310.5, 20493.27, ...  \n",
       "CNT_CREDIT_PROLONG                         [0, 2, 1, 4, 3, 5, 9, 8, 6, 7]  \n",
       "AMT_CREDIT_SUM          [91323.0, 225000.0, 464323.5, 90000.0, 2700000...  \n",
       "AMT_CREDIT_SUM_DEBT     [0.0, 171342.0, nan, 71017.38, 42103.8, 76905....  \n",
       "AMT_CREDIT_SUM_LIMIT    [nan, 108982.62, 0.0, 228320.1, 411.615, 12169...  \n",
       "AMT_CREDIT_SUM_OVERDUE  [0.0, 231.525, 288.0, 58.5, 504.0, 169582.5, 3...  \n",
       "CREDIT_TYPE             [Consumer credit, Credit card, Mortgage, Car l...  \n",
       "DAYS_CREDIT_UPDATE      [-131, -20, -16, -21, -31, -22, -1710, -840, -...  \n",
       "AMT_ANNUITY             [nan, 0.0, 2691.0, 24462.0, 8181.0, 8061.21, 1...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Table under consideration: BUREAU_BALANCE\n",
      "------------------------------------------------------------------------\n",
      "DataFrame shape\n",
      "Rows: 27299925\n",
      "Cols: 3\n",
      "------------------------------------------------------------------------\n",
      "Table Statistics\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null</th>\n",
       "      <th>%_Null</th>\n",
       "      <th>Unique_Count</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Max/Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_BUREAU</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>817395</td>\n",
       "      <td>int64</td>\n",
       "      <td>6842888/5001709</td>\n",
       "      <td>6036297.332974</td>\n",
       "      <td>492348.856904</td>\n",
       "      <td>-0.372188</td>\n",
       "      <td>[5715448, 5715449, 5715451, 5715452, 5715453, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97</td>\n",
       "      <td>int64</td>\n",
       "      <td>0/-96</td>\n",
       "      <td>-30.741687</td>\n",
       "      <td>23.864509</td>\n",
       "      <td>-0.76069</td>\n",
       "      <td>[0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATUS</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[C, 0, X, 1, 2, 3, 5, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Null  %_Null  Unique_Count Data_type          Max/Min  \\\n",
       "SK_ID_BUREAU       0     0.0        817395     int64  6842888/5001709   \n",
       "MONTHS_BALANCE     0     0.0            97     int64            0/-96   \n",
       "STATUS             0     0.0             8    object                -   \n",
       "\n",
       "                          Mean            Std  Skewness  \\\n",
       "SK_ID_BUREAU    6036297.332974  492348.856904 -0.372188   \n",
       "MONTHS_BALANCE      -30.741687      23.864509  -0.76069   \n",
       "STATUS                       -              -         -   \n",
       "\n",
       "                                                    Sample_values  \n",
       "SK_ID_BUREAU    [5715448, 5715449, 5715451, 5715452, 5715453, ...  \n",
       "MONTHS_BALANCE  [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -...  \n",
       "STATUS                                   [C, 0, X, 1, 2, 3, 5, 4]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Table under consideration: CREDIT_CARD_BALANCE\n",
      "------------------------------------------------------------------------\n",
      "DataFrame shape\n",
      "Rows: 3840312\n",
      "Cols: 23\n",
      "------------------------------------------------------------------------\n",
      "Table Statistics\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null</th>\n",
       "      <th>%_Null</th>\n",
       "      <th>Unique_Count</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Max/Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>104307</td>\n",
       "      <td>int64</td>\n",
       "      <td>2843496/1000018</td>\n",
       "      <td>1904503.5899</td>\n",
       "      <td>536469.470563</td>\n",
       "      <td>0.038385</td>\n",
       "      <td>[2562384, 2582071, 1740877, 1389973, 1891521, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>103558</td>\n",
       "      <td>int64</td>\n",
       "      <td>456250/100006</td>\n",
       "      <td>278324.207289</td>\n",
       "      <td>102704.475133</td>\n",
       "      <td>-0.001834</td>\n",
       "      <td>[378907, 363914, 371185, 337855, 126868, 38001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>96</td>\n",
       "      <td>int64</td>\n",
       "      <td>-1/-96</td>\n",
       "      <td>-34.521921</td>\n",
       "      <td>26.667751</td>\n",
       "      <td>-0.59804</td>\n",
       "      <td>[-6, -1, -7, -4, -5, -3, -2, -19, -13, -18, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_BALANCE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1347904</td>\n",
       "      <td>float64</td>\n",
       "      <td>1505902.19/-420250.18</td>\n",
       "      <td>58300.155262</td>\n",
       "      <td>106307.031025</td>\n",
       "      <td>2.920173</td>\n",
       "      <td>[56.97, 63975.555, 31815.225, 236572.11, 45391...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT_LIMIT_ACTUAL</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>181</td>\n",
       "      <td>int64</td>\n",
       "      <td>1350000/0</td>\n",
       "      <td>153807.9574</td>\n",
       "      <td>165145.699523</td>\n",
       "      <td>2.059732</td>\n",
       "      <td>[135000, 45000, 450000, 225000, 270000, 585000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_DRAWINGS_ATM_CURRENT</th>\n",
       "      <td>749816</td>\n",
       "      <td>19.525</td>\n",
       "      <td>2268</td>\n",
       "      <td>float64</td>\n",
       "      <td>2115000.0/-6827.31</td>\n",
       "      <td>5961.324822</td>\n",
       "      <td>28225.688579</td>\n",
       "      <td>9.664842</td>\n",
       "      <td>[0.0, 2250.0, 67500.0, 45000.0, 90000.0, 76500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_DRAWINGS_CURRENT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>187005</td>\n",
       "      <td>float64</td>\n",
       "      <td>2287098.31/-6211.62</td>\n",
       "      <td>7433.388179</td>\n",
       "      <td>33846.077334</td>\n",
       "      <td>10.065626</td>\n",
       "      <td>[877.5, 2250.0, 0.0, 11547.0, 67500.0, 45000.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_DRAWINGS_OTHER_CURRENT</th>\n",
       "      <td>749816</td>\n",
       "      <td>19.525</td>\n",
       "      <td>1833</td>\n",
       "      <td>float64</td>\n",
       "      <td>1529847.0/0.0</td>\n",
       "      <td>288.169582</td>\n",
       "      <td>8201.989345</td>\n",
       "      <td>50.57035</td>\n",
       "      <td>[0.0, 137700.0, nan, 177840.0, 46800.0, 187200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_DRAWINGS_POS_CURRENT</th>\n",
       "      <td>749816</td>\n",
       "      <td>19.525</td>\n",
       "      <td>168749</td>\n",
       "      <td>float64</td>\n",
       "      <td>2239274.16/0.0</td>\n",
       "      <td>2968.804848</td>\n",
       "      <td>20796.887047</td>\n",
       "      <td>19.421081</td>\n",
       "      <td>[877.5, 0.0, 11547.0, 199339.425, 34526.7, 968...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_INST_MIN_REGULARITY</th>\n",
       "      <td>305236</td>\n",
       "      <td>7.948</td>\n",
       "      <td>312267</td>\n",
       "      <td>float64</td>\n",
       "      <td>202882.01/0.0</td>\n",
       "      <td>3540.204129</td>\n",
       "      <td>5600.154122</td>\n",
       "      <td>2.494431</td>\n",
       "      <td>[1700.325, 2250.0, 11795.76, 22924.89, 4449.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_PAYMENT_CURRENT</th>\n",
       "      <td>767988</td>\n",
       "      <td>19.998</td>\n",
       "      <td>163210</td>\n",
       "      <td>float64</td>\n",
       "      <td>4289207.45/0.0</td>\n",
       "      <td>10280.537702</td>\n",
       "      <td>36078.084953</td>\n",
       "      <td>12.990581</td>\n",
       "      <td>[1800.0, 2250.0, 11925.0, 27000.0, 3825.0, 157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_PAYMENT_TOTAL_CURRENT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>182957</td>\n",
       "      <td>float64</td>\n",
       "      <td>4278315.69/0.0</td>\n",
       "      <td>7588.856739</td>\n",
       "      <td>32005.987768</td>\n",
       "      <td>14.479719</td>\n",
       "      <td>[1800.0, 2250.0, 11925.0, 27000.0, 3825.0, 157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_RECEIVABLE_PRINCIPAL</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1195839</td>\n",
       "      <td>float64</td>\n",
       "      <td>1472316.79/-423305.82</td>\n",
       "      <td>55965.876905</td>\n",
       "      <td>102533.616843</td>\n",
       "      <td>2.942316</td>\n",
       "      <td>[0.0, 60175.08, 26926.425, 224949.285, 443044....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_RECIVABLE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1338878</td>\n",
       "      <td>float64</td>\n",
       "      <td>1493338.19/-420250.18</td>\n",
       "      <td>58088.811177</td>\n",
       "      <td>105965.369908</td>\n",
       "      <td>2.913172</td>\n",
       "      <td>[0.0, 64875.555, 31460.085, 233048.97, 453919....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_TOTAL_RECEIVABLE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1339008</td>\n",
       "      <td>float64</td>\n",
       "      <td>1493338.19/-420250.18</td>\n",
       "      <td>58098.285489</td>\n",
       "      <td>105971.801103</td>\n",
       "      <td>2.912684</td>\n",
       "      <td>[0.0, 64875.555, 31460.085, 233048.97, 453919....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNT_DRAWINGS_ATM_CURRENT</th>\n",
       "      <td>749816</td>\n",
       "      <td>19.525</td>\n",
       "      <td>45</td>\n",
       "      <td>float64</td>\n",
       "      <td>51.0/0.0</td>\n",
       "      <td>0.309449</td>\n",
       "      <td>1.100401</td>\n",
       "      <td>6.906655</td>\n",
       "      <td>[0.0, 1.0, 3.0, 5.0, 2.0, nan, 6.0, 13.0, 4.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNT_DRAWINGS_CURRENT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>129</td>\n",
       "      <td>int64</td>\n",
       "      <td>165/0</td>\n",
       "      <td>0.703144</td>\n",
       "      <td>3.190347</td>\n",
       "      <td>10.635288</td>\n",
       "      <td>[1, 0, 8, 9, 5, 2, 30, 3, 4, 7, 14, 38, 12, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNT_DRAWINGS_OTHER_CURRENT</th>\n",
       "      <td>749816</td>\n",
       "      <td>19.525</td>\n",
       "      <td>12</td>\n",
       "      <td>float64</td>\n",
       "      <td>12.0/0.0</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.082639</td>\n",
       "      <td>26.323819</td>\n",
       "      <td>[0.0, 1.0, nan, 3.0, 2.0, 4.0, 6.0, 5.0, 7.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNT_DRAWINGS_POS_CURRENT</th>\n",
       "      <td>749816</td>\n",
       "      <td>19.525</td>\n",
       "      <td>134</td>\n",
       "      <td>float64</td>\n",
       "      <td>165.0/0.0</td>\n",
       "      <td>0.559479</td>\n",
       "      <td>3.240649</td>\n",
       "      <td>11.352616</td>\n",
       "      <td>[1.0, 0.0, 5.0, 6.0, 29.0, 4.0, 8.0, 2.0, nan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNT_INSTALMENT_MATURE_CUM</th>\n",
       "      <td>305236</td>\n",
       "      <td>7.948</td>\n",
       "      <td>122</td>\n",
       "      <td>float64</td>\n",
       "      <td>120.0/0.0</td>\n",
       "      <td>20.825084</td>\n",
       "      <td>20.051494</td>\n",
       "      <td>1.075588</td>\n",
       "      <td>[35.0, 69.0, 30.0, 10.0, 101.0, 2.0, 6.0, 51.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_CONTRACT_STATUS</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Active, Completed, Demand, Signed, Sent propo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_DPD</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>917</td>\n",
       "      <td>int64</td>\n",
       "      <td>3260/0</td>\n",
       "      <td>9.283667</td>\n",
       "      <td>97.5157</td>\n",
       "      <td>12.94699</td>\n",
       "      <td>[0, 7, 2192, 717, 28, 18, 1676, 1706, 1311, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_DPD_DEF</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>378</td>\n",
       "      <td>int64</td>\n",
       "      <td>3260/0</td>\n",
       "      <td>0.331622</td>\n",
       "      <td>21.479231</td>\n",
       "      <td>89.830434</td>\n",
       "      <td>[0, 7, 99, 1, 701, 8, 5, 63, 31, 1158, 1007, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Null  %_Null  Unique_Count Data_type  \\\n",
       "SK_ID_PREV                       0   0.000        104307     int64   \n",
       "SK_ID_CURR                       0   0.000        103558     int64   \n",
       "MONTHS_BALANCE                   0   0.000            96     int64   \n",
       "AMT_BALANCE                      0   0.000       1347904   float64   \n",
       "AMT_CREDIT_LIMIT_ACTUAL          0   0.000           181     int64   \n",
       "AMT_DRAWINGS_ATM_CURRENT    749816  19.525          2268   float64   \n",
       "AMT_DRAWINGS_CURRENT             0   0.000        187005   float64   \n",
       "AMT_DRAWINGS_OTHER_CURRENT  749816  19.525          1833   float64   \n",
       "AMT_DRAWINGS_POS_CURRENT    749816  19.525        168749   float64   \n",
       "AMT_INST_MIN_REGULARITY     305236   7.948        312267   float64   \n",
       "AMT_PAYMENT_CURRENT         767988  19.998        163210   float64   \n",
       "AMT_PAYMENT_TOTAL_CURRENT        0   0.000        182957   float64   \n",
       "AMT_RECEIVABLE_PRINCIPAL         0   0.000       1195839   float64   \n",
       "AMT_RECIVABLE                    0   0.000       1338878   float64   \n",
       "AMT_TOTAL_RECEIVABLE             0   0.000       1339008   float64   \n",
       "CNT_DRAWINGS_ATM_CURRENT    749816  19.525            45   float64   \n",
       "CNT_DRAWINGS_CURRENT             0   0.000           129     int64   \n",
       "CNT_DRAWINGS_OTHER_CURRENT  749816  19.525            12   float64   \n",
       "CNT_DRAWINGS_POS_CURRENT    749816  19.525           134   float64   \n",
       "CNT_INSTALMENT_MATURE_CUM   305236   7.948           122   float64   \n",
       "NAME_CONTRACT_STATUS             0   0.000             7    object   \n",
       "SK_DPD                           0   0.000           917     int64   \n",
       "SK_DPD_DEF                       0   0.000           378     int64   \n",
       "\n",
       "                                          Max/Min           Mean  \\\n",
       "SK_ID_PREV                        2843496/1000018   1904503.5899   \n",
       "SK_ID_CURR                          456250/100006  278324.207289   \n",
       "MONTHS_BALANCE                             -1/-96     -34.521921   \n",
       "AMT_BALANCE                 1505902.19/-420250.18   58300.155262   \n",
       "AMT_CREDIT_LIMIT_ACTUAL                 1350000/0    153807.9574   \n",
       "AMT_DRAWINGS_ATM_CURRENT       2115000.0/-6827.31    5961.324822   \n",
       "AMT_DRAWINGS_CURRENT          2287098.31/-6211.62    7433.388179   \n",
       "AMT_DRAWINGS_OTHER_CURRENT          1529847.0/0.0     288.169582   \n",
       "AMT_DRAWINGS_POS_CURRENT           2239274.16/0.0    2968.804848   \n",
       "AMT_INST_MIN_REGULARITY             202882.01/0.0    3540.204129   \n",
       "AMT_PAYMENT_CURRENT                4289207.45/0.0   10280.537702   \n",
       "AMT_PAYMENT_TOTAL_CURRENT          4278315.69/0.0    7588.856739   \n",
       "AMT_RECEIVABLE_PRINCIPAL    1472316.79/-423305.82   55965.876905   \n",
       "AMT_RECIVABLE               1493338.19/-420250.18   58088.811177   \n",
       "AMT_TOTAL_RECEIVABLE        1493338.19/-420250.18   58098.285489   \n",
       "CNT_DRAWINGS_ATM_CURRENT                 51.0/0.0       0.309449   \n",
       "CNT_DRAWINGS_CURRENT                        165/0       0.703144   \n",
       "CNT_DRAWINGS_OTHER_CURRENT               12.0/0.0       0.004812   \n",
       "CNT_DRAWINGS_POS_CURRENT                165.0/0.0       0.559479   \n",
       "CNT_INSTALMENT_MATURE_CUM               120.0/0.0      20.825084   \n",
       "NAME_CONTRACT_STATUS                            -              -   \n",
       "SK_DPD                                     3260/0       9.283667   \n",
       "SK_DPD_DEF                                 3260/0       0.331622   \n",
       "\n",
       "                                      Std   Skewness  \\\n",
       "SK_ID_PREV                  536469.470563   0.038385   \n",
       "SK_ID_CURR                  102704.475133  -0.001834   \n",
       "MONTHS_BALANCE                  26.667751   -0.59804   \n",
       "AMT_BALANCE                 106307.031025   2.920173   \n",
       "AMT_CREDIT_LIMIT_ACTUAL     165145.699523   2.059732   \n",
       "AMT_DRAWINGS_ATM_CURRENT     28225.688579   9.664842   \n",
       "AMT_DRAWINGS_CURRENT         33846.077334  10.065626   \n",
       "AMT_DRAWINGS_OTHER_CURRENT    8201.989345   50.57035   \n",
       "AMT_DRAWINGS_POS_CURRENT     20796.887047  19.421081   \n",
       "AMT_INST_MIN_REGULARITY       5600.154122   2.494431   \n",
       "AMT_PAYMENT_CURRENT          36078.084953  12.990581   \n",
       "AMT_PAYMENT_TOTAL_CURRENT    32005.987768  14.479719   \n",
       "AMT_RECEIVABLE_PRINCIPAL    102533.616843   2.942316   \n",
       "AMT_RECIVABLE               105965.369908   2.913172   \n",
       "AMT_TOTAL_RECEIVABLE        105971.801103   2.912684   \n",
       "CNT_DRAWINGS_ATM_CURRENT         1.100401   6.906655   \n",
       "CNT_DRAWINGS_CURRENT             3.190347  10.635288   \n",
       "CNT_DRAWINGS_OTHER_CURRENT       0.082639  26.323819   \n",
       "CNT_DRAWINGS_POS_CURRENT         3.240649  11.352616   \n",
       "CNT_INSTALMENT_MATURE_CUM       20.051494   1.075588   \n",
       "NAME_CONTRACT_STATUS                    -          -   \n",
       "SK_DPD                            97.5157   12.94699   \n",
       "SK_DPD_DEF                      21.479231  89.830434   \n",
       "\n",
       "                                                                Sample_values  \n",
       "SK_ID_PREV                  [2562384, 2582071, 1740877, 1389973, 1891521, ...  \n",
       "SK_ID_CURR                  [378907, 363914, 371185, 337855, 126868, 38001...  \n",
       "MONTHS_BALANCE              [-6, -1, -7, -4, -5, -3, -2, -19, -13, -18, -1...  \n",
       "AMT_BALANCE                 [56.97, 63975.555, 31815.225, 236572.11, 45391...  \n",
       "AMT_CREDIT_LIMIT_ACTUAL     [135000, 45000, 450000, 225000, 270000, 585000...  \n",
       "AMT_DRAWINGS_ATM_CURRENT    [0.0, 2250.0, 67500.0, 45000.0, 90000.0, 76500...  \n",
       "AMT_DRAWINGS_CURRENT        [877.5, 2250.0, 0.0, 11547.0, 67500.0, 45000.0...  \n",
       "AMT_DRAWINGS_OTHER_CURRENT  [0.0, 137700.0, nan, 177840.0, 46800.0, 187200...  \n",
       "AMT_DRAWINGS_POS_CURRENT    [877.5, 0.0, 11547.0, 199339.425, 34526.7, 968...  \n",
       "AMT_INST_MIN_REGULARITY     [1700.325, 2250.0, 11795.76, 22924.89, 4449.10...  \n",
       "AMT_PAYMENT_CURRENT         [1800.0, 2250.0, 11925.0, 27000.0, 3825.0, 157...  \n",
       "AMT_PAYMENT_TOTAL_CURRENT   [1800.0, 2250.0, 11925.0, 27000.0, 3825.0, 157...  \n",
       "AMT_RECEIVABLE_PRINCIPAL    [0.0, 60175.08, 26926.425, 224949.285, 443044....  \n",
       "AMT_RECIVABLE               [0.0, 64875.555, 31460.085, 233048.97, 453919....  \n",
       "AMT_TOTAL_RECEIVABLE        [0.0, 64875.555, 31460.085, 233048.97, 453919....  \n",
       "CNT_DRAWINGS_ATM_CURRENT    [0.0, 1.0, 3.0, 5.0, 2.0, nan, 6.0, 13.0, 4.0,...  \n",
       "CNT_DRAWINGS_CURRENT        [1, 0, 8, 9, 5, 2, 30, 3, 4, 7, 14, 38, 12, 19...  \n",
       "CNT_DRAWINGS_OTHER_CURRENT  [0.0, 1.0, nan, 3.0, 2.0, 4.0, 6.0, 5.0, 7.0, ...  \n",
       "CNT_DRAWINGS_POS_CURRENT    [1.0, 0.0, 5.0, 6.0, 29.0, 4.0, 8.0, 2.0, nan,...  \n",
       "CNT_INSTALMENT_MATURE_CUM   [35.0, 69.0, 30.0, 10.0, 101.0, 2.0, 6.0, 51.0...  \n",
       "NAME_CONTRACT_STATUS        [Active, Completed, Demand, Signed, Sent propo...  \n",
       "SK_DPD                      [0, 7, 2192, 717, 28, 18, 1676, 1706, 1311, 11...  \n",
       "SK_DPD_DEF                  [0, 7, 99, 1, 701, 8, 5, 63, 31, 1158, 1007, 6...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Table under consideration: INSTALLMENTS_PAYMENTS\n",
      "------------------------------------------------------------------------\n",
      "DataFrame shape\n",
      "Rows: 13605401\n",
      "Cols: 8\n",
      "------------------------------------------------------------------------\n",
      "Table Statistics\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null</th>\n",
       "      <th>%_Null</th>\n",
       "      <th>Unique_Count</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Max/Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>997752</td>\n",
       "      <td>int64</td>\n",
       "      <td>2843499/1000001</td>\n",
       "      <td>1.903365e+06</td>\n",
       "      <td>536202.905546</td>\n",
       "      <td>0.042510</td>\n",
       "      <td>[1054186, 1330831, 2085231, 2452527, 2714724, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>339587</td>\n",
       "      <td>int64</td>\n",
       "      <td>456255/100001</td>\n",
       "      <td>2.784449e+05</td>\n",
       "      <td>102718.310411</td>\n",
       "      <td>-0.003354</td>\n",
       "      <td>[161674, 151639, 193053, 199697, 167756, 16448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM_INSTALMENT_VERSION</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>65</td>\n",
       "      <td>float64</td>\n",
       "      <td>178.0/0.0</td>\n",
       "      <td>8.566373e-01</td>\n",
       "      <td>1.035216</td>\n",
       "      <td>9.593395</td>\n",
       "      <td>[1.0, 0.0, 2.0, 4.0, 3.0, 5.0, 7.0, 8.0, 6.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM_INSTALMENT_NUMBER</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>277</td>\n",
       "      <td>int64</td>\n",
       "      <td>277/1</td>\n",
       "      <td>1.887090e+01</td>\n",
       "      <td>26.664067</td>\n",
       "      <td>2.497597</td>\n",
       "      <td>[6, 34, 1, 3, 2, 12, 11, 4, 14, 8, 20, 56, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_INSTALMENT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2922</td>\n",
       "      <td>float64</td>\n",
       "      <td>-1.0/-2922.0</td>\n",
       "      <td>-1.042270e+03</td>\n",
       "      <td>800.946284</td>\n",
       "      <td>-0.628704</td>\n",
       "      <td>[-1180.0, -2156.0, -63.0, -2418.0, -1383.0, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_ENTRY_PAYMENT</th>\n",
       "      <td>2905</td>\n",
       "      <td>0.021</td>\n",
       "      <td>3040</td>\n",
       "      <td>float64</td>\n",
       "      <td>-1.0/-4921.0</td>\n",
       "      <td>-1.051114e+03</td>\n",
       "      <td>800.585883</td>\n",
       "      <td>-0.626889</td>\n",
       "      <td>[-1187.0, -2156.0, -63.0, -2426.0, -1366.0, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_INSTALMENT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>902539</td>\n",
       "      <td>float64</td>\n",
       "      <td>3771487.85/0.0</td>\n",
       "      <td>1.705091e+04</td>\n",
       "      <td>50570.254429</td>\n",
       "      <td>16.235905</td>\n",
       "      <td>[6948.36, 1716.525, 25425.0, 24350.13, 2165.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_PAYMENT</th>\n",
       "      <td>2905</td>\n",
       "      <td>0.021</td>\n",
       "      <td>944236</td>\n",
       "      <td>float64</td>\n",
       "      <td>3771487.85/0.0</td>\n",
       "      <td>1.723822e+04</td>\n",
       "      <td>54735.783981</td>\n",
       "      <td>14.951925</td>\n",
       "      <td>[6948.36, 1716.525, 25425.0, 24350.13, 2160.58...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Null  %_Null  Unique_Count Data_type          Max/Min  \\\n",
       "SK_ID_PREV                 0   0.000        997752     int64  2843499/1000001   \n",
       "SK_ID_CURR                 0   0.000        339587     int64    456255/100001   \n",
       "NUM_INSTALMENT_VERSION     0   0.000            65   float64        178.0/0.0   \n",
       "NUM_INSTALMENT_NUMBER      0   0.000           277     int64            277/1   \n",
       "DAYS_INSTALMENT            0   0.000          2922   float64     -1.0/-2922.0   \n",
       "DAYS_ENTRY_PAYMENT      2905   0.021          3040   float64     -1.0/-4921.0   \n",
       "AMT_INSTALMENT             0   0.000        902539   float64   3771487.85/0.0   \n",
       "AMT_PAYMENT             2905   0.021        944236   float64   3771487.85/0.0   \n",
       "\n",
       "                                Mean            Std   Skewness  \\\n",
       "SK_ID_PREV              1.903365e+06  536202.905546   0.042510   \n",
       "SK_ID_CURR              2.784449e+05  102718.310411  -0.003354   \n",
       "NUM_INSTALMENT_VERSION  8.566373e-01       1.035216   9.593395   \n",
       "NUM_INSTALMENT_NUMBER   1.887090e+01      26.664067   2.497597   \n",
       "DAYS_INSTALMENT        -1.042270e+03     800.946284  -0.628704   \n",
       "DAYS_ENTRY_PAYMENT     -1.051114e+03     800.585883  -0.626889   \n",
       "AMT_INSTALMENT          1.705091e+04   50570.254429  16.235905   \n",
       "AMT_PAYMENT             1.723822e+04   54735.783981  14.951925   \n",
       "\n",
       "                                                            Sample_values  \n",
       "SK_ID_PREV              [1054186, 1330831, 2085231, 2452527, 2714724, ...  \n",
       "SK_ID_CURR              [161674, 151639, 193053, 199697, 167756, 16448...  \n",
       "NUM_INSTALMENT_VERSION  [1.0, 0.0, 2.0, 4.0, 3.0, 5.0, 7.0, 8.0, 6.0, ...  \n",
       "NUM_INSTALMENT_NUMBER   [6, 34, 1, 3, 2, 12, 11, 4, 14, 8, 20, 56, 7, ...  \n",
       "DAYS_INSTALMENT         [-1180.0, -2156.0, -63.0, -2418.0, -1383.0, -1...  \n",
       "DAYS_ENTRY_PAYMENT      [-1187.0, -2156.0, -63.0, -2426.0, -1366.0, -1...  \n",
       "AMT_INSTALMENT          [6948.36, 1716.525, 25425.0, 24350.13, 2165.04...  \n",
       "AMT_PAYMENT             [6948.36, 1716.525, 25425.0, 24350.13, 2160.58...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Table under consideration: PREVIOUS_APPLICATION\n",
      "------------------------------------------------------------------------\n",
      "DataFrame shape\n",
      "Rows: 1670214\n",
      "Cols: 37\n",
      "------------------------------------------------------------------------\n",
      "Table Statistics\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null</th>\n",
       "      <th>%_Null</th>\n",
       "      <th>Unique_Count</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Max/Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1670214</td>\n",
       "      <td>int64</td>\n",
       "      <td>2845382/1000001</td>\n",
       "      <td>1923089.135331</td>\n",
       "      <td>532597.958696</td>\n",
       "      <td>-0.000573</td>\n",
       "      <td>[2030495, 2802425, 2523466, 2819243, 1784265, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>338857</td>\n",
       "      <td>int64</td>\n",
       "      <td>456255/100001</td>\n",
       "      <td>278357.174099</td>\n",
       "      <td>102814.823849</td>\n",
       "      <td>-0.003303</td>\n",
       "      <td>[271877, 108129, 122040, 176158, 202054, 19938...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Consumer loans, Cash loans, Revolving loans, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <td>372235</td>\n",
       "      <td>22.287</td>\n",
       "      <td>357960</td>\n",
       "      <td>float64</td>\n",
       "      <td>418058.15/0.0</td>\n",
       "      <td>15955.120659</td>\n",
       "      <td>14782.137335</td>\n",
       "      <td>2.692572</td>\n",
       "      <td>[1730.43, 25188.615, 15060.735, 47041.335, 319...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_APPLICATION</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>93885</td>\n",
       "      <td>float64</td>\n",
       "      <td>6905160.0/0.0</td>\n",
       "      <td>175233.86036</td>\n",
       "      <td>292779.762387</td>\n",
       "      <td>3.391442</td>\n",
       "      <td>[17145.0, 607500.0, 112500.0, 450000.0, 337500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>86804</td>\n",
       "      <td>float64</td>\n",
       "      <td>6905160.0/0.0</td>\n",
       "      <td>196114.021218</td>\n",
       "      <td>318574.616546</td>\n",
       "      <td>3.245815</td>\n",
       "      <td>[17145.0, 679671.0, 136444.5, 470790.0, 404055...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_DOWN_PAYMENT</th>\n",
       "      <td>895844</td>\n",
       "      <td>53.636</td>\n",
       "      <td>29279</td>\n",
       "      <td>float64</td>\n",
       "      <td>3060045.0/-0.9</td>\n",
       "      <td>6697.402139</td>\n",
       "      <td>20921.49541</td>\n",
       "      <td>36.476576</td>\n",
       "      <td>[0.0, nan, 12649.5, 1350.0, 9000.0, 13500.0, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <td>385515</td>\n",
       "      <td>23.082</td>\n",
       "      <td>93886</td>\n",
       "      <td>float64</td>\n",
       "      <td>6905160.0/0.0</td>\n",
       "      <td>227847.279283</td>\n",
       "      <td>315396.557937</td>\n",
       "      <td>3.07369</td>\n",
       "      <td>[17145.0, 607500.0, 112500.0, 450000.0, 337500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[SATURDAY, THURSDAY, TUESDAY, MONDAY, FRIDAY, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUR_APPR_PROCESS_START</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24</td>\n",
       "      <td>int64</td>\n",
       "      <td>23/0</td>\n",
       "      <td>12.484182</td>\n",
       "      <td>3.334028</td>\n",
       "      <td>-0.025629</td>\n",
       "      <td>[15, 11, 7, 9, 8, 10, 12, 13, 14, 16, 6, 4, 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLAG_LAST_APPL_PER_CONTRACT</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Y, N]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLAG_LAST_APPL_IN_DAY</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>int64</td>\n",
       "      <td>1/0</td>\n",
       "      <td>0.996468</td>\n",
       "      <td>0.05933</td>\n",
       "      <td>-16.735924</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RATE_DOWN_PAYMENT</th>\n",
       "      <td>895844</td>\n",
       "      <td>53.636</td>\n",
       "      <td>207034</td>\n",
       "      <td>float64</td>\n",
       "      <td>1.0/-0.0</td>\n",
       "      <td>0.079637</td>\n",
       "      <td>0.107823</td>\n",
       "      <td>2.107713</td>\n",
       "      <td>[0.0, nan, 0.1039712869911545, 0.0513237940193...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RATE_INTEREST_PRIMARY</th>\n",
       "      <td>1664263</td>\n",
       "      <td>99.644</td>\n",
       "      <td>149</td>\n",
       "      <td>float64</td>\n",
       "      <td>1.0/0.03</td>\n",
       "      <td>0.188357</td>\n",
       "      <td>0.087671</td>\n",
       "      <td>5.198204</td>\n",
       "      <td>[0.1828318032415278, nan, 0.1969143148588915, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RATE_INTEREST_PRIVILEGED</th>\n",
       "      <td>1664263</td>\n",
       "      <td>99.644</td>\n",
       "      <td>26</td>\n",
       "      <td>float64</td>\n",
       "      <td>1.0/0.37</td>\n",
       "      <td>0.773503</td>\n",
       "      <td>0.100879</td>\n",
       "      <td>-1.00768</td>\n",
       "      <td>[0.8673361522198731, nan, 0.8350951374207188, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_CASH_LOAN_PURPOSE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[XAP, XNA, Repairs, Everyday expenses, Car rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_CONTRACT_STATUS</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Approved, Refused, Canceled, Unused offer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_DECISION</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2922</td>\n",
       "      <td>int64</td>\n",
       "      <td>-1/-2922</td>\n",
       "      <td>-880.679668</td>\n",
       "      <td>779.099667</td>\n",
       "      <td>-1.05308</td>\n",
       "      <td>[-73, -164, -301, -512, -781, -684, -14, -21, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_PAYMENT_TYPE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Cash through the bank, XNA, Non-cash from you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CODE_REJECT_REASON</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[XAP, HC, LIMIT, CLIENT, SCOFR, SCO, XNA, VERI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <td>820405</td>\n",
       "      <td>49.120</td>\n",
       "      <td>8</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[nan, Unaccompanied, Spouse, partner, Family, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_CLIENT_TYPE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Repeater, New, Refreshed, XNA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_GOODS_CATEGORY</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Mobile, XNA, Consumer Electronics, Constructi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_PORTFOLIO</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[POS, Cash, XNA, Cards, Cars]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_PRODUCT_TYPE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[XNA, x-sell, walk-in]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHANNEL_TYPE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Country-wide, Contact center, Credit and cash...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELLERPLACE_AREA</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2097</td>\n",
       "      <td>int64</td>\n",
       "      <td>4000000/-1</td>\n",
       "      <td>313.951115</td>\n",
       "      <td>7127.443459</td>\n",
       "      <td>529.620279</td>\n",
       "      <td>[35, -1, 200, 83, 130, 6, 61, 20, 50, 136, 40,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_SELLER_INDUSTRY</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Connectivity, XNA, Consumer electronics, Indu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNT_PAYMENT</th>\n",
       "      <td>372230</td>\n",
       "      <td>22.286</td>\n",
       "      <td>50</td>\n",
       "      <td>float64</td>\n",
       "      <td>84.0/0.0</td>\n",
       "      <td>16.054082</td>\n",
       "      <td>14.567288</td>\n",
       "      <td>1.531403</td>\n",
       "      <td>[12.0, 36.0, 24.0, 18.0, nan, 54.0, 30.0, 8.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_YIELD_GROUP</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[middle, low_action, high, low_normal, XNA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRODUCT_COMBINATION</th>\n",
       "      <td>346</td>\n",
       "      <td>0.021</td>\n",
       "      <td>18</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[POS mobile with interest, Cash X-Sell: low, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_FIRST_DRAWING</th>\n",
       "      <td>673065</td>\n",
       "      <td>40.298</td>\n",
       "      <td>2839</td>\n",
       "      <td>float64</td>\n",
       "      <td>365243.0/-2922.0</td>\n",
       "      <td>342209.855039</td>\n",
       "      <td>88916.115834</td>\n",
       "      <td>-3.601343</td>\n",
       "      <td>[365243.0, nan, -277.0, -265.0, -479.0, -332.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_FIRST_DUE</th>\n",
       "      <td>673065</td>\n",
       "      <td>40.298</td>\n",
       "      <td>2893</td>\n",
       "      <td>float64</td>\n",
       "      <td>365243.0/-2892.0</td>\n",
       "      <td>13826.269337</td>\n",
       "      <td>72444.869708</td>\n",
       "      <td>4.644096</td>\n",
       "      <td>[-42.0, -134.0, -271.0, -482.0, nan, -654.0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_LAST_DUE_1ST_VERSION</th>\n",
       "      <td>673065</td>\n",
       "      <td>40.298</td>\n",
       "      <td>4606</td>\n",
       "      <td>float64</td>\n",
       "      <td>365243.0/-2801.0</td>\n",
       "      <td>33767.774054</td>\n",
       "      <td>106857.034789</td>\n",
       "      <td>2.77945</td>\n",
       "      <td>[300.0, 916.0, 59.0, -152.0, nan, -144.0, 885....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_LAST_DUE</th>\n",
       "      <td>673065</td>\n",
       "      <td>40.298</td>\n",
       "      <td>2874</td>\n",
       "      <td>float64</td>\n",
       "      <td>365243.0/-2889.0</td>\n",
       "      <td>76582.403064</td>\n",
       "      <td>149647.415123</td>\n",
       "      <td>1.410473</td>\n",
       "      <td>[-42.0, 365243.0, -182.0, nan, -144.0, -345.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_TERMINATION</th>\n",
       "      <td>673065</td>\n",
       "      <td>40.298</td>\n",
       "      <td>2831</td>\n",
       "      <td>float64</td>\n",
       "      <td>365243.0/-2874.0</td>\n",
       "      <td>81992.343838</td>\n",
       "      <td>153303.516729</td>\n",
       "      <td>1.306376</td>\n",
       "      <td>[-37.0, 365243.0, -177.0, nan, -137.0, -334.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLAG_INSURED_ON_APPROVAL</th>\n",
       "      <td>673065</td>\n",
       "      <td>40.298</td>\n",
       "      <td>3</td>\n",
       "      <td>float64</td>\n",
       "      <td>1.0/0.0</td>\n",
       "      <td>0.33257</td>\n",
       "      <td>0.471134</td>\n",
       "      <td>0.710754</td>\n",
       "      <td>[0.0, 1.0, nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Null  %_Null  Unique_Count Data_type  \\\n",
       "SK_ID_PREV                         0   0.000       1670214     int64   \n",
       "SK_ID_CURR                         0   0.000        338857     int64   \n",
       "NAME_CONTRACT_TYPE                 0   0.000             4    object   \n",
       "AMT_ANNUITY                   372235  22.287        357960   float64   \n",
       "AMT_APPLICATION                    0   0.000         93885   float64   \n",
       "AMT_CREDIT                         1   0.000         86804   float64   \n",
       "AMT_DOWN_PAYMENT              895844  53.636         29279   float64   \n",
       "AMT_GOODS_PRICE               385515  23.082         93886   float64   \n",
       "WEEKDAY_APPR_PROCESS_START         0   0.000             7    object   \n",
       "HOUR_APPR_PROCESS_START            0   0.000            24     int64   \n",
       "FLAG_LAST_APPL_PER_CONTRACT        0   0.000             2    object   \n",
       "NFLAG_LAST_APPL_IN_DAY             0   0.000             2     int64   \n",
       "RATE_DOWN_PAYMENT             895844  53.636        207034   float64   \n",
       "RATE_INTEREST_PRIMARY        1664263  99.644           149   float64   \n",
       "RATE_INTEREST_PRIVILEGED     1664263  99.644            26   float64   \n",
       "NAME_CASH_LOAN_PURPOSE             0   0.000            25    object   \n",
       "NAME_CONTRACT_STATUS               0   0.000             4    object   \n",
       "DAYS_DECISION                      0   0.000          2922     int64   \n",
       "NAME_PAYMENT_TYPE                  0   0.000             4    object   \n",
       "CODE_REJECT_REASON                 0   0.000             9    object   \n",
       "NAME_TYPE_SUITE               820405  49.120             8    object   \n",
       "NAME_CLIENT_TYPE                   0   0.000             4    object   \n",
       "NAME_GOODS_CATEGORY                0   0.000            28    object   \n",
       "NAME_PORTFOLIO                     0   0.000             5    object   \n",
       "NAME_PRODUCT_TYPE                  0   0.000             3    object   \n",
       "CHANNEL_TYPE                       0   0.000             8    object   \n",
       "SELLERPLACE_AREA                   0   0.000          2097     int64   \n",
       "NAME_SELLER_INDUSTRY               0   0.000            11    object   \n",
       "CNT_PAYMENT                   372230  22.286            50   float64   \n",
       "NAME_YIELD_GROUP                   0   0.000             5    object   \n",
       "PRODUCT_COMBINATION              346   0.021            18    object   \n",
       "DAYS_FIRST_DRAWING            673065  40.298          2839   float64   \n",
       "DAYS_FIRST_DUE                673065  40.298          2893   float64   \n",
       "DAYS_LAST_DUE_1ST_VERSION     673065  40.298          4606   float64   \n",
       "DAYS_LAST_DUE                 673065  40.298          2874   float64   \n",
       "DAYS_TERMINATION              673065  40.298          2831   float64   \n",
       "NFLAG_INSURED_ON_APPROVAL     673065  40.298             3   float64   \n",
       "\n",
       "                                      Max/Min            Mean            Std  \\\n",
       "SK_ID_PREV                    2845382/1000001  1923089.135331  532597.958696   \n",
       "SK_ID_CURR                      456255/100001   278357.174099  102814.823849   \n",
       "NAME_CONTRACT_TYPE                          -               -              -   \n",
       "AMT_ANNUITY                     418058.15/0.0    15955.120659   14782.137335   \n",
       "AMT_APPLICATION                 6905160.0/0.0    175233.86036  292779.762387   \n",
       "AMT_CREDIT                      6905160.0/0.0   196114.021218  318574.616546   \n",
       "AMT_DOWN_PAYMENT               3060045.0/-0.9     6697.402139    20921.49541   \n",
       "AMT_GOODS_PRICE                 6905160.0/0.0   227847.279283  315396.557937   \n",
       "WEEKDAY_APPR_PROCESS_START                  -               -              -   \n",
       "HOUR_APPR_PROCESS_START                  23/0       12.484182       3.334028   \n",
       "FLAG_LAST_APPL_PER_CONTRACT                 -               -              -   \n",
       "NFLAG_LAST_APPL_IN_DAY                    1/0        0.996468        0.05933   \n",
       "RATE_DOWN_PAYMENT                    1.0/-0.0        0.079637       0.107823   \n",
       "RATE_INTEREST_PRIMARY                1.0/0.03        0.188357       0.087671   \n",
       "RATE_INTEREST_PRIVILEGED             1.0/0.37        0.773503       0.100879   \n",
       "NAME_CASH_LOAN_PURPOSE                      -               -              -   \n",
       "NAME_CONTRACT_STATUS                        -               -              -   \n",
       "DAYS_DECISION                        -1/-2922     -880.679668     779.099667   \n",
       "NAME_PAYMENT_TYPE                           -               -              -   \n",
       "CODE_REJECT_REASON                          -               -              -   \n",
       "NAME_TYPE_SUITE                             -               -              -   \n",
       "NAME_CLIENT_TYPE                            -               -              -   \n",
       "NAME_GOODS_CATEGORY                         -               -              -   \n",
       "NAME_PORTFOLIO                              -               -              -   \n",
       "NAME_PRODUCT_TYPE                           -               -              -   \n",
       "CHANNEL_TYPE                                -               -              -   \n",
       "SELLERPLACE_AREA                   4000000/-1      313.951115    7127.443459   \n",
       "NAME_SELLER_INDUSTRY                        -               -              -   \n",
       "CNT_PAYMENT                          84.0/0.0       16.054082      14.567288   \n",
       "NAME_YIELD_GROUP                            -               -              -   \n",
       "PRODUCT_COMBINATION                         -               -              -   \n",
       "DAYS_FIRST_DRAWING           365243.0/-2922.0   342209.855039   88916.115834   \n",
       "DAYS_FIRST_DUE               365243.0/-2892.0    13826.269337   72444.869708   \n",
       "DAYS_LAST_DUE_1ST_VERSION    365243.0/-2801.0    33767.774054  106857.034789   \n",
       "DAYS_LAST_DUE                365243.0/-2889.0    76582.403064  149647.415123   \n",
       "DAYS_TERMINATION             365243.0/-2874.0    81992.343838  153303.516729   \n",
       "NFLAG_INSURED_ON_APPROVAL             1.0/0.0         0.33257       0.471134   \n",
       "\n",
       "                               Skewness  \\\n",
       "SK_ID_PREV                    -0.000573   \n",
       "SK_ID_CURR                    -0.003303   \n",
       "NAME_CONTRACT_TYPE                    -   \n",
       "AMT_ANNUITY                    2.692572   \n",
       "AMT_APPLICATION                3.391442   \n",
       "AMT_CREDIT                     3.245815   \n",
       "AMT_DOWN_PAYMENT              36.476576   \n",
       "AMT_GOODS_PRICE                 3.07369   \n",
       "WEEKDAY_APPR_PROCESS_START            -   \n",
       "HOUR_APPR_PROCESS_START       -0.025629   \n",
       "FLAG_LAST_APPL_PER_CONTRACT           -   \n",
       "NFLAG_LAST_APPL_IN_DAY       -16.735924   \n",
       "RATE_DOWN_PAYMENT              2.107713   \n",
       "RATE_INTEREST_PRIMARY          5.198204   \n",
       "RATE_INTEREST_PRIVILEGED       -1.00768   \n",
       "NAME_CASH_LOAN_PURPOSE                -   \n",
       "NAME_CONTRACT_STATUS                  -   \n",
       "DAYS_DECISION                  -1.05308   \n",
       "NAME_PAYMENT_TYPE                     -   \n",
       "CODE_REJECT_REASON                    -   \n",
       "NAME_TYPE_SUITE                       -   \n",
       "NAME_CLIENT_TYPE                      -   \n",
       "NAME_GOODS_CATEGORY                   -   \n",
       "NAME_PORTFOLIO                        -   \n",
       "NAME_PRODUCT_TYPE                     -   \n",
       "CHANNEL_TYPE                          -   \n",
       "SELLERPLACE_AREA             529.620279   \n",
       "NAME_SELLER_INDUSTRY                  -   \n",
       "CNT_PAYMENT                    1.531403   \n",
       "NAME_YIELD_GROUP                      -   \n",
       "PRODUCT_COMBINATION                   -   \n",
       "DAYS_FIRST_DRAWING            -3.601343   \n",
       "DAYS_FIRST_DUE                 4.644096   \n",
       "DAYS_LAST_DUE_1ST_VERSION       2.77945   \n",
       "DAYS_LAST_DUE                  1.410473   \n",
       "DAYS_TERMINATION               1.306376   \n",
       "NFLAG_INSURED_ON_APPROVAL      0.710754   \n",
       "\n",
       "                                                                 Sample_values  \n",
       "SK_ID_PREV                   [2030495, 2802425, 2523466, 2819243, 1784265, ...  \n",
       "SK_ID_CURR                   [271877, 108129, 122040, 176158, 202054, 19938...  \n",
       "NAME_CONTRACT_TYPE           [Consumer loans, Cash loans, Revolving loans, ...  \n",
       "AMT_ANNUITY                  [1730.43, 25188.615, 15060.735, 47041.335, 319...  \n",
       "AMT_APPLICATION              [17145.0, 607500.0, 112500.0, 450000.0, 337500...  \n",
       "AMT_CREDIT                   [17145.0, 679671.0, 136444.5, 470790.0, 404055...  \n",
       "AMT_DOWN_PAYMENT             [0.0, nan, 12649.5, 1350.0, 9000.0, 13500.0, 4...  \n",
       "AMT_GOODS_PRICE              [17145.0, 607500.0, 112500.0, 450000.0, 337500...  \n",
       "WEEKDAY_APPR_PROCESS_START   [SATURDAY, THURSDAY, TUESDAY, MONDAY, FRIDAY, ...  \n",
       "HOUR_APPR_PROCESS_START      [15, 11, 7, 9, 8, 10, 12, 13, 14, 16, 6, 4, 5,...  \n",
       "FLAG_LAST_APPL_PER_CONTRACT                                             [Y, N]  \n",
       "NFLAG_LAST_APPL_IN_DAY                                                  [1, 0]  \n",
       "RATE_DOWN_PAYMENT            [0.0, nan, 0.1039712869911545, 0.0513237940193...  \n",
       "RATE_INTEREST_PRIMARY        [0.1828318032415278, nan, 0.1969143148588915, ...  \n",
       "RATE_INTEREST_PRIVILEGED     [0.8673361522198731, nan, 0.8350951374207188, ...  \n",
       "NAME_CASH_LOAN_PURPOSE       [XAP, XNA, Repairs, Everyday expenses, Car rep...  \n",
       "NAME_CONTRACT_STATUS               [Approved, Refused, Canceled, Unused offer]  \n",
       "DAYS_DECISION                [-73, -164, -301, -512, -781, -684, -14, -21, ...  \n",
       "NAME_PAYMENT_TYPE            [Cash through the bank, XNA, Non-cash from you...  \n",
       "CODE_REJECT_REASON           [XAP, HC, LIMIT, CLIENT, SCOFR, SCO, XNA, VERI...  \n",
       "NAME_TYPE_SUITE              [nan, Unaccompanied, Spouse, partner, Family, ...  \n",
       "NAME_CLIENT_TYPE                               [Repeater, New, Refreshed, XNA]  \n",
       "NAME_GOODS_CATEGORY          [Mobile, XNA, Consumer Electronics, Constructi...  \n",
       "NAME_PORTFOLIO                                   [POS, Cash, XNA, Cards, Cars]  \n",
       "NAME_PRODUCT_TYPE                                       [XNA, x-sell, walk-in]  \n",
       "CHANNEL_TYPE                 [Country-wide, Contact center, Credit and cash...  \n",
       "SELLERPLACE_AREA             [35, -1, 200, 83, 130, 6, 61, 20, 50, 136, 40,...  \n",
       "NAME_SELLER_INDUSTRY         [Connectivity, XNA, Consumer electronics, Indu...  \n",
       "CNT_PAYMENT                  [12.0, 36.0, 24.0, 18.0, nan, 54.0, 30.0, 8.0,...  \n",
       "NAME_YIELD_GROUP                   [middle, low_action, high, low_normal, XNA]  \n",
       "PRODUCT_COMBINATION          [POS mobile with interest, Cash X-Sell: low, C...  \n",
       "DAYS_FIRST_DRAWING           [365243.0, nan, -277.0, -265.0, -479.0, -332.0...  \n",
       "DAYS_FIRST_DUE               [-42.0, -134.0, -271.0, -482.0, nan, -654.0, -...  \n",
       "DAYS_LAST_DUE_1ST_VERSION    [300.0, 916.0, 59.0, -152.0, nan, -144.0, 885....  \n",
       "DAYS_LAST_DUE                [-42.0, 365243.0, -182.0, nan, -144.0, -345.0,...  \n",
       "DAYS_TERMINATION             [-37.0, 365243.0, -177.0, nan, -137.0, -334.0,...  \n",
       "NFLAG_INSURED_ON_APPROVAL                                      [0.0, 1.0, nan]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Table under consideration: POS_CASH_BALANCE\n",
      "------------------------------------------------------------------------\n",
      "DataFrame shape\n",
      "Rows: 10001358\n",
      "Cols: 8\n",
      "------------------------------------------------------------------------\n",
      "Table Statistics\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null</th>\n",
       "      <th>%_Null</th>\n",
       "      <th>Unique_Count</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Max/Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>936325</td>\n",
       "      <td>int64</td>\n",
       "      <td>2843499/1000001</td>\n",
       "      <td>1903216.598957</td>\n",
       "      <td>535846.530722</td>\n",
       "      <td>0.044229</td>\n",
       "      <td>[1803195, 1715348, 1784872, 1903291, 2341044, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>337252</td>\n",
       "      <td>int64</td>\n",
       "      <td>456255/100001</td>\n",
       "      <td>278403.863306</td>\n",
       "      <td>102763.74509</td>\n",
       "      <td>-0.003128</td>\n",
       "      <td>[182943, 367990, 397406, 269225, 334279, 34216...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>96</td>\n",
       "      <td>int64</td>\n",
       "      <td>-1/-96</td>\n",
       "      <td>-35.012588</td>\n",
       "      <td>26.06657</td>\n",
       "      <td>-0.672777</td>\n",
       "      <td>[-31, -33, -32, -35, -38, -39, -34, -41, -37, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNT_INSTALMENT</th>\n",
       "      <td>26071</td>\n",
       "      <td>0.261</td>\n",
       "      <td>74</td>\n",
       "      <td>float64</td>\n",
       "      <td>92.0/1.0</td>\n",
       "      <td>17.08965</td>\n",
       "      <td>11.995056</td>\n",
       "      <td>1.601734</td>\n",
       "      <td>[48.0, 36.0, 12.0, 24.0, 60.0, 18.0, 4.0, 42.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNT_INSTALMENT_FUTURE</th>\n",
       "      <td>26087</td>\n",
       "      <td>0.261</td>\n",
       "      <td>80</td>\n",
       "      <td>float64</td>\n",
       "      <td>85.0/0.0</td>\n",
       "      <td>10.48384</td>\n",
       "      <td>11.109058</td>\n",
       "      <td>1.846746</td>\n",
       "      <td>[45.0, 35.0, 9.0, 42.0, 12.0, 43.0, 36.0, 16.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_CONTRACT_STATUS</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9</td>\n",
       "      <td>object</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[Active, Completed, Signed, Approved, Returned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_DPD</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3400</td>\n",
       "      <td>int64</td>\n",
       "      <td>4231/0</td>\n",
       "      <td>11.606928</td>\n",
       "      <td>132.714043</td>\n",
       "      <td>14.899126</td>\n",
       "      <td>[0, 1, 2, 4, 3, 18, 7, 5, 12, 6, 8, 13, 16, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK_DPD_DEF</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2307</td>\n",
       "      <td>int64</td>\n",
       "      <td>3595/0</td>\n",
       "      <td>0.654468</td>\n",
       "      <td>32.762491</td>\n",
       "      <td>66.339906</td>\n",
       "      <td>[0, 1, 2, 4, 3, 18, 7, 5, 12, 8, 13, 10, 15, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Null  %_Null  Unique_Count Data_type          Max/Min  \\\n",
       "SK_ID_PREV                 0   0.000        936325     int64  2843499/1000001   \n",
       "SK_ID_CURR                 0   0.000        337252     int64    456255/100001   \n",
       "MONTHS_BALANCE             0   0.000            96     int64           -1/-96   \n",
       "CNT_INSTALMENT         26071   0.261            74   float64         92.0/1.0   \n",
       "CNT_INSTALMENT_FUTURE  26087   0.261            80   float64         85.0/0.0   \n",
       "NAME_CONTRACT_STATUS       0   0.000             9    object                -   \n",
       "SK_DPD                     0   0.000          3400     int64           4231/0   \n",
       "SK_DPD_DEF                 0   0.000          2307     int64           3595/0   \n",
       "\n",
       "                                 Mean            Std   Skewness  \\\n",
       "SK_ID_PREV             1903216.598957  535846.530722   0.044229   \n",
       "SK_ID_CURR              278403.863306   102763.74509  -0.003128   \n",
       "MONTHS_BALANCE             -35.012588       26.06657  -0.672777   \n",
       "CNT_INSTALMENT               17.08965      11.995056   1.601734   \n",
       "CNT_INSTALMENT_FUTURE        10.48384      11.109058   1.846746   \n",
       "NAME_CONTRACT_STATUS                -              -          -   \n",
       "SK_DPD                      11.606928     132.714043  14.899126   \n",
       "SK_DPD_DEF                   0.654468      32.762491  66.339906   \n",
       "\n",
       "                                                           Sample_values  \n",
       "SK_ID_PREV             [1803195, 1715348, 1784872, 1903291, 2341044, ...  \n",
       "SK_ID_CURR             [182943, 367990, 397406, 269225, 334279, 34216...  \n",
       "MONTHS_BALANCE         [-31, -33, -32, -35, -38, -39, -34, -41, -37, ...  \n",
       "CNT_INSTALMENT         [48.0, 36.0, 12.0, 24.0, 60.0, 18.0, 4.0, 42.0...  \n",
       "CNT_INSTALMENT_FUTURE  [45.0, 35.0, 9.0, 42.0, 12.0, 43.0, 36.0, 16.0...  \n",
       "NAME_CONTRACT_STATUS   [Active, Completed, Signed, Approved, Returned...  \n",
       "SK_DPD                 [0, 1, 2, 4, 3, 18, 7, 5, 12, 6, 8, 13, 16, 10...  \n",
       "SK_DPD_DEF             [0, 1, 2, 4, 3, 18, 7, 5, 12, 8, 13, 10, 15, 6...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,ds_name in enumerate(datasets.keys()):\n",
    "    print(\"Table under consideration:\",ds_name.upper())\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    ds = feature_summary(datasets[ds_name])\n",
    "    print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction based on Type\n",
    "\n",
    "\n",
    "__Function id_num_cat_feature:__\n",
    "\n",
    "This function will take a dataframe as input and return 4 lists that contain ID columns, numerical features, categorical features, and numerical features without the ID cols. \n",
    "\n",
    "Function name: id_num_cat_feature\n",
    "Input : Dataframe\n",
    "Output : 4 Lists\n",
    "\n",
    "Function output:\n",
    "1. ID columns\n",
    "2. Numerical features\n",
    "3. Categorical features\n",
    "4. Numerical features excluding the ID columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function gives us mutiple lists of the column types which are then used in other functions. The function returns clear separations on what columns are categorical and numerical. By having the distinctive categorical columns and numerical columns lists, different transformations are performed on them based on if they are categorical or numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_num_cat_feature(df,text = True):\n",
    "    numerical = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical = df.select_dtypes(include=['object', 'bool']).columns\n",
    "    feat_num = list(numerical)\n",
    "    feat_cat = list(categorical)\n",
    "    \n",
    "    id_cols = ['SK_ID_CURR','SK_ID_BUREAU']\n",
    "    \n",
    "    id_cols = [cols for cols in  list(df.columns.intersection(id_cols))] \n",
    "    features = list(set(df.columns) - set(id_cols))\n",
    "\n",
    "    if text == True:\n",
    "          # print eda\n",
    "        print('--------')\n",
    "        print(f\"# of ID's: {len(id_cols)}\")\n",
    "        print(f\" ID's:\")\n",
    "        print(id_cols)\n",
    "        print('')\n",
    "        print('--------')\n",
    "        print(f\"# All features: {len(features)}\")\n",
    "        print(f\"All features:\")\n",
    "        print(features)\n",
    "        print('')\n",
    "        print(f\"Missing data:\")\n",
    "        print(missing_data(df[features]))\n",
    "        print('')\n",
    "        print('--------')\n",
    "        print(f\"# of Numerical features: {len(feat_num)}\")\n",
    "        print(f\"Numerical features:\")\n",
    "        print(feat_num)\n",
    "        print('')\n",
    "        print(f\"Numerical Statistical Summary:\")\n",
    "        print('')\n",
    "        print(df[feat_num].describe())\n",
    "        print('')\n",
    "        print('--------')\n",
    "        print(f\"# of Categorical features: {len(feat_cat)}\")\n",
    "        print(f\"Categorical features:\")\n",
    "        print(feat_cat)\n",
    "        print('')\n",
    "        print(f\"Categorical Statistical Summary:\")\n",
    "        print('')\n",
    "        #print(df[feat_cat].describe(include='all'))\n",
    "        print('')\n",
    "        print(\"Categories:\")\n",
    "        print('')\n",
    "        print(df[feat_cat].apply(lambda col: col.unique()))\n",
    "        print('')\n",
    "        print('--------')\n",
    "    return id_cols,feat_num,feat_cat,features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Count and percentage\n",
    "\n",
    "\n",
    "__Function missing_data:__\n",
    "\n",
    "This function will take a dataframe as input and provide null count and % of nulls for a dataframe.\n",
    "\n",
    "Function name: missing_data\n",
    "\n",
    "Input: Dataframe\n",
    "\n",
    "Output: NULL count and NULL %\n",
    "\n",
    "Function output:\n",
    "1. NULL Count\n",
    "2. NULL Percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(data):\n",
    "    total = data.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature Aggregating\n",
    "\n",
    "__Class:__ FeatureSummarizer\n",
    "\n",
    "\n",
    "Class FeatureSummarizer has following aggregation parameters:\n",
    "1. \"min\"\n",
    "2. \"max\"\n",
    "3. \"count\"\n",
    "4. \"sum\"\n",
    "5. \"median\"\n",
    "6. \"mean\"\n",
    "7. \"var\"\n",
    "\n",
    "Based on the keys of the dataframe, transformation function will enable grouping of feature variables on ID and then aggregate the feature variables into their predefined statistical summaries for each grouping.\n",
    "\n",
    "__Function:__ runFeatureSummarizer\n",
    "\n",
    "This function will take dataframe and features as input and using the class above, get aggregated features. The output of the above function will be the transformed aggregated features for the dataframe passed into the function argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSummarizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features=None):\n",
    "        self.features = features\n",
    "        self.agg_ops = [\"min\", \"max\", \"count\", \"sum\", \"median\", \"mean\", \"var\"]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        keys = list(set(X.columns) - set(self.features))\n",
    "        \n",
    "        result = X.groupby(keys, as_index=False).agg({ft:self.agg_ops for ft in self.features}).reset_index()\n",
    "        result.columns = result.columns.map(lambda ct: '_'.join([x for x in ct if x != '']))\n",
    "        result.reset_index()\n",
    "        return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runFeatureSummarizer(df, features):\n",
    "    print(f\"df.shape: {df.shape}\\n\")\n",
    "    print(f\"Aggregated Features:\\ndf[{features}][0:5]: \\n{df[features][0:5]}\")\n",
    "    pipeline = make_pipeline(FeatureSummarizer(features))\n",
    "    return(pipeline.fit_transform(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoded Extract-Transform-Load\n",
    "\n",
    "Function eda_transformation:\n",
    "\n",
    "Function input: Dataframe, n. Where n is a parameter for feature selection. \n",
    "\n",
    "- This function calls id_num_cat_feature to put all features types id columns, numerical features, categorical features, and numerical features excluding id columns into 4 respectively lists.\n",
    "- Categorical variables are one hot encoded into some numerical value, to allow the pipeline to make interpretations from categorical varibles more easily.\n",
    "- run FeatureSummarizer function is called to get all aggregated features. \n",
    "- Final features are selected through feature selection from the transformed tables. \n",
    "- Output of this function will be a dataframe with all aggregated features selected, which will eventually be used in feature selection.\n",
    "- The function will also prints aggregated features and aggregated data. \n",
    "\n",
    "\n",
    "__Feature Selection:__\n",
    "\n",
    "    - Once we have completed OHE, we can remove some attributes which are redundant, for example:\n",
    "    - count of previous application is good to have, but mean,max is not required.\n",
    "    - Features with DAYS, count suffice the aggregated feature, we can remove all other min, max, etc. feature forthat column.\n",
    "    - Based on above logic, we removed certain columns from the supporting tables to remove the redundant attributes and save on execution time. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_transformation(df,n):\n",
    "\n",
    "    id_cols, feat_num, feat_cat, features =  id_num_cat_feature(df)\n",
    "    \n",
    "    df = pd.get_dummies(data=df, columns=feat_cat)\n",
    "\n",
    "    features = list(set(df.columns) - set(id_cols))\n",
    "    feat_ohe = list(set(features) - set(feat_num))\n",
    "\n",
    "    print(f\"# of OHE categorical features: {len(feat_ohe)}\")\n",
    "    print(f\"OHE Categorical features: {feat_ohe}\")\n",
    "    print('--------')\n",
    "\n",
    "    df = runFeatureSummarizer(df, features)\n",
    "    \n",
    "    if n == 0:\n",
    "        # bureau_balance\n",
    "        feature_selection = [\n",
    "            df[id_cols],\n",
    "            df[[column for column in df.columns if column.startswith('MONTHS') and column.endswith('count')]],\n",
    "            df[[column for column in df.columns if column.startswith('STATUS') and column.endswith(('mean', 'median', 'var'))]]\n",
    "        ]\n",
    "    elif n == 1:\n",
    "        # bureau\n",
    "        feature_selection = [\n",
    "            df[[column for column in df.columns if not column.startswith(tuple(feat_cat)) and not column.endswith('count')]],\n",
    "            df[[column for column in df.columns if column.startswith('DAYS_CREDIT') and column.endswith('count')]],\n",
    "            df[[column for column in df.columns if column.startswith(tuple(feat_cat)) and column.endswith(('mean', 'median', 'var'))]]\n",
    "        ]\n",
    "    elif n ==3:\n",
    "        \n",
    "        feature_selection = [\n",
    "            df[[column for column in df.columns if not column.startswith('SK_ID_PREV') and column.startswith(tuple(feat_num))]],\n",
    "            df[[column for column in df.columns if column.startswith('DAYS') and column.endswith('count')]],\n",
    "            df[[column for column in df.columns if column.startswith('SK_ID_PREV') and column.endswith('count')]],\n",
    "            df[[column for column in df.columns if column.startswith(tuple(feat_cat)) and column.endswith(('mean', 'median', 'var'))]]\n",
    "        ]\n",
    "     \n",
    "    elif n ==4:\n",
    "        \n",
    "        feature_selection = [\n",
    "            df[[column for column in df.columns if not column.startswith('SK_ID_PREV') and column.startswith(tuple(feat_num))]],\n",
    "            df[[column for column in df.columns if column.startswith('SK_ID_PREV') and column.endswith('count')]],\n",
    "            df[[column for column in df.columns if column.startswith(tuple(feat_cat)) and column.endswith(('mean', 'median', 'var'))]]\n",
    "        ]\n",
    "    else: \n",
    "        print('ERROR: Invalid feature method. ')\n",
    "\n",
    "    df = pd.concat(feature_selection, axis=1)\n",
    "\n",
    "    features = list(set(df.columns) - set(id_cols))\n",
    "\n",
    "    print('--------')\n",
    "    print('Aggregated Features:')\n",
    "    print('\\n'.join(map(str, sorted(features))))\n",
    "    print('')\n",
    "    print('Aggregated Data:')\n",
    "    print('')\n",
    "    print(df[features].describe().T)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA on Tables\n",
    "\n",
    "Since each table is structured slightly differently and they are all composed of separate variables, It is necessary to perform different steps on each of the tables as necessary. While all the tables can be explored and transformed by the `eda_transformation()` function, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bureau Balance\n",
    "\n",
    "1. This function is specifically for Bureau Balance table. Below are the intial pre-processing steps done before passing this table into the pipeline.\n",
    "    - Since this table has only 2 features, no features are dropped or created for this table. \n",
    "    - Take absolute of the months balance attribute. which was provided as negative values, as it is relative to application date.\n",
    "    - Any column or row with more than 70% of its data as null will be deleted from the dataframe, as the threshold is set to .7.\n",
    "    - Once processed, store the transformed data into a csv file. Benefit of this is that data can be passed ed csv file. directly to model for merging into application train/test table. We do not have to repeatedly perform expensive EDA/ETL/Transformation.\n",
    "    \n",
    "    - Note that this table does not contain SK_ID_CURR. It will be rolled up to Bureau table which contains the SK_ID_CURR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbal_eda(df):\n",
    "    print(\"bureau_bal :: EDA and transformation\")\n",
    "    print('')\n",
    "    bbal = df\n",
    "    #bureau balance table contains all the data so no need to drop any column or row.\n",
    "    #Adding new features, take the abs for the monthly balance attribute.\n",
    "    bbal['MONTHS_BALANCE'] = bbal['MONTHS_BALANCE'].abs()\n",
    "    return (eda_transformation(bbal,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbal = datasets['bureau_balance']\n",
    "bbal = bbal_eda(bbal)\n",
    "datasets_transformed['bureau_balance'] = bbal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bureau\n",
    "\n",
    "1. This function is specifically for Bureau table. Below are the intial pre-processing steps done before passing this table into the pipeline.\n",
    "\n",
    "    - For columns with DAYS in name, there are two with negative values, we will take the absolute for those. \n",
    "    \n",
    "    - Data from Buereau balance table is rolled up in Bureau table befor any EDA. This will enable using all the featues from buereau balance table as well before rolling up all data to main table, i.e. application train. \n",
    "    \n",
    "    - while doing left join, we updated OHE column names to more readale forms by removing any space or spcl charater to \"\\_\" which is widely used in column names. \n",
    "    \n",
    "    - Any column or row with more than 70% of its data as null will be deleted from the dataframe, as the threshold is set to .7.\n",
    "    \n",
    "    - Once processed, store the transformed data into a csv file. Benefit of this is that data can be passed ed csv file. directly to model for merging into application train/test table. We do not have to repeatedly perform expensive EDA/ETL/Transformation.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bureau_eda(df):\n",
    "    bureau = df\n",
    "    drop_list_bureau = []\n",
    "    \n",
    "    #Adding new features\n",
    "    #bureau['MONTHS_BALANCE'] = bureau['MONTHS_BALANCE'].abs()\n",
    "    for c in [co for co in bureau.columns if 'DAYS' in co]:\n",
    "        bureau[c] = bureau[c].replace({365243.0: np.nan})\n",
    "        bureau[c] = bureau[c].abs()\n",
    "    # Drop elements in drop list\n",
    "    threshold = 0.7\n",
    "\n",
    "    #Dropping rows with missing value rate higher than threshold\n",
    "    bureau = bureau.loc[bureau.isnull().mean(axis=1) < threshold]\n",
    "    \n",
    "    return (eda_transformation(bureau,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau = datasets['bureau']\n",
    "\n",
    "# rollup bureau_bal\n",
    "# gets rid of the unwanted characters in categorical columns entries - makes for nicer OHE column names later...\n",
    "bureau = bureau.merge(bbal, on='SK_ID_BUREAU', how='left') \\\n",
    "               .replace(to_replace='\\s+', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\-', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\(', value='', regex=True) \\\n",
    "               .replace(to_replace='\\)', value='', regex=True) \\\n",
    "               .drop('SK_ID_BUREAU', axis=1)\n",
    "bureau = bureau_eda(bureau)\n",
    "datasets_transformed['bureau'] = bureau\n",
    "#bureau.to_csv(os.getcwd() + DATA_DIR + 'bureau_agg_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collinearity Analysis\n",
    "\n",
    "The collinearity of variable pairs are compared via correlation and can be iteratively dropped from combined dataset based on which variables are least correlated to the target variable. Below is an example of the collinearity analysis. This step will be added to the pre-processing pipeline as a method of feature selection in future phases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colinearityReducer(dataframe, threshold=0.5):\n",
    "\n",
    "    '''\n",
    "    This function explores the correlation between each variable pair and the Target.\n",
    "    Of the var1iable pairs with absolute correlations above the threshold value...\n",
    "    ...the variable with the lowest target variable correlation is dropped from the input dataframe.\n",
    "    The process is repeated until there are no more colinear pairs with absolute correlations above the threshold.\n",
    "    \n",
    "    NOTE! The function receives a dataframe structured with the target variable in first column.\n",
    "    '''\n",
    "    \n",
    "    print('------------------------------------')\n",
    "    print('BEGIN COLINEAR FEATURE REDUCTION')\n",
    "    print('------------------------------------')\n",
    "    \n",
    "    i = 1\n",
    "    dropped_variables = list()\n",
    "    while True:\n",
    "    \n",
    "        # read-in and assign columns\n",
    "        # gets correlation matrix between variables and pivots to a longer df\n",
    "        # identify target variable\n",
    "        # drop same-name and target correlations \n",
    "        \n",
    "        print('------------------------------------')\n",
    "        print(f\"Colinearity Reduction Iteration {i}\\n\")\n",
    "        \n",
    "        df = dataframe\n",
    "        features = df.iloc[:,1:].columns\n",
    "        target_name = df.iloc[:,0].name\n",
    "        \n",
    "        print('')\n",
    "        print(f'Dataframe Features ({len(features)}):')\n",
    "        print(features)\n",
    "        \n",
    "        df = pd.melt(abs(df.corr()).reset_index(), id_vars='index', value_vars=features)\n",
    "        targets = df[df['index']==target_name]\n",
    "        df = df[(df['index'] != df['variable']) & (df['index'] != target_name) & (df['variable'] != target_name)]\n",
    "\n",
    "        # combine the correlated variables into ordered string\n",
    "        # aggregate the max correlation and sort pairs\n",
    "        # split out the variables from the original string\n",
    "        # join the target variable correlations for each variable pair, rename columns\n",
    "\n",
    "        df['joined'] = df[['index', 'variable']].apply(lambda row: '::'.join(np.sort(row.values.astype(str))), axis=1)\n",
    "\n",
    "        df = df.groupby('joined', as_index=False) \\\n",
    "               .agg({'value':'max'}) \\\n",
    "               .sort_values(by='value', ascending=False)\n",
    "\n",
    "        df[['var_1','var_2']] = df['joined'].str.split(\"::\",expand=True)\n",
    "\n",
    "        df = df.merge(targets, how='left', left_on='var_1', right_on='variable') \\\n",
    "               .merge(targets, how='left', left_on='var_2', right_on='variable')\n",
    "        df.rename(columns = {'value_x':'var_pair_corr', 'value_y':'var_1_target_corr', 'value':'var_2_target_corr'}, inplace = True)\n",
    "\n",
    "        # This section takes all variable pairs with a correlation greater than threshold\n",
    "        # test to determine which has a higher correlation with the target.\n",
    "        # The higher of the two gets marked as a win\n",
    "        # While the other gets marked as a loss\n",
    "        # the wins and losses for each variable are then grouped and summed\n",
    "\n",
    "        exceeds = df[df['var_pair_corr']>threshold]\n",
    "\n",
    "        # break if none above threshold\n",
    "        if len(exceeds['var_pair_corr'])==0:\n",
    "            print('------------------------------------')\n",
    "            print(f\"NO VARIABLE PAIRS WITH CORRELATION > {threshold}\")\n",
    "            break\n",
    "\n",
    "        exceeds['var_1_win'] = exceeds.apply(lambda row: 1 if row[\"var_1_target_corr\"] >= row[\"var_2_target_corr\"] else 0, axis=1)\n",
    "        exceeds['var_1_loss'] = exceeds.apply(lambda row: 1 if row[\"var_2_target_corr\"] >= row[\"var_1_target_corr\"] else 0, axis=1)\n",
    "        exceeds['var_2_win'] = exceeds.apply(lambda row: 1 if row[\"var_1_target_corr\"] < row[\"var_2_target_corr\"] else 0, axis=1)\n",
    "        exceeds['var_2_loss'] = exceeds.apply(lambda row: 1 if row[\"var_2_target_corr\"] < row[\"var_1_target_corr\"] else 0, axis=1)\n",
    "\n",
    "        var1 = exceeds[['var_1', 'var_1_win', 'var_1_loss']].groupby('var_1', as_index=False) \\\n",
    "                                                            .agg({'var_1_win':'sum', 'var_1_loss':'sum'})\n",
    "        var1.rename(columns = {'var_1':'var', 'var_1_win':'win', 'var_1_loss':'loss'}, inplace=True)\n",
    "\n",
    "        var2 = exceeds[['var_2', 'var_2_win', 'var_2_loss']].groupby('var_2', as_index=False) \\\n",
    "                                                            .agg({'var_2_win':'sum', 'var_2_loss':'sum'})\n",
    "        var2.rename(columns = {'var_2':'var', 'var_2_win':'win', 'var_2_loss':'loss'}, inplace=True)\n",
    "\n",
    "        corrcomps = pd.concat([var1,var2], axis=0).groupby('var', as_index=False) \\\n",
    "                                                  .agg({'win':'sum', 'loss':'sum'})\n",
    "\n",
    "        # drop variables which had 0 wins - IE collinear variables which were always least related to the target\n",
    "        dropvars = corrcomps[corrcomps['win']==0]['var']\n",
    "        \n",
    "        dropped_variables.extend(list(dropvars))\n",
    "        \n",
    "        dropvarsummary = targets[targets['variable'].isin(dropvars)].iloc[:,1:]\n",
    "        dropvarsummary.rename(columns={'variable':'Dropped Variable', 'value':'Target Variable Correlation'}, inplace = True)\n",
    "        \n",
    "        print('')\n",
    "        print('Dropped Variables:')\n",
    "        print(dropvarsummary)\n",
    "        # print('------------------------------------')\n",
    "        # print('Exceedances:')\n",
    "        # print(exceeds)\n",
    "        \n",
    "        dataframe = dataframe.drop(dropvars, axis=1)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    print('------------------------------------')\n",
    "    print('Final Dropped Variable List:')\n",
    "    print(dropped_variables)\n",
    "    print('------------------------------------')\n",
    "    print('END COLINEAR FEATURE REDUCTION')\n",
    "    print('------------------------------------')\n",
    "    \n",
    "    return dataframe\n",
    "    \n",
    "    \n",
    "# testing\n",
    "df = pd.concat([y_train,X_train[X_feat_num]],axis=1)\n",
    "\n",
    "colinearityReducer(df, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS - POS_CASH_balance\n",
    "\n",
    "1. This function is specifically for POS table. Below are the intial pre-processing steps done before passing this table into the pipeline.\n",
    "    - Create a drop list. \n",
    "        - Attributes that will be dropped are added to this list and all columns will be deleted before passing the dataframe into the eda function.\n",
    "    - Create new features based on analysis. 3 new features were created:\n",
    "        - Percentage of installments pending.\n",
    "        - Number of installments pending.\n",
    "        - Days with Tolerance.\n",
    "    - Take absolute of the months balance attribute. which was provided as negative values, as it is relative to application date.\n",
    "    - Replace \" \" with \"_\" for OHE columns.\n",
    "    - Any column or row with more than 70% of its data as null will be deleted from the dataframe, as the threshold is set to .7.\n",
    "    - Once processed, store the transformBenefit of this is that the data can be passed ed csv file. directly to model for merging into application train/test table. We do not have to repeatedly perform expensive EDA/ETL/Transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_eda(df):\n",
    "    pos = df\n",
    "    drop_list_pos = []\n",
    "    \n",
    "    #Adding new features\n",
    "    pos['POS_PERC_INSTL_PNDNG']=pos['CNT_INSTALMENT_FUTURE']/pos['CNT_INSTALMENT']\n",
    "    pos['POS_CNT_INSTAL_PNDNG']=pos['CNT_INSTALMENT']-pos['CNT_INSTALMENT_FUTURE']\n",
    "    pos['POS_DAYS_WTHT_TOLRNC']=pos['SK_DPD']-pos['SK_DPD_DEF']\n",
    "    pos['MONTHS_BALANCE'] = pos['MONTHS_BALANCE'].abs()\n",
    "    \n",
    "    #replacing \" \" with _ for OHE cols.\n",
    "    pos['NAME_CONTRACT_STATUS']=pos['NAME_CONTRACT_STATUS'].apply(lambda x: str(x).replace(\" \",\"_\")) \n",
    "    \n",
    "    # Drop elements in drop list\n",
    "    threshold = 0.7\n",
    "\n",
    "    #Dropping rows with missing value rate higher than threshold\n",
    "    pos = pos.loc[pos.isnull().mean(axis=1) < threshold]\n",
    "    \n",
    "    return (eda_transformation(pos,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = datasets['POS_CASH_balance']\n",
    "pos = pos_eda(pos)\n",
    "datasets_transformed['POS_CASH_balance'] = pos\n",
    "#pos.to_csv(os.getcwd() + DATA_DIR + 'pos_agg_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREVAPP - Previous Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This function is specifically for POS table. Below are the initial pre-processing steps done before passing this table into the pipeline.\n",
    "\n",
    "    - Create a drop list. \n",
    "        - Attributes that will be dropped will be added to this list and all columns will be deleted before passing the dataframe into the eda function.\n",
    "    - Create new features. based on analysis, 6 new features were created:\n",
    "        - Count of approved previous application. \n",
    "        - Count of Rejected previous applications.  \n",
    "        - Difference: Amount requested in application - Actual credit amount.\n",
    "        - Ratio - Ratio of application amount to amount credited. \n",
    "        - Ratio - Ratio of amount credited to amount annuity\n",
    "        - Ratio - Ratio of down payment to amount credited. \n",
    "\n",
    "    - There are number of attributes which are in days and amount. For that, we created list of columns which ends with \n",
    "    'DAYS' and 'AMT'\n",
    "\n",
    "    - Analysis on attributes with date shows that many are capped to 365243, which is 100 years. This looks to be added by the system and not user data. This will be replaced by nan and later imputed.\n",
    "    - Another observation was that days columns are marked as negative and so the absolute values were calcuated and used.\n",
    "\n",
    "    - Added below attributes to droplist:\n",
    "        - WEEKDAY_APPR_PROCESS_START\n",
    "        - HOUR_APPR_PROCESS_START\n",
    "\n",
    "    - Any column or row with more than 70% of its data as null will be deleted from the dataframe as the threshold is set to .7.\n",
    "\n",
    "    - Once processed, store the transformed csv file. Benefit of this is that we can then pass it directly to model for merging into application train/test table. We do not have to perform expensive EDA/ETL/Transformation everytime we want to process the same data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prevapp_eda(df):\n",
    "    prevapp = df\n",
    "    drop_list_pa = []\n",
    "    \n",
    "    #Day and Amount columns\n",
    "    day_cols = [col for col in prevapp.columns if 'DAY' in col]\n",
    "\n",
    "    amt_cols = [col for col in prevapp.columns if 'AMT' in col]\n",
    "    \n",
    "    #Adding new features\n",
    "    prevapp['PREV_APRV_CNT'] = prevapp['NAME_CONTRACT_STATUS'].map(lambda x: 1 if (x == 'Approved') else 0)\n",
    "    prevapp['PREV_REJ_CNT'] = prevapp['NAME_CONTRACT_STATUS'].map(lambda x: 1 if (x == 'Rejected') else 0)\n",
    "    prevapp['PREV_APCTN_CRDT_DIFF'] = prevapp['AMT_APPLICATION'] - prevapp['AMT_CREDIT']\n",
    "    prevapp['PREV_APCTN_CRDT_RATIO'] = prevapp['AMT_APPLICATION'] / prevapp['AMT_CREDIT']\n",
    "    prevapp['PREV_CRDT_ANNUTY_RATIO'] = prevapp['AMT_CREDIT']/prevapp['AMT_ANNUITY']\n",
    "    prevapp['PREV_DWN_PYMNT_CRDT_RATIO'] = prevapp['AMT_DOWN_PAYMENT'] / prevapp['AMT_CREDIT']\n",
    "    \n",
    "    for c in [co for co in prevapp.columns if 'DAYS' in co]:\n",
    "        prevapp[c] = prevapp[c].replace({365243.0: np.nan})\n",
    "        prevapp[c] = prevapp[c].abs()\n",
    "    \n",
    "    drop_list_pa.append('WEEKDAY_APPR_PROCESS_START') ## weekday data is normally distributed, so wont make any sense to add that\n",
    "    drop_list_pa.append('HOUR_APPR_PROCESS_START') ## Hour application started.\n",
    "    \n",
    "    # Drop elements in the drop list\n",
    "    drop_list_pa.append('WEEKDAY_APPR_PROCESS_START') ## weekday data is normally distributed, so wont make any sense to add that\n",
    "    drop_list_pa.append('HOUR_APPR_PROCESS_START') ## Hour application started.\n",
    "\n",
    "    threshold = 0.7\n",
    "    drop_list_pa = list(prevapp.columns[prevapp.isnull().mean() > threshold])\n",
    "\n",
    "    prevapp = prevapp.drop(columns=drop_list_pa, axis=1)\n",
    "\n",
    "    #Dropping columns with missing value rate higher than threshold\n",
    "    prevapp = prevapp[prevapp.columns[prevapp.isnull().mean() < threshold]]\n",
    "\n",
    "    #Dropping rows with missing value rate higher than threshold\n",
    "    prevapp = prevapp.loc[prevapp.isnull().mean(axis=1) < threshold]\n",
    "    \n",
    "    prevapp= eda_transformation(prevapp,3)\n",
    "    return prevapp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevapp = datasets['previous_application']\n",
    "prevapp = prevapp_eda(prevapp)\n",
    "datasets_transformed['previous_application'] = prevapp\n",
    "\n",
    "#prevapp.to_csv(os.getcwd() + DATA_DIR + 'prevapp_agg_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### CCB - Credit card Balance EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This function is specifically for Credit Card Balance table. Below are the pre-processing done before passing this table into the pipeline.\n",
    "\n",
    "    - Absolute value of the Months Balance is used as that allows only use of postive values without effecting the correlation, as it is realtive to the application date.\n",
    "\n",
    "    - Any column or row with more than 70% of its data as null will be deleted from the dataframe as the threshold is set to .7.\n",
    "\n",
    "    - Similar to above, once processed, store the transformed csv file. Benefit of this is that we can then pass it directly to model for merging into application train/test table. We do not have to perform expensive EDA/ETL/Transformation everytime we want to process the same data.\n",
    "    \n",
    "2. Specific Feature Transformations\n",
    "    - The NAME_CONTRACT_STATUS contained the below values with the count and ratio.\n",
    "                         \n",
    "                         COUNT  RATIO\n",
    "                         \n",
    "          Active         3698436   0.96\n",
    "        \n",
    "          Completed       128918   0.03\n",
    "        \n",
    "          Signed           11058   0.00\n",
    "        \n",
    "          Demand            1365   0.00\n",
    "        \n",
    "          Sent proposal      513   0.00\n",
    "        \n",
    "          Refused             17   0.00\n",
    "         \n",
    "          Approved             5   0.00\n",
    "             \n",
    "         - All values with Active and Complete were made into one category. If complete that is a positive finding or if acitve  that is also a postive finding as that means it payments are being made on it or the status is healthy enough to stay active for the credit.                 \n",
    "         <br>     \n",
    "         <br>     \n",
    "     - The other created column is of a count of the number of credit lines the person has open. This was done by aggreated the SK_ID_CURR. This also can give us some glimpse into number of credit lines open vs the target. The higher the credit lines should demostrate a postive finding as the newer ones may have been denied as they would have a bad credit score and possibly not get approved for another line.\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccb_eda(df, col_to_drop):\n",
    "    #dropping a highly correlated columns (.95 or .99)\n",
    "    ccb = df.drop(columns_to_drop, axis = 1)\n",
    "    ccb[\"NAME_CONTRACT_STATUS\"] = np.where((ccb[\"NAME_CONTRACT_STATUS\"].isin([\n",
    "       \"Active\", \"Completed\"\n",
    "    ])), \"GoodStatus\", ccb[\"NAME_CONTRACT_STATUS\"])\n",
    "    \n",
    "    #Adding new features\n",
    "    ccb['MONTHS_BALANCE'] = ccb['MONTHS_BALANCE'].abs()\n",
    "    \n",
    "    #replacing \" \" with _ for OHE cols.\n",
    "    ccb['NAME_CONTRACT_STATUS']=ccb['NAME_CONTRACT_STATUS'].apply(lambda x: str(x).replace(\" \",\"_\")) \n",
    "    \n",
    "    threshold = 0.7\n",
    "\n",
    "    #Dropping columns with missing value rate higher than threshold\n",
    "    ccb = ccb[ccb.columns[ccb.isnull().mean() < threshold]]\n",
    "\n",
    "    #Dropping rows with missing value rate higher than threshold\n",
    "    ccb = ccb.loc[ccb.isnull().mean(axis=1) < threshold]\n",
    "    agg = eda_transformation(ccb,4)\n",
    "    agg['CC_COUNT'] = ccb.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    return (agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation is calcuated with the highest correlated columns being dropped. The threshold used was when columns had a correlation of .95 or higher, only one of the columns was kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMT_BALANCE\n",
      "-------------------------------\n",
      "AMT_RECIVABLE               0.999917\n",
      "AMT_TOTAL_RECEIVABLE        0.999897\n",
      "AMT_RECEIVABLE_PRINCIPAL    0.999720\n",
      "AMT_INST_MIN_REGULARITY     0.896728\n",
      "Name: AMT_BALANCE, dtype: float64\n",
      "\n",
      "\n",
      "AMT_DRAWINGS_ATM_CURRENT\n",
      "-------------------------------\n",
      "AMT_DRAWINGS_CURRENT        0.800190\n",
      "CNT_DRAWINGS_ATM_CURRENT    0.732907\n",
      "Name: AMT_DRAWINGS_ATM_CURRENT, dtype: float64\n",
      "\n",
      "\n",
      "AMT_DRAWINGS_CURRENT\n",
      "-------------------------------\n",
      "AMT_DRAWINGS_ATM_CURRENT    0.80019\n",
      "Name: AMT_DRAWINGS_CURRENT, dtype: float64\n",
      "\n",
      "\n",
      "AMT_INST_MIN_REGULARITY\n",
      "-------------------------------\n",
      "AMT_RECIVABLE               0.897617\n",
      "AMT_TOTAL_RECEIVABLE        0.897587\n",
      "AMT_BALANCE                 0.896728\n",
      "AMT_RECEIVABLE_PRINCIPAL    0.896030\n",
      "Name: AMT_INST_MIN_REGULARITY, dtype: float64\n",
      "\n",
      "\n",
      "AMT_PAYMENT_CURRENT\n",
      "-------------------------------\n",
      "AMT_PAYMENT_TOTAL_CURRENT    0.994764\n",
      "Name: AMT_PAYMENT_CURRENT, dtype: float64\n",
      "\n",
      "\n",
      "AMT_PAYMENT_TOTAL_CURRENT\n",
      "-------------------------------\n",
      "AMT_PAYMENT_CURRENT    0.994764\n",
      "Name: AMT_PAYMENT_TOTAL_CURRENT, dtype: float64\n",
      "\n",
      "\n",
      "AMT_RECEIVABLE_PRINCIPAL\n",
      "-------------------------------\n",
      "AMT_RECIVABLE              0.999727\n",
      "AMT_BALANCE                0.999720\n",
      "AMT_TOTAL_RECEIVABLE       0.999702\n",
      "AMT_INST_MIN_REGULARITY    0.896030\n",
      "Name: AMT_RECEIVABLE_PRINCIPAL, dtype: float64\n",
      "\n",
      "\n",
      "AMT_RECIVABLE\n",
      "-------------------------------\n",
      "AMT_TOTAL_RECEIVABLE        0.999995\n",
      "AMT_BALANCE                 0.999917\n",
      "AMT_RECEIVABLE_PRINCIPAL    0.999727\n",
      "AMT_INST_MIN_REGULARITY     0.897617\n",
      "Name: AMT_RECIVABLE, dtype: float64\n",
      "\n",
      "\n",
      "AMT_TOTAL_RECEIVABLE\n",
      "-------------------------------\n",
      "AMT_RECIVABLE               0.999995\n",
      "AMT_BALANCE                 0.999897\n",
      "AMT_RECEIVABLE_PRINCIPAL    0.999702\n",
      "AMT_INST_MIN_REGULARITY     0.897587\n",
      "Name: AMT_TOTAL_RECEIVABLE, dtype: float64\n",
      "\n",
      "\n",
      "CNT_DRAWINGS_ATM_CURRENT\n",
      "-------------------------------\n",
      "AMT_DRAWINGS_ATM_CURRENT    0.732907\n",
      "Name: CNT_DRAWINGS_ATM_CURRENT, dtype: float64\n",
      "\n",
      "\n",
      "CNT_DRAWINGS_CURRENT\n",
      "-------------------------------\n",
      "CNT_DRAWINGS_POS_CURRENT    0.950546\n",
      "Name: CNT_DRAWINGS_CURRENT, dtype: float64\n",
      "\n",
      "\n",
      "CNT_DRAWINGS_POS_CURRENT\n",
      "-------------------------------\n",
      "CNT_DRAWINGS_CURRENT    0.950546\n",
      "Name: CNT_DRAWINGS_POS_CURRENT, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "high_correlation(datasets['credit_card_balance'], remove=['SK_ID_CURR', 'SK_ID_BUREAU'], corr_coef=\"pearson\", corr_value = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below are .99 correlations \n",
    "columns_to_drop = [\"AMT_RECIVABLE\", \"AMT_TOTAL_RECEIVABLE\", \"AMT_RECEIVABLE_PRINCIPAL\", \"AMT_PAYMENT_TOTAL_CURRENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below are .95+ correlations \n",
    "columns_to_drop = [\"AMT_RECIVABLE\", \"AMT_TOTAL_RECEIVABLE\", \"AMT_RECEIVABLE_PRINCIPAL\", \"AMT_PAYMENT_TOTAL_CURRENT\", \"CNT_DRAWINGS_POS_CURRENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "# of ID's: 1\n",
      " ID's:\n",
      "['SK_ID_CURR']\n",
      "\n",
      "--------\n",
      "# All features: 17\n",
      "All features:\n",
      "['CNT_DRAWINGS_CURRENT', 'MONTHS_BALANCE', 'AMT_DRAWINGS_CURRENT', 'SK_DPD', 'AMT_DRAWINGS_ATM_CURRENT', 'SK_DPD_DEF', 'CNT_DRAWINGS_ATM_CURRENT', 'AMT_BALANCE', 'NAME_CONTRACT_STATUS', 'CNT_DRAWINGS_OTHER_CURRENT', 'AMT_PAYMENT_CURRENT', 'SK_ID_PREV', 'AMT_DRAWINGS_POS_CURRENT', 'AMT_CREDIT_LIMIT_ACTUAL', 'AMT_DRAWINGS_OTHER_CURRENT', 'CNT_INSTALMENT_MATURE_CUM', 'AMT_INST_MIN_REGULARITY']\n",
      "\n",
      "Missing data:\n",
      "                             Total    Percent\n",
      "AMT_PAYMENT_CURRENT         767988  19.998063\n",
      "AMT_DRAWINGS_OTHER_CURRENT  749816  19.524872\n",
      "AMT_DRAWINGS_ATM_CURRENT    749816  19.524872\n",
      "CNT_DRAWINGS_ATM_CURRENT    749816  19.524872\n",
      "AMT_DRAWINGS_POS_CURRENT    749816  19.524872\n",
      "CNT_DRAWINGS_OTHER_CURRENT  749816  19.524872\n",
      "AMT_INST_MIN_REGULARITY     305236   7.948208\n",
      "CNT_INSTALMENT_MATURE_CUM   305236   7.948208\n",
      "AMT_CREDIT_LIMIT_ACTUAL          0   0.000000\n",
      "SK_ID_PREV                       0   0.000000\n",
      "CNT_DRAWINGS_CURRENT             0   0.000000\n",
      "MONTHS_BALANCE                   0   0.000000\n",
      "AMT_BALANCE                      0   0.000000\n",
      "SK_DPD_DEF                       0   0.000000\n",
      "SK_DPD                           0   0.000000\n",
      "AMT_DRAWINGS_CURRENT             0   0.000000\n",
      "NAME_CONTRACT_STATUS             0   0.000000\n",
      "\n",
      "--------\n",
      "# of Numerical features: 17\n",
      "Numerical features:\n",
      "['SK_ID_PREV', 'SK_ID_CURR', 'MONTHS_BALANCE', 'AMT_BALANCE', 'AMT_CREDIT_LIMIT_ACTUAL', 'AMT_DRAWINGS_ATM_CURRENT', 'AMT_DRAWINGS_CURRENT', 'AMT_DRAWINGS_OTHER_CURRENT', 'AMT_DRAWINGS_POS_CURRENT', 'AMT_INST_MIN_REGULARITY', 'AMT_PAYMENT_CURRENT', 'CNT_DRAWINGS_ATM_CURRENT', 'CNT_DRAWINGS_CURRENT', 'CNT_DRAWINGS_OTHER_CURRENT', 'CNT_INSTALMENT_MATURE_CUM', 'SK_DPD', 'SK_DPD_DEF']\n",
      "\n",
      "Numerical Statistical Summary:\n",
      "\n",
      "         SK_ID_PREV    SK_ID_CURR  MONTHS_BALANCE   AMT_BALANCE  \\\n",
      "count  3.840312e+06  3.840312e+06    3.840312e+06  3.840312e+06   \n",
      "mean   1.904504e+06  2.783242e+05    3.452192e+01  5.830016e+04   \n",
      "std    5.364695e+05  1.027045e+05    2.666775e+01  1.063070e+05   \n",
      "min    1.000018e+06  1.000060e+05    1.000000e+00 -4.202502e+05   \n",
      "25%    1.434385e+06  1.895170e+05    1.100000e+01  0.000000e+00   \n",
      "50%    1.897122e+06  2.783960e+05    2.800000e+01  0.000000e+00   \n",
      "75%    2.369328e+06  3.675800e+05    5.500000e+01  8.904669e+04   \n",
      "max    2.843496e+06  4.562500e+05    9.600000e+01  1.505902e+06   \n",
      "\n",
      "       AMT_CREDIT_LIMIT_ACTUAL  AMT_DRAWINGS_ATM_CURRENT  \\\n",
      "count             3.840312e+06              3.090496e+06   \n",
      "mean              1.538080e+05              5.961325e+03   \n",
      "std               1.651457e+05              2.822569e+04   \n",
      "min               0.000000e+00             -6.827310e+03   \n",
      "25%               4.500000e+04              0.000000e+00   \n",
      "50%               1.125000e+05              0.000000e+00   \n",
      "75%               1.800000e+05              0.000000e+00   \n",
      "max               1.350000e+06              2.115000e+06   \n",
      "\n",
      "       AMT_DRAWINGS_CURRENT  AMT_DRAWINGS_OTHER_CURRENT  \\\n",
      "count          3.840312e+06                3.090496e+06   \n",
      "mean           7.433388e+03                2.881696e+02   \n",
      "std            3.384608e+04                8.201989e+03   \n",
      "min           -6.211620e+03                0.000000e+00   \n",
      "25%            0.000000e+00                0.000000e+00   \n",
      "50%            0.000000e+00                0.000000e+00   \n",
      "75%            0.000000e+00                0.000000e+00   \n",
      "max            2.287098e+06                1.529847e+06   \n",
      "\n",
      "       AMT_DRAWINGS_POS_CURRENT  AMT_INST_MIN_REGULARITY  AMT_PAYMENT_CURRENT  \\\n",
      "count              3.090496e+06             3.535076e+06         3.072324e+06   \n",
      "mean               2.968805e+03             3.540204e+03         1.028054e+04   \n",
      "std                2.079689e+04             5.600154e+03         3.607808e+04   \n",
      "min                0.000000e+00             0.000000e+00         0.000000e+00   \n",
      "25%                0.000000e+00             0.000000e+00         1.523700e+02   \n",
      "50%                0.000000e+00             0.000000e+00         2.702700e+03   \n",
      "75%                0.000000e+00             6.633911e+03         9.000000e+03   \n",
      "max                2.239274e+06             2.028820e+05         4.289207e+06   \n",
      "\n",
      "       CNT_DRAWINGS_ATM_CURRENT  CNT_DRAWINGS_CURRENT  \\\n",
      "count              3.090496e+06          3.840312e+06   \n",
      "mean               3.094490e-01          7.031439e-01   \n",
      "std                1.100401e+00          3.190347e+00   \n",
      "min                0.000000e+00          0.000000e+00   \n",
      "25%                0.000000e+00          0.000000e+00   \n",
      "50%                0.000000e+00          0.000000e+00   \n",
      "75%                0.000000e+00          0.000000e+00   \n",
      "max                5.100000e+01          1.650000e+02   \n",
      "\n",
      "       CNT_DRAWINGS_OTHER_CURRENT  CNT_INSTALMENT_MATURE_CUM        SK_DPD  \\\n",
      "count                3.090496e+06               3.535076e+06  3.840312e+06   \n",
      "mean                 4.812496e-03               2.082508e+01  9.283667e+00   \n",
      "std                  8.263861e-02               2.005149e+01  9.751570e+01   \n",
      "min                  0.000000e+00               0.000000e+00  0.000000e+00   \n",
      "25%                  0.000000e+00               4.000000e+00  0.000000e+00   \n",
      "50%                  0.000000e+00               1.500000e+01  0.000000e+00   \n",
      "75%                  0.000000e+00               3.200000e+01  0.000000e+00   \n",
      "max                  1.200000e+01               1.200000e+02  3.260000e+03   \n",
      "\n",
      "         SK_DPD_DEF  \n",
      "count  3.840312e+06  \n",
      "mean   3.316220e-01  \n",
      "std    2.147923e+01  \n",
      "min    0.000000e+00  \n",
      "25%    0.000000e+00  \n",
      "50%    0.000000e+00  \n",
      "75%    0.000000e+00  \n",
      "max    3.260000e+03  \n",
      "\n",
      "--------\n",
      "# of Categorical features: 1\n",
      "Categorical features:\n",
      "['NAME_CONTRACT_STATUS']\n",
      "\n",
      "Categorical Statistical Summary:\n",
      "\n",
      "\n",
      "Categories:\n",
      "\n",
      "  NAME_CONTRACT_STATUS\n",
      "0           GoodStatus\n",
      "1               Demand\n",
      "2               Signed\n",
      "3        Sent_proposal\n",
      "4              Refused\n",
      "5             Approved\n",
      "\n",
      "--------\n",
      "# of OHE categorical features: 6\n",
      "OHE Categorical features: ['NAME_CONTRACT_STATUS_Refused', 'NAME_CONTRACT_STATUS_Demand', 'NAME_CONTRACT_STATUS_Approved', 'NAME_CONTRACT_STATUS_Signed', 'NAME_CONTRACT_STATUS_GoodStatus', 'NAME_CONTRACT_STATUS_Sent_proposal']\n",
      "--------\n",
      "df.shape: (3840312, 23)\n",
      "\n",
      "Aggregated Features:\n",
      "df[['CNT_DRAWINGS_CURRENT', 'MONTHS_BALANCE', 'AMT_DRAWINGS_CURRENT', 'NAME_CONTRACT_STATUS_Demand', 'SK_DPD', 'NAME_CONTRACT_STATUS_Approved', 'NAME_CONTRACT_STATUS_Sent_proposal', 'AMT_DRAWINGS_ATM_CURRENT', 'SK_DPD_DEF', 'CNT_DRAWINGS_ATM_CURRENT', 'AMT_BALANCE', 'CNT_DRAWINGS_OTHER_CURRENT', 'NAME_CONTRACT_STATUS_Refused', 'AMT_PAYMENT_CURRENT', 'SK_ID_PREV', 'AMT_DRAWINGS_POS_CURRENT', 'AMT_CREDIT_LIMIT_ACTUAL', 'NAME_CONTRACT_STATUS_GoodStatus', 'NAME_CONTRACT_STATUS_Signed', 'AMT_DRAWINGS_OTHER_CURRENT', 'CNT_INSTALMENT_MATURE_CUM', 'AMT_INST_MIN_REGULARITY']][0:5]: \n",
      "   CNT_DRAWINGS_CURRENT  MONTHS_BALANCE  AMT_DRAWINGS_CURRENT  \\\n",
      "0                     1               6                 877.5   \n",
      "1                     1               1                2250.0   \n",
      "2                     0               7                   0.0   \n",
      "3                     1               4                2250.0   \n",
      "4                     1               1               11547.0   \n",
      "\n",
      "   NAME_CONTRACT_STATUS_Demand  SK_DPD  NAME_CONTRACT_STATUS_Approved  \\\n",
      "0                            0       0                              0   \n",
      "1                            0       0                              0   \n",
      "2                            0       0                              0   \n",
      "3                            0       0                              0   \n",
      "4                            0       0                              0   \n",
      "\n",
      "   NAME_CONTRACT_STATUS_Sent_proposal  AMT_DRAWINGS_ATM_CURRENT  SK_DPD_DEF  \\\n",
      "0                                   0                       0.0           0   \n",
      "1                                   0                    2250.0           0   \n",
      "2                                   0                       0.0           0   \n",
      "3                                   0                    2250.0           0   \n",
      "4                                   0                       0.0           0   \n",
      "\n",
      "   CNT_DRAWINGS_ATM_CURRENT  ...  NAME_CONTRACT_STATUS_Refused  \\\n",
      "0                       0.0  ...                             0   \n",
      "1                       1.0  ...                             0   \n",
      "2                       0.0  ...                             0   \n",
      "3                       1.0  ...                             0   \n",
      "4                       0.0  ...                             0   \n",
      "\n",
      "   AMT_PAYMENT_CURRENT  SK_ID_PREV  AMT_DRAWINGS_POS_CURRENT  \\\n",
      "0               1800.0     2562384                     877.5   \n",
      "1               2250.0     2582071                       0.0   \n",
      "2               2250.0     1740877                       0.0   \n",
      "3              11925.0     1389973                       0.0   \n",
      "4              27000.0     1891521                   11547.0   \n",
      "\n",
      "   AMT_CREDIT_LIMIT_ACTUAL  NAME_CONTRACT_STATUS_GoodStatus  \\\n",
      "0                   135000                                1   \n",
      "1                    45000                                1   \n",
      "2                   450000                                1   \n",
      "3                   225000                                1   \n",
      "4                   450000                                1   \n",
      "\n",
      "   NAME_CONTRACT_STATUS_Signed  AMT_DRAWINGS_OTHER_CURRENT  \\\n",
      "0                            0                         0.0   \n",
      "1                            0                         0.0   \n",
      "2                            0                         0.0   \n",
      "3                            0                         0.0   \n",
      "4                            0                         0.0   \n",
      "\n",
      "   CNT_INSTALMENT_MATURE_CUM  AMT_INST_MIN_REGULARITY  \n",
      "0                       35.0                 1700.325  \n",
      "1                       69.0                 2250.000  \n",
      "2                       30.0                 2250.000  \n",
      "3                       10.0                11795.760  \n",
      "4                      101.0                22924.890  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "--------\n",
      "Aggregated Features:\n",
      "AMT_BALANCE_count\n",
      "AMT_BALANCE_max\n",
      "AMT_BALANCE_mean\n",
      "AMT_BALANCE_median\n",
      "AMT_BALANCE_min\n",
      "AMT_BALANCE_sum\n",
      "AMT_BALANCE_var\n",
      "AMT_CREDIT_LIMIT_ACTUAL_count\n",
      "AMT_CREDIT_LIMIT_ACTUAL_max\n",
      "AMT_CREDIT_LIMIT_ACTUAL_mean\n",
      "AMT_CREDIT_LIMIT_ACTUAL_median\n",
      "AMT_CREDIT_LIMIT_ACTUAL_min\n",
      "AMT_CREDIT_LIMIT_ACTUAL_sum\n",
      "AMT_CREDIT_LIMIT_ACTUAL_var\n",
      "AMT_DRAWINGS_ATM_CURRENT_count\n",
      "AMT_DRAWINGS_ATM_CURRENT_max\n",
      "AMT_DRAWINGS_ATM_CURRENT_mean\n",
      "AMT_DRAWINGS_ATM_CURRENT_median\n",
      "AMT_DRAWINGS_ATM_CURRENT_min\n",
      "AMT_DRAWINGS_ATM_CURRENT_sum\n",
      "AMT_DRAWINGS_ATM_CURRENT_var\n",
      "AMT_DRAWINGS_CURRENT_count\n",
      "AMT_DRAWINGS_CURRENT_max\n",
      "AMT_DRAWINGS_CURRENT_mean\n",
      "AMT_DRAWINGS_CURRENT_median\n",
      "AMT_DRAWINGS_CURRENT_min\n",
      "AMT_DRAWINGS_CURRENT_sum\n",
      "AMT_DRAWINGS_CURRENT_var\n",
      "AMT_DRAWINGS_OTHER_CURRENT_count\n",
      "AMT_DRAWINGS_OTHER_CURRENT_max\n",
      "AMT_DRAWINGS_OTHER_CURRENT_mean\n",
      "AMT_DRAWINGS_OTHER_CURRENT_median\n",
      "AMT_DRAWINGS_OTHER_CURRENT_min\n",
      "AMT_DRAWINGS_OTHER_CURRENT_sum\n",
      "AMT_DRAWINGS_OTHER_CURRENT_var\n",
      "AMT_DRAWINGS_POS_CURRENT_count\n",
      "AMT_DRAWINGS_POS_CURRENT_max\n",
      "AMT_DRAWINGS_POS_CURRENT_mean\n",
      "AMT_DRAWINGS_POS_CURRENT_median\n",
      "AMT_DRAWINGS_POS_CURRENT_min\n",
      "AMT_DRAWINGS_POS_CURRENT_sum\n",
      "AMT_DRAWINGS_POS_CURRENT_var\n",
      "AMT_INST_MIN_REGULARITY_count\n",
      "AMT_INST_MIN_REGULARITY_max\n",
      "AMT_INST_MIN_REGULARITY_mean\n",
      "AMT_INST_MIN_REGULARITY_median\n",
      "AMT_INST_MIN_REGULARITY_min\n",
      "AMT_INST_MIN_REGULARITY_sum\n",
      "AMT_INST_MIN_REGULARITY_var\n",
      "AMT_PAYMENT_CURRENT_count\n",
      "AMT_PAYMENT_CURRENT_max\n",
      "AMT_PAYMENT_CURRENT_mean\n",
      "AMT_PAYMENT_CURRENT_median\n",
      "AMT_PAYMENT_CURRENT_min\n",
      "AMT_PAYMENT_CURRENT_sum\n",
      "AMT_PAYMENT_CURRENT_var\n",
      "CNT_DRAWINGS_ATM_CURRENT_count\n",
      "CNT_DRAWINGS_ATM_CURRENT_max\n",
      "CNT_DRAWINGS_ATM_CURRENT_mean\n",
      "CNT_DRAWINGS_ATM_CURRENT_median\n",
      "CNT_DRAWINGS_ATM_CURRENT_min\n",
      "CNT_DRAWINGS_ATM_CURRENT_sum\n",
      "CNT_DRAWINGS_ATM_CURRENT_var\n",
      "CNT_DRAWINGS_CURRENT_count\n",
      "CNT_DRAWINGS_CURRENT_max\n",
      "CNT_DRAWINGS_CURRENT_mean\n",
      "CNT_DRAWINGS_CURRENT_median\n",
      "CNT_DRAWINGS_CURRENT_min\n",
      "CNT_DRAWINGS_CURRENT_sum\n",
      "CNT_DRAWINGS_CURRENT_var\n",
      "CNT_DRAWINGS_OTHER_CURRENT_count\n",
      "CNT_DRAWINGS_OTHER_CURRENT_max\n",
      "CNT_DRAWINGS_OTHER_CURRENT_mean\n",
      "CNT_DRAWINGS_OTHER_CURRENT_median\n",
      "CNT_DRAWINGS_OTHER_CURRENT_min\n",
      "CNT_DRAWINGS_OTHER_CURRENT_sum\n",
      "CNT_DRAWINGS_OTHER_CURRENT_var\n",
      "CNT_INSTALMENT_MATURE_CUM_count\n",
      "CNT_INSTALMENT_MATURE_CUM_max\n",
      "CNT_INSTALMENT_MATURE_CUM_mean\n",
      "CNT_INSTALMENT_MATURE_CUM_median\n",
      "CNT_INSTALMENT_MATURE_CUM_min\n",
      "CNT_INSTALMENT_MATURE_CUM_sum\n",
      "CNT_INSTALMENT_MATURE_CUM_var\n",
      "MONTHS_BALANCE_count\n",
      "MONTHS_BALANCE_max\n",
      "MONTHS_BALANCE_mean\n",
      "MONTHS_BALANCE_median\n",
      "MONTHS_BALANCE_min\n",
      "MONTHS_BALANCE_sum\n",
      "MONTHS_BALANCE_var\n",
      "NAME_CONTRACT_STATUS_Approved_mean\n",
      "NAME_CONTRACT_STATUS_Approved_median\n",
      "NAME_CONTRACT_STATUS_Approved_var\n",
      "NAME_CONTRACT_STATUS_Demand_mean\n",
      "NAME_CONTRACT_STATUS_Demand_median\n",
      "NAME_CONTRACT_STATUS_Demand_var\n",
      "NAME_CONTRACT_STATUS_GoodStatus_mean\n",
      "NAME_CONTRACT_STATUS_GoodStatus_median\n",
      "NAME_CONTRACT_STATUS_GoodStatus_var\n",
      "NAME_CONTRACT_STATUS_Refused_mean\n",
      "NAME_CONTRACT_STATUS_Refused_median\n",
      "NAME_CONTRACT_STATUS_Refused_var\n",
      "NAME_CONTRACT_STATUS_Sent_proposal_mean\n",
      "NAME_CONTRACT_STATUS_Sent_proposal_median\n",
      "NAME_CONTRACT_STATUS_Sent_proposal_var\n",
      "NAME_CONTRACT_STATUS_Signed_mean\n",
      "NAME_CONTRACT_STATUS_Signed_median\n",
      "NAME_CONTRACT_STATUS_Signed_var\n",
      "SK_DPD_DEF_count\n",
      "SK_DPD_DEF_max\n",
      "SK_DPD_DEF_mean\n",
      "SK_DPD_DEF_median\n",
      "SK_DPD_DEF_min\n",
      "SK_DPD_DEF_sum\n",
      "SK_DPD_DEF_var\n",
      "SK_DPD_count\n",
      "SK_DPD_max\n",
      "SK_DPD_mean\n",
      "SK_DPD_median\n",
      "SK_DPD_min\n",
      "SK_DPD_sum\n",
      "SK_DPD_var\n",
      "SK_ID_PREV_count\n",
      "\n",
      "Aggregated Data:\n",
      "\n",
      "                                              count          mean  \\\n",
      "CNT_INSTALMENT_MATURE_CUM_var              102866.0  6.456481e+01   \n",
      "MONTHS_BALANCE_mean                        103558.0  1.950555e+01   \n",
      "SK_DPD_median                              103558.0  2.034609e+00   \n",
      "AMT_DRAWINGS_POS_CURRENT_var                71692.0  7.335384e+08   \n",
      "NAME_CONTRACT_STATUS_Refused_var           102866.0  2.006632e-06   \n",
      "...                                             ...           ...   \n",
      "NAME_CONTRACT_STATUS_Sent_proposal_median  103558.0  0.000000e+00   \n",
      "CNT_DRAWINGS_CURRENT_min                   103558.0  9.523166e-02   \n",
      "AMT_DRAWINGS_CURRENT_var                   102866.0  1.798590e+09   \n",
      "AMT_PAYMENT_CURRENT_mean                    72120.0  1.793468e+04   \n",
      "AMT_DRAWINGS_CURRENT_sum                   103558.0  2.756574e+05   \n",
      "\n",
      "                                                    std     min          25%  \\\n",
      "CNT_INSTALMENT_MATURE_CUM_var              1.421240e+02     0.0     0.000000   \n",
      "MONTHS_BALANCE_mean                        1.666657e+01     1.0     6.000000   \n",
      "SK_DPD_median                              3.174861e+01     0.0     0.000000   \n",
      "AMT_DRAWINGS_POS_CURRENT_var               4.849624e+09     0.0     0.000000   \n",
      "NAME_CONTRACT_STATUS_Refused_var           1.565132e-04     0.0     0.000000   \n",
      "...                                                 ...     ...          ...   \n",
      "NAME_CONTRACT_STATUS_Sent_proposal_median  0.000000e+00     0.0     0.000000   \n",
      "CNT_DRAWINGS_CURRENT_min                   1.010919e+00     0.0     0.000000   \n",
      "AMT_DRAWINGS_CURRENT_var                   7.646675e+09     0.0     0.000000   \n",
      "AMT_PAYMENT_CURRENT_mean                   2.842948e+04     0.0  4668.146719   \n",
      "AMT_DRAWINGS_CURRENT_sum                   4.556683e+05 -1687.5     0.000000   \n",
      "\n",
      "                                                    50%           75%  \\\n",
      "CNT_INSTALMENT_MATURE_CUM_var              6.000000e+00  4.216667e+01   \n",
      "MONTHS_BALANCE_mean                        1.200000e+01  3.800000e+01   \n",
      "SK_DPD_median                              0.000000e+00  0.000000e+00   \n",
      "AMT_DRAWINGS_POS_CURRENT_var               2.649883e+06  2.538298e+08   \n",
      "NAME_CONTRACT_STATUS_Refused_var           0.000000e+00  0.000000e+00   \n",
      "...                                                 ...           ...   \n",
      "NAME_CONTRACT_STATUS_Sent_proposal_median  0.000000e+00  0.000000e+00   \n",
      "CNT_DRAWINGS_CURRENT_min                   0.000000e+00  0.000000e+00   \n",
      "AMT_DRAWINGS_CURRENT_var                   1.918232e+08  1.215640e+09   \n",
      "AMT_PAYMENT_CURRENT_mean                   9.856811e+03  2.134006e+04   \n",
      "AMT_DRAWINGS_CURRENT_sum                   1.431000e+05  3.616040e+05   \n",
      "\n",
      "                                                    max  \n",
      "CNT_INSTALMENT_MATURE_CUM_var              1.078032e+03  \n",
      "MONTHS_BALANCE_mean                        5.017978e+01  \n",
      "SK_DPD_median                              1.385500e+03  \n",
      "AMT_DRAWINGS_POS_CURRENT_var               4.358126e+11  \n",
      "NAME_CONTRACT_STATUS_Refused_var           1.388889e-02  \n",
      "...                                                 ...  \n",
      "NAME_CONTRACT_STATUS_Sent_proposal_median  0.000000e+00  \n",
      "CNT_DRAWINGS_CURRENT_min                   7.800000e+01  \n",
      "AMT_DRAWINGS_CURRENT_var                   6.075000e+11  \n",
      "AMT_PAYMENT_CURRENT_mean                   1.593111e+06  \n",
      "AMT_DRAWINGS_CURRENT_sum                   3.029332e+07  \n",
      "\n",
      "[124 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "ccb = datasets['credit_card_balance']\n",
    "ccb = ccb_eda(ccb, columns_to_drop)\n",
    "datasets_transformed['credit_card_balance'] = ccb\n",
    "\n",
    "#ccb.to_csv(os.getcwd() + DATA_DIR + 'ccb_agg_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installment Payments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This function is specifically for Installment Payments table. Below are the pre-processing done before passing this table into the pipeline.\n",
    "\n",
    "    - Absolute value of the Days Installment and Days Entry Payment are used as that allows only use of postive values without effecting the correlation. As more negative means longer time from the intial date. \n",
    "\n",
    "    - A new column of IP_DIFF_PAYMNT_INSTLMNT was also calculated from difference of AMT_INSTALMENT from AMT_PAYMENT as a part of the feature select/transformation process.\n",
    "\n",
    "    - Any column or row with more than 70% of its data as null will be deleted from the dataframe as the threshold is set to .7.\n",
    "\n",
    "    - Similar to above, once processed, store the transfored csv file. Benefit of this is that we can then pass it directly to model for merging into application train/test table. We do not have to perform expensive EDA/ETL/Transformation everytime we want to process the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ip_eda(df):\n",
    "    ip = df\n",
    "    drop_list_ip = []\n",
    "    \n",
    "    #Adding new features\n",
    "    ip['DAYS_INSTALMENT'] = ip['DAYS_INSTALMENT'].abs()\n",
    "    ip['DAYS_ENTRY_PAYMENT'] = ip['DAYS_ENTRY_PAYMENT'].abs()\n",
    "    ip['IP_DIFF_PAYMNT_INSTLMNT'] = ip['AMT_PAYMENT'] - ip['AMT_INSTALMENT']\n",
    "    \n",
    "    threshold = 0.7\n",
    "\n",
    "    #Dropping columns with missing value rate higher than threshold\n",
    "    ip = ip[ip.columns[ip.isnull().mean() < threshold]]\n",
    "\n",
    "    #Dropping rows with missing value rate higher than threshold\n",
    "    ip = ip.loc[ip.isnull().mean(axis=1) < threshold]\n",
    "    \n",
    "    return (eda_transformation(ip,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = datasets['installments_payments']\n",
    "ip = ip_eda(ip)\n",
    "datasets_transformed['installments_payments'] = ip\n",
    "\n",
    "ip.to_csv(os.getcwd() + DATA_DIR + 'ip_agg_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visual EDA <a name='EDAV'></a>\n",
    "\n",
    "## EDA Visualization functions\n",
    "\n",
    "Following are the functions created to do visualization. These are rudimentary level plots which provide insights into a dataframe. The input to these functions will either be a dataframe or a combination of dataframe and type of attribute (numerical, categorical) depending upon the type of function.\n",
    "\n",
    "+ **Attr_Type**: This function plots a bar graph which shows the count of type of attribute, i.e. Number, Categorical, Date etc. We are using similar logic in summary statistics where depending upon the type of variable, we derive the numerical and categorical features to further do the processing.\n",
    "+ **Unique Values**: This function plots the bar chart for the unique value for each attribute. This process will give us some insights about the number of binary , ordinal and continuous (more than 10 unique values) features in the dataset. This info can also be read from info and summary python functions. Another thing to notice here is that y-axis is on log scale. This is because on such a large data set, few elements have more unique values(like CURR ID, SK ID PREV) which makes distribution highly skewed. By taking log, we will have fair idea about other features with lesser unique values.\n",
    "+ **Percent Missing**: This bar plot will show to percentage of nulls in the data. This plot will be helpful for us to see how much nulls a attribute has. In phase I, we created pipeline with attributes with more than 50% nulls. This information will also help while finding the correlation and cross-verify if some values are less or highly correlated. 1 thing to note here is that this plot also has y-axis log scaled for the same reason as provided above. \n",
    "+ **Categorical_count**: This function will take a dataframe and categorical features as input and will produce a bar plot for each category. This will enable us to understand if certain set of values are more correlated to the target. For example, we saw that less educated people are more likely to default on their loan, as per the data provided. Now that we have seen this info as a plot, we can analyze  a little more. This will also help us group certain values which are negligible, For example, if 2 categories are related to 90 % of the data, we can group certain low occurring values to make them as 1 category. This can also be seen by using the F score to see how statistically important it can be.\n",
    "+ **Dendo**: This unique plot will groups together columns that have strong correlations in nullity. If a number of columns are grouped together at level zero, then the presence of nulls in one of those columns is directly related to the presence or absence of nulls in the others columns. The more separated the columns in the tree, the less likely the null values can be correlated between the columns.\n",
    "+ **Numerical_features**:  This function will take only the numerical attributes from a dataframe and produce a dot plot. Each dot in this plot is a sample in our dataset and each subplot represents a different feature. The y-axis shows the feature value, while the x-axis is the sample index. These kind of plots provide a lot of ideas for data cleaning and EDA.   \n",
    "+ **Num Hist**: This functions takes dataframe and numerical attributes. This will plot histogram for all the features supplied. A very useful visualization to see the data distribution in 1 view. We can take note of attributes which needs transformation, as well as outliers. For a better input data, we should remove the outliers so that it does not influence the target outcome. \n",
    "+ **all_missing_values_plot**: This function will plot the missing in all the features of the dataframe supplied. For attributes which have no nulls will show as 1, if an attribute has half of the records null, then it will show 0.5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr_type(df):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    pd.value_counts(df.dtypes).sort_values().plot(kind=\"bar\", figsize=(15, 8),logy=False,\n",
    "                                              title=\"Type of features- Numerical/Categorical\",\n",
    "                                              ylabel=\"Number of features\");\n",
    "    plt.show()\n",
    "\n",
    "def unique_values(df):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    unique_values = df.select_dtypes(include=\"number\").nunique().sort_values(ascending=False)\n",
    "    unique_values.plot.bar(logy=True, figsize=(15, 4), title=\"Unique values per feature\");\n",
    "    plt.show()\n",
    "\n",
    "def percent_missing(df):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    df.isna().mean().sort_values().plot(kind=\"bar\", figsize=(15, 8),logy=True,\n",
    "                                          title=\"Percentage of missing values per feature\",\n",
    "                                          ylabel=\"Ratio of missing values per feature\");\n",
    "    plt.show()\n",
    "    \n",
    "def categorical_count(df,categorical):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    for i, col in enumerate(feat_cat):\n",
    "        ax = plt.subplot(5, 4, i+1)\n",
    "        sns.countplot(data=df[categorical], y=col, ax=ax,) \n",
    "    plt.suptitle('Category counts for all categorical variables')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def dendo(df):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    msno.dendrogram(df)\n",
    "    plt.show()\n",
    "    \n",
    "def numerical_features(df,num_cat):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    df[num_cat].plot(lw=0, marker=\".\", subplots=True, layout=(-1, 4),\n",
    "              figsize=(15, 12), markersize=1);\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def num_hist(df):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    df[np.isfinite(df)].hist(bins=25, figsize=(15, 25), layout=(-1, 5), edgecolor=\"black\")\n",
    "    plt.tight_layout();\n",
    "    plt.show();\n",
    "\n",
    "    \n",
    "def continous_features(df,feat_num):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    cols_continuous = df.select_dtypes(include=\"number\").nunique() >= 25\n",
    "    df_continuous = df[cols_continuous[cols_continuous].index]\n",
    "    #df_continuous.shape\n",
    "    sns.pairplot(df_continuous[feat_num], height=1.5, plot_kws={\"s\": 2, \"alpha\": 0.2});\n",
    "    plt.show()\n",
    "def all_missing_values_plot(df):\n",
    "    \n",
    "    div = df.columns[df.isin([np.nan]).any()]\n",
    "    plt.figure(figsize=(20,20))\n",
    "    (msno.bar(df[div]).set_title(\"All features with missing data\",fontsize=24))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDAV Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ds_name in enumerate(datasets.keys()):\n",
    "    \n",
    "    #n = True\n",
    "    #if n:\n",
    "        \n",
    "    if ds_name.lower() not in (#\"application_train\",\n",
    "                               \"application_test\", \"bureau_balance\"):\n",
    "        print(\"Table under consideration:\",ds_name.upper())\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        id_cols, feat_num, feat_cat, features =  id_num_cat_feature(datasets[ds_name],text = False)\n",
    "        only_num_cat = list(set(feat_num)-set(['SK_ID_CURR','SK_ID_PREV','SK_ID_BUREAU']))\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(ds_name.upper(),\":-------------------------Type of Features-------------------------------\")\n",
    "        attr_type(datasets[ds_name])\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(ds_name.upper(),\":-------------------------UNIQUE VALUES----------------------------------\")\n",
    "        unique_values(datasets[ds_name]) \n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(ds_name.upper(),\":-------------------------MISSING PERCENTAGE-----------------------------\")\n",
    "        percent_missing(datasets[ds_name])\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(ds_name.upper(),\":-------------------------CATEGORICAL COUNT------------------------------\")\n",
    "        categorical_count(datasets[ds_name],feat_cat)\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(ds_name.upper(),\":-------------------------NUM FEATURES-DOT PLOT----------------------\")\n",
    "        numerical_features(datasets[ds_name],only_num_cat)\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(ds_name.upper(),\":-------------------------NUM FEATURES - HISTOGRAM ----------------------\")\n",
    "        num_hist(datasets[ds_name][only_num_cat])\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(ds_name.upper(),\":-------------------------Continous Features ----------------------------\")\n",
    "        #continous_features(df_x,only_num_cat)\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(ds_name.upper(),\":-------------------------All Missing Features---------------------------\")\n",
    "        all_missing_values_plot(datasets[ds_name])\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(ds_name.upper(),\":-------------------------DendoGram for Nulls----------------------------\")\n",
    "        dendo(datasets[ds_name])\n",
    "        print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Plots Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlation matrix is a table showing correlation coefficients between variables. Each cell in the table shows the correlation between two variables. This correlation is a value put on the relationship between two attributes. A correlation matrix is used to summarize data, then with that information do more advanced analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_plot(data, remove=[\"Id\"], corr_coef = \"pearson\", figsize=(20, 20)):\n",
    "    if len(remove) > 0:\n",
    "        num_cols2 = [x for x in data.columns if (x not in remove)]\n",
    "\n",
    "    sns.set(font_scale=1.1)\n",
    "    c = data[num_cols2].corr(method = corr_coef)\n",
    "    mask = np.triu(c.corr(method = corr_coef))\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(c,\n",
    "                annot=True,\n",
    "                fmt='.1f',\n",
    "                cmap='coolwarm',\n",
    "                square=True,\n",
    "                mask=mask,\n",
    "                linewidths=1,\n",
    "                cbar=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ds_name in enumerate(datasets.keys()):\n",
    "    if(ds_name != \"bureau_balance\"):\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(\"Table under consideration FOR CORRELATION PLOT:\",ds_name.upper())\n",
    "        corr_plot(datasets[ds_name], remove=['SK_ID_CURR','SK_ID_BUREAU'], corr_coef = \"spearman\")\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(\"------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in Application train and application test dataframes, most of the __FLAG_DOCUMENT_XX__ are null, we will remove these columns at later point of time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Plots and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These visualizations consist of the paired plots for each column in the each table. \n",
    "\n",
    "The first is a histogram, a diagram consisting of rectangles whose area is proportional to the frequency of a variable and whose width is equal to the class interval, which helps to visualize distribution. \n",
    "\n",
    "The second is a boxplot, which is a standardized way of displaying the distribution of data based on a five number summary (“minimum”, first quartile Q1, median, third quartile Q3 and “maximum”). It can tell you about your outliers and what their values are.\n",
    "\n",
    "https://builtin.com/data-science/boxplot#:~:text=What%20Is%20a%20Boxplot%3F,and%20what%20their%20values%20are.\n",
    "\n",
    "The third is a Kernel Density Plot which also helps to visualize distriubtion over a time peroid or some continuous value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_col_names(dataframe, cat_th=10, car_th=20, show_date=False):\n",
    "    date_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"datetime64[ns]\"]\n",
    "    cat_cols = dataframe.select_dtypes([\"object\", \"category\"]).columns.tolist()\n",
    "    \n",
    "    num_but_cat = [col for col in dataframe.select_dtypes([\"float\", \"integer\"]).columns if dataframe[col].nunique() < cat_th]\n",
    "    cat_but_car = [col for col in dataframe.select_dtypes([\"object\", \"category\"]).columns if dataframe[col].nunique() > car_th]\n",
    "    \n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    num_cols = dataframe.select_dtypes([\"float\", \"integer\"]).columns\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "    \n",
    "    if show_date == True:\n",
    "        return date_cols, cat_cols, cat_but_car, num_cols, num_but_cat\n",
    "    else:\n",
    "        return cat_cols, cat_but_car, num_cols, num_but_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_plot(data, num_cols, remove=[\"Id\"], hist_bins=10, figsize=(20, 4)):\n",
    "\n",
    "    if len(remove) > 0:\n",
    "        num_cols2 = [x for x in num_cols if (x not in remove)]\n",
    "\n",
    "    for i in num_cols2:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "        data.hist(str(i), bins=hist_bins, ax=axes[0])\n",
    "        data.boxplot(str(i), ax=axes[1], vert=False);\n",
    "        try:\n",
    "            sns.kdeplot(np.array(data[str(i)]))\n",
    "        except:\n",
    "            ValueError\n",
    "\n",
    "        axes[1].set_yticklabels([])\n",
    "        axes[1].set_yticks([])\n",
    "        axes[0].set_title(i + \" | Histogram\")\n",
    "        axes[1].set_title(i + \" | Boxplot\")\n",
    "        axes[2].set_title(i + \" | Density\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ds_name in enumerate(datasets.keys()):\n",
    "    \n",
    "    if ds_name.lower() not in (\"application_train\",\n",
    "                               \"application_test\", \"bureau_balance\"):\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        #_,_, num_cols, _ = grab_col_names(datasets[ds_name], car_th=10)\n",
    "        _,num_cols,_,_ = id_num_cat_feature(datasets[ds_name], text = False)\n",
    "        datasets[ds_name].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        print(\"Table under consideration FOR NUMERICAL PLOTS:\",ds_name.upper())\n",
    "        num_plot(datasets[ds_name], num_cols, remove=['SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV'], figsize = (15,3))\n",
    "        print(\"------------------------------------------------------------------------\")\n",
    "        print(\"------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Skewness/Distribution : Numerical data\n",
    "\n",
    "**Look for skewed column in numerical data but ignore dates, Days,Flags, status, ID's.**\n",
    "\n",
    "**Skewness in : AMT_INCOME_TOTAL,AMT_CREDIT,AMT_ANNUITY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train = datasets[\"application_train\"]\n",
    "numerical_ix = application_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_ix = application_train.select_dtypes(include=['object', 'bool']).columns\n",
    "num_features = list(numerical_ix)\n",
    "cat_features = list(categorical_ix)\n",
    "print(f\"# of numerical   features: {len(numerical_ix)}\")\n",
    "print(f\"Numerical   features: {numerical_ix}\")\n",
    "print('--------')\n",
    "print(f\"# of categorical features: {len(categorical_ix)}\")\n",
    "print(f\"Categorical features: {categorical_ix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"application_train\"][numerical_ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AMT_CREDIT and AMT_ANNUITY looks skewed. we wil do log transformation on these attributes and make them more mormalized.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMT_CREDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(datasets[\"application_train\"]['AMT_CREDIT'], bins=25);\n",
    "plt.xlabel('AMT_CREDIT')\n",
    "plt.ylabel('Count')\n",
    "plt.title(\"Distribution - AMT_CREDIT \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(datasets[\"application_train\"]['AMT_CREDIT']), bins=30);\n",
    "plt.xlabel('Log(AMT_CREDIT)')\n",
    "plt.ylabel('Count')\n",
    "plt.title(\"Distribution - Log(AMT_CREDIT) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMT_ANNUITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(datasets[\"application_train\"]['AMT_ANNUITY'], bins=25);\n",
    "plt.xlabel('AMT_ANNUITY')\n",
    "plt.ylabel('Count')\n",
    "plt.title(\"Distribution - AMT_ANNUITY \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(datasets[\"application_train\"]['AMT_ANNUITY']), bins=30);\n",
    "plt.xlabel('Log(AMT_ANNUITY)')\n",
    "plt.ylabel('Count')\n",
    "plt.title(\"Distribution - Log(AMT_ANNUITY) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data for application train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = (datasets[\"application_train\"].isnull().sum()/datasets[\"application_train\"].isnull().count()*100).sort_values(ascending = False).round(2)\n",
    "sum_missing = datasets[\"application_train\"].isna().sum().sort_values(ascending = False)\n",
    "missing_application_train_data  = pd.concat([percent, sum_missing], axis=1, keys=['Percent', \"Train Missing Count\"])\n",
    "missing_application_train_data.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine more than 50% null\n",
    "\n",
    "Determine attributes which have more than 50% NULLS. Once done, these will be used as part of feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls_50 = missing_application_train_data[round(missing_application_train_data['Percent']>50.0)==True]\n",
    "#nulls_50.index\n",
    "\n",
    "remove_num_nulls = list(set(nulls_50.index).intersection(set(numerical_ix)))\n",
    "remove_cat_nulls = list(set(nulls_50.index).intersection(set(categorical_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = (datasets[\"application_test\"].isnull().sum()/datasets[\"application_test\"].isnull().count()*100).sort_values(ascending = False).round(2)\n",
    "sum_missing = datasets[\"application_test\"].isna().sum().sort_values(ascending = False)\n",
    "missing_application_train_data  = pd.concat([percent, sum_missing], axis=1, keys=['Percent', \"Test Missing Count\"])\n",
    "missing_application_train_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of the target column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"application_train\"]['TARGET'].astype(int).plot.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This shows that around 8% of people are not able to repay the loans back.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"application_train\"]['TARGET'].value_counts()/datasets[\"application_train\"]['TARGET'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation with  the target column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_against_target(df):\n",
    "    df_joined = {} \n",
    "    df_joined =  datasets['application_train'][[\"SK_ID_CURR\", \"TARGET\"]].merge(df, on='SK_ID_CURR', how='right')\n",
    "    cols = df.columns\n",
    "    keys = list(df.columns)\n",
    "    keys.append(\"TARGET\")\n",
    "    return df_joined[keys].corr()['TARGET'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations against the target on the Original Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_corr = {}\n",
    "#barplot\n",
    "for i,ds_name in enumerate(datasets.keys()):\n",
    "    if(ds_name.upper() != \"APPLICATION_TRAIN\"):\n",
    "        if (ds_name.upper() != \"APPLICATION_TEST\"):\n",
    "            if (ds_name.upper() != \"BUREAU_BALANCE\"):\n",
    "                if (ds_name.upper() == \"BUREAU\"):\n",
    "                    if 'AMT_ANNUITY' in datasets[\"bureau\"].columns:\n",
    "                        datasets[\"bureau\"] = datasets[\"bureau\"].drop([\"AMT_ANNUITY\"], axis = 1)\n",
    "                print(\"------------------------------------------------------------------------\")\n",
    "                print(\"Correlation for Orignal Table:\", ds_name.upper())\n",
    "                print(\"------------------------------------------------------------------------\")\n",
    "                ds = correlation_against_target(datasets[ds_name])\n",
    "                print(\"------------------------------------------------------------------------\")\n",
    "                original_corr[ds_name] = ds\n",
    "                print(ds)\n",
    "                print(\"------------------------------------------------------------------------\")\n",
    "                print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations on the Transformed Tables done with a right merge against the table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_corr = {}\n",
    "for i,ds_name in enumerate(datasets_transformed.keys()):\n",
    "    datasets_transformed[ds_name].reset_index()\n",
    "    #if(ds_name.upper() not in ( \"APPLICATION_TRAIN\",\"APPLICATION_TEST\",\"BUREAU_BALANCE\"):\n",
    "    if(ds_name.upper() != \"APPLICATION_TRAIN\"):\n",
    "        if (ds_name.upper() != \"APPLICATION_TEST\"):\n",
    "            #if (ds_name.upper() != \"POS_CASH_BALANCE\"):\n",
    "                if (ds_name.upper() != \"BUREAU_BALANCE\"):        \n",
    "                    print(\"------------------------------------------------------------------------\")\n",
    "                    print(\"Correlation for Transformed Table:\", ds_name.upper())\n",
    "                    print(\"------------------------------------------------------------------------\")\n",
    "                    ds = correlation_against_target(datasets_transformed[ds_name])\n",
    "                    print(\"------------------------------------------------------------------------\")\n",
    "                    transformed_corr[ds_name] = ds\n",
    "                    print(ds)\n",
    "                    print(\"------------------------------------------------------------------------\")\n",
    "                    print(\"------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest Correlations on Original Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below gives you the highest correlated attributes from each table with a threshold of .7. This is correlation to other attributes in the same table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get high correlated variables\n",
    "def high_correlation(data, remove=['SK_ID_CURR', 'SK_ID_BUREAU'], corr_coef=\"pearson\", corr_value = 0.7):\n",
    "    if len(remove) > 0:\n",
    "        cols = [x for x in data.columns if (x not in remove)]\n",
    "        c = data[cols].corr(method=corr_coef)\n",
    "    else:\n",
    "        c = data.corr(method=corr_coef)\n",
    "\n",
    "    for i in c.columns:\n",
    "        cr = c.loc[i].loc[(c.loc[i] >= corr_value) | (c.loc[i] <= -corr_value)].drop(i)\n",
    "        if len(cr) > 0:\n",
    "            print(i)\n",
    "            print(\"-------------------------------\")\n",
    "            print(cr.sort_values(ascending=False))\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"application_train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are determining the highest correlations for each table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,ds_name in enumerate(datasets.keys()):\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"Table under consideration FOR HIGHEST CORRELATIONS:\",ds_name.upper())\n",
    "    high_correlation(datasets[ds_name], remove=['SK_ID_CURR','SK_ID_BUREAU', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_10', \n",
    "                                                'FLAG_DOCUMENT_12','FLAG_DOCUMENT_13','FLAG_DOCUMENT_14',\n",
    "                                               'FLAG_DOCUMENT_15','FLAG_DOCUMENT_16','FLAG_DOCUMENT_17',\n",
    "                                               'FLAG_DOCUMENT_18','FLAG_DOCUMENT_19','FLAG_DOCUMENT_20',\n",
    "                                               'FLAG_DOCUMENT_21','PREV_REJ_CNT'], corr_coef = \"spearman\", corr_value = 0.7)\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we find the attributes which are highly correlated, either positive or negative. Looks like EXT_SOURCE columns are highly correlated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = datasets[\"application_train\"].corr()['TARGET'].sort_values()\n",
    "print('Most Positive Correlations:\\n', correlations.tail(10))\n",
    "print('\\nMost Negative Correlations:\\n', correlations.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Top 10__ highly correlated columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = correlations.abs().sort_values().tail(11)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applicants Age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(datasets[\"application_train\"]['DAYS_BIRTH'] / -365, edgecolor = 'k', bins = 25)\n",
    "plt.title('Age of Client'); plt.xlabel('Age (years)'); plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applicants occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='OCCUPATION_TYPE', data=datasets[\"application_train\"]);\n",
    "plt.title('Applicants Occupation');\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**17% of our applicants are labourers and around 10% are from the Sales. This seems like folks which are from the lower income range which apply for the loan.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Dataset questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### previous applications - Phase I Analysis\n",
    "The persons in the kaggle submission file have had previous applications in the `previous_application.csv`. 47,800 out 48,744 people have had previous appications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appsDF = datasets[\"previous_application\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.intersect1d(datasets[\"previous_application\"][\"SK_ID_CURR\"], datasets[\"application_test\"][\"SK_ID_CURR\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are  {appsDF.shape[0]:,} previous applications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many entries are there for each month?\n",
    "prevAppCounts = appsDF['SK_ID_CURR'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prevAppCounts[prevAppCounts >40])  #more that 40 previous applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevAppCounts[prevAppCounts >50].plot(kind='bar')\n",
    "plt.xticks(rotation=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of Number of previous applications for an ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(appsDF['SK_ID_CURR'].value_counts()==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(appsDF['SK_ID_CURR'].value_counts(), cumulative =True, bins = 100);\n",
    "plt.grid()\n",
    "plt.ylabel('cumulative number of IDs')\n",
    "plt.xlabel('Number of previous applications per ID')\n",
    "plt.title('Histogram of Number of previous applications for an ID')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Can we differentiate applications by low, medium and high previous apps?**\n",
    "    * Low = <5 claims (22%)\n",
    "    * Medium = 10 to 39 claims (58%)\n",
    "    * High = 40 or more claims (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_all = appsDF['SK_ID_CURR'].nunique()\n",
    "apps_5plus = appsDF['SK_ID_CURR'].value_counts()>=5\n",
    "#print(apps_5plus)\n",
    "apps_40plus = appsDF['SK_ID_CURR'].value_counts()>=40\n",
    "apps_med_plus = 100 - apps_5plus- apps_40plus\n",
    "print('Percentage with 10 or more previous apps:', np.round(100.*(sum(apps_5plus)/apps_all),5))\n",
    "print('Percentage with 11 to 39 no of apps:', np.round(100-(100.*(sum(apps_5plus)/apps_all))-(100.*(sum(apps_40plus)/apps_all)),5))\n",
    "print('Percentage with 40 or more previous apps:', np.round(100.*(sum(apps_40plus)/apps_all),5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(prevAppCounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Machine Learning Pipelines <a name='pipelines'></a>\n",
    "\n",
    "## Pre-Processing\n",
    "\n",
    "###  OHE when previously unseen unique values in the test/validation set\n",
    "\n",
    "Train, validation and Test sets (and the leakage problem we have mentioned previously):\n",
    "\n",
    " \n",
    "\n",
    "Let's look at a small usecase to tell us how to deal with this:\n",
    "\n",
    "* The OneHotEncoder is fitted to the training set, which means that for each unique value present in the training set, for each feature, a new column is created. Let's say we have 39 columns after the encoding up from 30 (before preprocessing).\n",
    "* The output is a numpy array (when the option sparse=False is used), which has the disadvantage of losing all the information about the original column names and values.\n",
    "* When we try to transform the test set, after having fitted the encoder to the training set, we obtain a `ValueError`. This is because the there are new, previously unseen unique values in the test set and the encoder doesn’t know how to handle these values. In order to use both the transformed training and test sets in machine learning algorithms, we need them to have the same number of columns.\n",
    "\n",
    "This last problem can be solved by using the option handle_unknown='ignore'of the OneHotEncoder, which, as the name suggests, will ignore previously unseen values when transforming the test set.\n",
    "\n",
    " \n",
    "\n",
    "Here is a example that in action:\n",
    "\n",
    "```python\n",
    "# Identify the categorical features we wish to consider.\n",
    "cat_attribs = ['CODE_GENDER', 'FLAG_OWN_REALTY','FLAG_OWN_CAR','NAME_CONTRACT_TYPE', \n",
    "               'NAME_EDUCATION_TYPE','OCCUPATION_TYPE','NAME_INCOME_TYPE']\n",
    "\n",
    "# Notice handle_unknown=\"ignore\" in OHE which ignore values from the validation/test that\n",
    "# do NOT occur in the training set\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please [this  blog](https://medium.com/hugo-ferreiras-blog/dealing-with-categorical-features-in-machine-learning-1bb70f07262d) for more details of OHE when the validation/test have previously unseen unique values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrameSelector Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model Algorithms\n",
    "\n",
    "The `sklearn.linear_model.LogisticRegression` implementation will be used for the baseline model with parameters penalty that can be any one the these `l1`, `l2`, `elasticnet`, a mutli class of `ovr` to fit each label using a binary problem, and `C` which is the inverse of regularization strength. The Logistic Regression loss function will be calculated using with cross entropy loss. \n",
    "\n",
    "The objective function for the learning a multinomial logistic regression model (log loss) can be stated as follows:\n",
    "\n",
    "$$\\textrm{CXE}(\\theta) = \\left[-\\frac{1}{m}\\sum_{i=1}^m\\left(y_i\\cdot\\log\\left(p_i\\right)+\\left(1-y_i\\right)\\cdot\\log\\left(1-p_i\\right)\\right)\\right]$$\n",
    "\n",
    "Regularization helps reduce the risk of overfitting.\n",
    "\n",
    "* Ridge Regularization (L2):\n",
    "  * $\\textrm{RidgeCXE}(\\theta) = \\textrm{CXE}(\\theta) + \\lambda \\sum_{j=1}^{n}\\theta_j^2$\n",
    "* Lasso Regularization (L1):\n",
    "  * $\\textrm{LassoCXE}(\\theta) = \\textrm{CXE}(\\theta) + \\lambda \\sum_{j=1}^n|\\theta_j|$\n",
    "* Elastic Net Regularization (Hybrid L1 + L2):\n",
    "  * $\\textrm{ElasticCXE}(\\theta) = \\textrm{CXE}(\\theta) + r\\lambda\\sum_{j=1}^n|\\theta_j| + \\frac{1-r}{2}\\lambda\\sum_{j=1}^n\\theta_j^2$\n",
    "  \n",
    "However, for the scope of Phase 2 regularization *will not* be incorporated into the baseline model due to time and computing power constraints. Regularization is planned to be incorporated in the Phase 3 model pipelines. \n",
    "\n",
    "## Baseline Models - Before EDA\n",
    "\n",
    "Here are some model runs using only the `application_train` data, with various feature selections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline with 14 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify the numeric features we wish to consider. \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split  # sklearn.cross_validation in old versions\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = datasets[\"application_train\"]\n",
    "y = data['TARGET']\n",
    "X = data.drop(['SK_ID_CURR', 'TARGET'], axis = 1) #drop some features with questionable value\n",
    "\n",
    "# Split the provided training data into training and validationa and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(f\"X train           shape: {X_train.shape}\")\n",
    "print(f\"X validation      shape: {X_valid.shape}\")\n",
    "print(f\"X test            shape: {X_test.shape}\")\n",
    "\n",
    "num_attribs = [\n",
    "    'AMT_INCOME_TOTAL',  'AMT_CREDIT','DAYS_EMPLOYED','DAYS_BIRTH','EXT_SOURCE_1',\n",
    "    'EXT_SOURCE_2','EXT_SOURCE_3']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "# Identify the categorical features we wish to consider.\n",
    "cat_attribs = ['CODE_GENDER', 'FLAG_OWN_REALTY','FLAG_OWN_CAR','NAME_CONTRACT_TYPE', \n",
    "               'NAME_EDUCATION_TYPE','OCCUPATION_TYPE','NAME_INCOME_TYPE']\n",
    "\n",
    "selected_features = num_attribs + cat_attribs\n",
    "# Notice handle_unknown=\"ignore\" in OHE which ignore values from the validation/test that\n",
    "# do NOT occur in the training set\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "data_pipeline = ColumnTransformer(transformers=[\n",
    "        (\"num_pipeline\", num_pipeline, num_attribs),\n",
    "        (\"cat_pipeline\", cat_pipeline, cat_attribs)],\n",
    "        remainder='drop',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", data_pipeline),\n",
    "        (\"linear\", LogisticRegression())\n",
    "    ])\n",
    "\n",
    "param_grid = {'linear__penalty':[#'l1', 'l2', 'elasticnet',\n",
    "                                 'none']\n",
    "              #,'linear__C':[1.0#, 10.0, 100.0 ]\n",
    "             }\n",
    "\n",
    "gd2 = GridSearchCV(full_pipeline_with_predictor, param_grid= param_grid, cv = 5, n_jobs=-1, scoring='roc_auc')\n",
    "\n",
    "model = gd2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "try:\n",
    "    expLog\n",
    "except NameError:\n",
    "    expLog = pd.DataFrame(columns=[\"exp_name\", \n",
    "                                   \"Train Acc\", \n",
    "                                   \"Valid Acc\",\n",
    "                                   \"Test  Acc\",\n",
    "                                   \"Train AUC\", \n",
    "                                   \"Valid AUC\",\n",
    "                                   \"Test  AUC\"\n",
    "                                  ])\n",
    "\n",
    "exp_name = f\"Baseline_{len(selected_features)}_features\"\n",
    "expLog.loc[len(expLog)] = [f\"{exp_name}\"] + list(np.round(\n",
    "               [accuracy_score(y_train, model.predict(X_train)), \n",
    "                accuracy_score(y_valid, model.predict(X_valid)),\n",
    "                accuracy_score(y_test, model.predict(X_test)),\n",
    "                roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]),\n",
    "                roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1]),\n",
    "                roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])],\n",
    "    4)) \n",
    "expLog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = datasets[\"application_train\"]\n",
    "y = data['TARGET']\n",
    "X = data.drop(['SK_ID_CURR', 'TARGET'], axis = 1) #drop some features with questionable value\n",
    "\n",
    "# Split the provided training data into training and validationa and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(f\"X train           shape: {X_train.shape}\")\n",
    "print(f\"X validation      shape: {X_valid.shape}\")\n",
    "print(f\"X test            shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 2:  All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split  # sklearn.cross_validation in old versions\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "data = datasets[\"application_train\"]\n",
    "y = data['TARGET']\n",
    "X = data.drop(['SK_ID_CURR', 'TARGET'], axis = 1) #drop some features with questionable value\n",
    "\n",
    "# Split the provided training data into training and validationa and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(f\"X train           shape: {X_train.shape}\")\n",
    "print(f\"X validation      shape: {X_valid.shape}\")\n",
    "print(f\"X test            shape: {X_test.shape}\")\n",
    "\n",
    "numerical_features = list(numerical_ix[2:])\n",
    "\n",
    "num_pipeline =Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "categorical_features = list(categorical_ix)\n",
    "\n",
    "selected_features = (numerical_features) + (categorical_features)\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "\n",
    "data_pipeline = ColumnTransformer(transformers=[\n",
    "        (\"num_pipeline\", num_pipeline, numerical_features),\n",
    "        (\"cat_pipeline\", cat_pipeline, categorical_features)],\n",
    "        remainder='drop',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", data_pipeline),\n",
    "        (\"linear\", LogisticRegression())\n",
    "    ])\n",
    "\n",
    "param_grid = {'linear__penalty':[#'l1', 'l2', 'elasticnet',\n",
    "                                 'none']\n",
    "              #,'linear__C':[1.0#, 10.0, 100.0]\n",
    "             }\n",
    "\n",
    "gd1 = GridSearchCV(full_pipeline_with_predictor, param_grid= param_grid, cv = 5, n_jobs=-1, scoring='roc_auc')\n",
    "\n",
    "model = gd1.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "try:\n",
    "    expLog\n",
    "except NameError:\n",
    "    expLog = pd.DataFrame(columns=[\"exp_name\", \n",
    "                                   \"Train Acc\", \n",
    "                                   \"Valid Acc\",\n",
    "                                   \"Test  Acc\",\n",
    "                                   \"Train AUC\", \n",
    "                                   \"Valid AUC\",\n",
    "                                   \"Test  AUC\"\n",
    "                                  ])\n",
    "\n",
    "exp_name = f\"Baseline_{len(selected_features)}_features\"\n",
    "expLog.loc[len(expLog)] = [f\"{exp_name}\"] + list(np.round(\n",
    "               [accuracy_score(y_train, model.predict(X_train)), \n",
    "                accuracy_score(y_valid, model.predict(X_valid)),\n",
    "                accuracy_score(y_test, model.predict(X_test)),\n",
    "                roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]),\n",
    "                roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1]),\n",
    "                roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])],\n",
    "    4)) \n",
    "expLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 3: 79 Features\n",
    "\n",
    "**Selected Features**\n",
    "\n",
    "**Remove elements with more than 50% nulls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split  # sklearn.cross_validation in old versions\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "data = datasets[\"application_train\"]\n",
    "y = data['TARGET']\n",
    "X = data.drop(['SK_ID_CURR', 'TARGET'], axis = 1) #drop some features with questionable value\n",
    "\n",
    "# Split the provided training data into training and validationa and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(f\"X train           shape: {X_train.shape}\")\n",
    "print(f\"X validation      shape: {X_valid.shape}\")\n",
    "print(f\"X test            shape: {X_test.shape}\")\n",
    "\n",
    "numerical_features = list(numerical_ix[2:].drop(remove_num_nulls))\n",
    "\n",
    "num_pipeline =Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "categorical_features = list(categorical_ix.drop(remove_cat_nulls))\n",
    "\n",
    "selected_features = (numerical_features) + (categorical_features)\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "\n",
    "data_pipeline = ColumnTransformer(transformers=[\n",
    "        (\"num_pipeline\", num_pipeline, numerical_features),\n",
    "        (\"cat_pipeline\", cat_pipeline, categorical_features)],\n",
    "        remainder='drop',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", data_pipeline),\n",
    "        (\"linear\", LogisticRegression())\n",
    "    ])\n",
    "\n",
    "param_grid = {'linear__penalty':[#'l1', 'l2', 'elasticnet',\n",
    "                                 'none']\n",
    "              #,'linear__C':[1.0#, 10.0, 100.0]\n",
    "                            }\n",
    "\n",
    "gd3 = GridSearchCV(full_pipeline_with_predictor, param_grid= param_grid, cv = 5, n_jobs=-1, scoring='roc_auc')\n",
    "\n",
    "model = gd3.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "try:\n",
    "    expLog\n",
    "except NameError:\n",
    "    expLog = pd.DataFrame(columns=[\"exp_name\", \n",
    "                                   \"Train Acc\", \n",
    "                                   \"Valid Acc\",\n",
    "                                   \"Test  Acc\",\n",
    "                                   \"Train AUC\", \n",
    "                                   \"Valid AUC\",\n",
    "                                   \"Test  AUC\"\n",
    "                                  ])\n",
    "\n",
    "exp_name = f\"Baseline_{len(selected_features)}_features\"\n",
    "expLog.loc[len(expLog)] = [f\"{exp_name}\"] + list(np.round(\n",
    "               [accuracy_score(y_train, model.predict(X_train)), \n",
    "                accuracy_score(y_valid, model.predict(X_valid)),\n",
    "                accuracy_score(y_test, model.predict(X_test)),\n",
    "                roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]),\n",
    "                roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1]),\n",
    "                roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])],\n",
    "    4)) \n",
    "expLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 4 : 79 features; 2 log features\n",
    "\n",
    "**Remove elements with more than 50% nulls with log AMT_ANNUITY and AMT_CREDIT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = datasets[\"application_train\"]\n",
    "y = data['TARGET']\n",
    "X = data.drop(['SK_ID_CURR', 'TARGET'], axis = 1) #drop some features with questionable value\n",
    "X['LOG_AMT_ANNUITY'] = np.log(X['AMT_ANNUITY']) #add LOG_AMT_ANNUITY colunm\n",
    "X = X.drop(['AMT_ANNUITY'], axis = 1) # drop AMT_ANNUITY colunm\n",
    "X['LOG_AMT_CREDIT'] = np.log(X['AMT_CREDIT']) #add LOG_AMT_ANNUITY colunm\n",
    "X = X.drop(['AMT_CREDIT'], axis = 1) # drop AMT_ANNUITY colunm\n",
    "\n",
    "# Split the provided training data into training and validationa and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "print(f\"X train           shape: {X_train.shape}\")\n",
    "print(f\"X validation      shape: {X_valid.shape}\")\n",
    "print(f\"X test            shape: {X_test.shape}\")\n",
    "\n",
    "numerical_features = list(numerical_ix[2:].drop(remove_num_nulls))\n",
    "numerical_features.append('LOG_AMT_ANNUITY')\n",
    "numerical_features.append('LOG_AMT_CREDIT')\n",
    "numerical_features.remove('AMT_CREDIT')\n",
    "numerical_features.remove('AMT_ANNUITY')\n",
    "\n",
    "\n",
    "num_pipeline =Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "     \n",
    "categorical_features =  list(categorical_ix.drop(remove_cat_nulls))\n",
    "\n",
    "selected_features = (numerical_features) + (categorical_features)\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "\n",
    "data_pipeline = ColumnTransformer(transformers=[\n",
    "        (\"num_pipeline\", num_pipeline, numerical_features),\n",
    "        (\"cat_pipeline\", cat_pipeline, categorical_features)],\n",
    "        remainder='drop',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", data_pipeline),\n",
    "        (\"linear\", LogisticRegression())\n",
    "    ])\n",
    "\n",
    "param_grid = {'linear__penalty':[#'l1', 'l2', 'elasticnet',\n",
    "                                 'none']\n",
    "              #,'linear__C':[1.0#, 10.0, 100.0]\n",
    "             }\n",
    "\n",
    "gd4 = GridSearchCV(full_pipeline_with_predictor, param_grid= param_grid, cv = 5, n_jobs=-1, scoring='roc_auc')\n",
    "\n",
    "model = gd4.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "try:\n",
    "    expLog\n",
    "except NameError:\n",
    "    expLog = pd.DataFrame(columns=[\"exp_name\", \n",
    "                                   \"Train Acc\", \n",
    "                                   \"Valid Acc\",\n",
    "                                   \"Test  Acc\",\n",
    "                                   \"Train AUC\", \n",
    "                                   \"Valid AUC\",\n",
    "                                   \"Test  AUC\"\n",
    "                                  ])\n",
    "\n",
    "exp_name = f\"Baseline_{len(selected_features)}_features with log attributes\"\n",
    "expLog.loc[len(expLog)] = [f\"{exp_name}\"] + list(np.round(\n",
    "               [accuracy_score(y_train, model.predict(X_train)), \n",
    "                accuracy_score(y_valid, model.predict(X_valid)),\n",
    "                accuracy_score(y_test, model.predict(X_test)),\n",
    "                roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]),\n",
    "                roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1]),\n",
    "                roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])],\n",
    "    4)) \n",
    "expLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model on Aggregated Features - Post EDA\n",
    "\n",
    "The model below was constructed after exploratory data analysis was performed on all the tables. The sections below outline the data denormalization process (aggregating the tables into a singular input variable 'X') and then incorporate them into a baseline logistic regression model without regularization. \n",
    "\n",
    "### Data Denormalization\n",
    "\n",
    "This first section takes all of the aggregated tables and merges them into the single denormalized table, called `bureau_ip_ccb_prev_pos_merged`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_DIR =  \"/../Data/\"\n",
    "\n",
    "ds_names = (\"application_train\", \"application_test\", \"ccb_agg_data\", \"ip_agg_data\",\"prevapp_agg_data\",\n",
    "            \"pos_agg_data\",\"bureau_agg_data\")\n",
    "\n",
    "datasets_agg = {}\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    datasets_agg[ds_name] = pd.read_csv(os.getcwd() + DATA_DIR + f'{ds_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_merged = datasets_agg[\"application_train\"].merge(datasets_agg[\"pos_agg_data\"], on='SK_ID_CURR', how='left') \\\n",
    "               .replace(to_replace='\\s+', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\-', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\(', value='', regex=True) \\\n",
    "               .replace(to_replace='\\)', value='', regex=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_merged_test = datasets_agg[\"application_test\"].merge(datasets_agg[\"pos_agg_data\"], on='SK_ID_CURR', how='left') \\\n",
    "               .replace(to_replace='\\s+', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\-', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\(', value='', regex=True) \\\n",
    "               .replace(to_replace='\\)', value='', regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_pos_merged = pos_merged.merge(datasets_agg[\"prevapp_agg_data\"], on='SK_ID_CURR', how='left') \\\n",
    "               .replace(to_replace='\\s+', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\-', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\(', value='', regex=True) \\\n",
    "               .replace(to_replace='\\)', value='', regex=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_pos_merged_test = pos_merged_test.merge(datasets_agg[\"prevapp_agg_data\"], on='SK_ID_CURR', how='left') \\\n",
    "               .replace(to_replace='\\s+', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\-', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\(', value='', regex=True) \\\n",
    "               .replace(to_replace='\\)', value='', regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccb_prev_pos_merged = prev_pos_merged.merge(datasets_agg[\"ccb_agg_data\"], on='SK_ID_CURR', how='left') \\\n",
    "               .replace(to_replace='\\s+', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\-', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\(', value='', regex=True) \\\n",
    "               .replace(to_replace='\\)', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccb_prev_pos_merged_test = prev_pos_merged_test.merge(datasets_agg[\"ccb_agg_data\"], on='SK_ID_CURR', how='left') \\\n",
    "               .replace(to_replace='\\s+', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\-', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\(', value='', regex=True) \\\n",
    "               .replace(to_replace='\\)', value='', regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_ccb_prev_pos_merged = ccb_prev_pos_merged.merge(datasets_agg[\"ip_agg_data\"], on='SK_ID_CURR', how='left') \\\n",
    "               .replace(to_replace='\\s+', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\-', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\(', value='', regex=True) \\\n",
    "               .replace(to_replace='\\)', value='', regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_ccb_prev_pos_merged_test = ccb_prev_pos_merged_test.merge(datasets_agg[\"ip_agg_data\"], on='SK_ID_CURR', how='left') \\\n",
    "               .replace(to_replace='\\s+', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\-', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\(', value='', regex=True) \\\n",
    "               .replace(to_replace='\\)', value='', regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_ip_ccb_prev_pos_merged = ip_ccb_prev_pos_merged.merge(datasets_agg[\"bureau_agg_data\"], on='SK_ID_CURR', how='left') \\\n",
    "               .replace(to_replace='\\s+', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\-', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\(', value='', regex=True) \\\n",
    "               .replace(to_replace='\\)', value='', regex=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_ip_ccb_prev_pos_merged_test = ip_ccb_prev_pos_merged_test.merge(datasets_agg[\"bureau_agg_data\"], on='SK_ID_CURR', how='left') \\\n",
    "               .replace(to_replace='\\s+', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\-', value='_', regex=True) \\\n",
    "               .replace(to_replace='\\(', value='', regex=True) \\\n",
    "               .replace(to_replace='\\)', value='', regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_ip_ccb_prev_pos_merged.to_csv(os.getcwd() + DATA_DIR + 'bureau_ip_ccb_prev_pos_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_ip_ccb_prev_pos_merged_test.to_csv(os.getcwd() + DATA_DIR + 'bureau_ip_ccb_prev_pos_merged_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Pipeline with All Features\n",
    "\n",
    "This section runs the baseline ML pipeline using all the integrated data features as outlined by the block diagram below:\n",
    "\n",
    "<img src=\"../images/pipelineblockdiagram.png\" alt=\"drawing\" width=\"1000\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR =  \"/../Data/\"\n",
    "\n",
    "datasets_agg = {}\n",
    "datasets_agg[\"bureau_ip_ccb_prev_pos_merged\"] = pd.read_csv(os.getcwd() + DATA_DIR + f'bureau_ip_ccb_prev_pos_merged.csv')\n",
    "bureau_ip_ccb_prev_pos_merged = datasets_agg[\"bureau_ip_ccb_prev_pos_merged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bureau_ip_ccb_prev_pos_merged['TARGET']\n",
    "X = bureau_ip_ccb_prev_pos_merged.drop(['SK_ID_CURR', 'TARGET', 'Unnamed: 0'], axis = 1) #drop some features with questionable value\n",
    "\n",
    "#X['LOG_AMT_ANNUITY'] = np.log(X['AMT_ANNUITY']) #add LOG_AMT_ANNUITY colunm\n",
    "#X = X.drop(['AMT_ANNUITY'], axis = 1) # drop AMT_ANNUITY colunm\n",
    "#X['LOG_AMT_CREDIT'] = np.log(X['AMT_CREDIT']) #add LOG_AMT_ANNUITY colunm\n",
    "#X = X.drop(['AMT_CREDIT'], axis = 1) # drop AMT_ANNUITY colunm\n",
    "\n",
    "# Split the provided training data into training and validationa and test\n",
    "_, X, _, y = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X train           shape: {X_train.shape}\")\n",
    "print(f\"X validation      shape: {X_valid.shape}\")\n",
    "print(f\"X test            shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols, feat_num, feat_cat, features =  id_num_cat_feature(X, text = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "     \n",
    "#categorical_features =  list(categorical_ix.drop(remove_cat_nulls))\n",
    "categorical_features =  feat_cat\n",
    "numerical_features = feat_num\n",
    "\n",
    "selected_features = (numerical_features) + (categorical_features)\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "\n",
    "data_pipeline = ColumnTransformer(transformers=[\n",
    "        (\"num_pipeline\", num_pipeline, numerical_features),\n",
    "        (\"cat_pipeline\", cat_pipeline, categorical_features)],\n",
    "        remainder='drop',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", data_pipeline),\n",
    "       # ('pca', decomposition.PCA()),\n",
    "        (\"logistic_Reg\", LogisticRegression(solver=\"liblinear\"))\n",
    "    ])\n",
    "\n",
    "#n_components = list(range(1,X_train.shape[1]+1,1))\n",
    "#C = np.logspace(-4, 4, 50)\n",
    "penalty = [\n",
    "           #,'l1', 'l2'\n",
    "          ]\n",
    "\n",
    "parameters = dict(#pca__n_components=n_components,\n",
    "                      #logistic_Reg__C=C,\n",
    "                  #    logistic_Reg__penalty=penalty\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd4 = GridSearchCV(full_pipeline_with_predictor, param_grid= parameters, cv = 5, n_jobs=-10, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Best Penalty:', gd4.best_estimator_.get_params()['logistic_Reg__penalty'])\n",
    "# print('Best C:', gd4.best_estimator_.get_params()['logistic_Reg__C'])\n",
    "# #print('Best Number Of Components:', gd4.best_estimator_.get_params()['pca__n_components'])\n",
    "# print(); print(gd4.best_estimator_.get_params()['logistic_Reg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_valid.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "try:\n",
    "    expLog\n",
    "except NameError:\n",
    "    expLog = pd.DataFrame(columns=[\"exp_name\", \n",
    "                                   \"Train Acc\", \n",
    "                                   \"Valid Acc\",\n",
    "                                   \"Test  Acc\",\n",
    "                                   \"Train AUC\", \n",
    "                                   \"Valid AUC\",\n",
    "                                   \"Test  AUC\"\n",
    "                                  ])\n",
    "\n",
    "exp_name = f\"Baseline_{len(selected_features)}_features with log attributes\"\n",
    "expLog.loc[len(expLog)] = [f\"{exp_name}\"] + list(np.round(\n",
    "               [accuracy_score(y_train, gd4.predict(X_train)), \n",
    "                accuracy_score(y_valid, gd4.predict(X_valid)),\n",
    "                accuracy_score(y_test, gd4.predict(X_test)),\n",
    "                roc_auc_score(y_train, gd4.predict_proba(X_train)[:, 1]),\n",
    "                roc_auc_score(y_valid, gd4.predict_proba(X_valid)[:, 1]),\n",
    "                roc_auc_score(y_test, gd4.predict_proba(X_test)[:, 1])],\n",
    "    4)) \n",
    "expLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission File Prep\n",
    "\n",
    "For each SK_ID_CURR in the test set, you must predict a probability for the TARGET variable. The file should contain a header and have the following format:\n",
    "\n",
    "```python \n",
    "SK_ID_CURR,TARGET\n",
    "100001,0.1\n",
    "100005,0.9\n",
    "100013,0.2\n",
    "etc.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR =  \"/../Data/\"\n",
    "\n",
    "datasets_agg = {}\n",
    "datasets_agg[\"bureau_ip_ccb_prev_pos_merged_test\"] = pd.read_csv(os.getcwd() + DATA_DIR + f'bureau_ip_ccb_prev_pos_merged_test.csv')\n",
    "bureau_ip_ccb_prev_pos_merged_test = datasets_agg[\"bureau_ip_ccb_prev_pos_merged_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = bureau_ip_ccb_prev_pos_merged_test\n",
    "X_Kaggle_test = data_test.drop(['SK_ID_CURR','Unnamed: 0'], axis = 1)\n",
    "X_Kaggle_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "print(X_Kaggle_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Kaggle_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "#X_Kaggle_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class_scores = gd4.predict_proba(X_Kaggle_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = datasets[\"application_test\"][['SK_ID_CURR']]\n",
    "submit_df['TARGET'] = test_class_scores\n",
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Kaggle Submission\n",
    "\n",
    "Click on this [link](https://www.kaggle.com/c/home-credit-default-risk/submissions?sortBy=date&group=all&page=1)\n",
    "\n",
    "<img src=\"../images/p2Kaggle.png\" alt=\"drawing\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Discussion <a name='results'></a>\n",
    "\n",
    "## Models before EDA\n",
    "\n",
    "Below are the results from our Pre-EDA Experiment Log.\n",
    "\n",
    "<img src=\"../images/baseline_apptrain.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "The results of our baseline models constructed before EDA and feature aggregation were a good starting point. With only a modicum of complexity, we were able to establish an ROC-AUC score of 74.34%. Below are the details on phase I results:\n",
    "1. Initial run was considered with 14 features, 7 numerical and 7 categorical. We got training accuracy of 91.98%, test accuracy of 91.58% and AUC score as 73.57% for this very first model.\n",
    "   + Num cols : ‘AMT_INCOME_TOTAL',  'AMT_CREDIT','DAYS_EMPLOYED','DAYS_BIRTH','EXT_SOURCE_1', 'EXT_SOURCE_2','EXT_SOURCE_3’, \n",
    "   + Categorical Cols : 'CODE_GENDER','FLAG_OWN_REALTY','FLAG_OWN_CAR','NAME_CONTRACT_TYPE','NAME_EDUCATION_TYPE',             'OCCUPATION_TYPE', 'NAME_INCOME_TYPE'\n",
    "2. Next we considered all 120 elements form Application train table. Here we got a marginal increase to 92% train accuracy,  and 91.93% test accuracy. But there was improvement in AUC score, which was 74.34 % in this iteration.\n",
    "3. Next, we used a function to remove features which were more than 50% NULL. This led to a list of 79 features. There was very minute change in the test and train score. AUC score reduced from 74.34% to 74.06%. Although reducing the number of features was definitely a boost but we expect same or higher AUC score.\n",
    "4. Next, we log transformed 2 attributes which were highly skewed and used the features from run 3 from above step. This did not help either, we got same score as in last run up to first decimal point. 1 reason for this is because the attribute we log transformed had a big null percentage which didn’t really helped the score. \n",
    "\n",
    "Our Kaggle score for submission was 73.3 for this phase.\n",
    "\n",
    "## Model after EDA\n",
    "\n",
    "Below is the result from the Post-EDA Experiment Log.\n",
    "\n",
    "<img src=\"../images/baseline_allfeatures.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "After EDA with the new features added, our model performed significantly better with ROC-AUC scores averaging around 77%, with the highest being 77.09%. The inclusion of newly engineered features did help increase our scores, which was anyway our main goal for this phase of the project. \n",
    "\n",
    "Here we have taken all 1277 aggregated features for the pipeline run. As explained in the EDA part, we aggregated all features with \"min\", \"max\", \"count\", \"sum\", \"median\", \"mean\", and  \"var\" and subsequently rolled up all those to the main train and test tables. \n",
    "\n",
    "---\n",
    "\n",
    "We also created more features as part of our analysis on features:\n",
    "\n",
    "From POS: \n",
    "+ Percentage of installments pending.\n",
    "+ Number of installments pending.\n",
    "+ Days with Tolerance.\n",
    "\n",
    "From Previous Application:\n",
    "+ Count of approved previous application.\n",
    "+ Count of Rejected previous applications.\n",
    "+ Difference: Amount requested in application - Actual credit amount.\n",
    "+ Ratio - Ratio of application amount to amount credited.\n",
    "+ Ratio - Ratio of amount credited to amount annuity\n",
    "+ Ratio - Ratio of down payment to amount credited.\n",
    "\n",
    "From Installments payments: \n",
    "+ Difference of payment amount from installment amount.\n",
    "\n",
    "---\n",
    "\n",
    "Although we did not see much difference in test score but there was an increase in the test score by almost 1%. Scores were .9198 and .9209 respectively. But to expectations, there was a substantial increment in the test AUC score which now has the score of 77.09 %. This 3.6% increase in AUC score is deemed a good outcome. This was also evident in our Kaggle submission score of 76.17 %.\n",
    "\n",
    "In both the phases, by using pipelines and parameters, we kept data leakage at bay. See Kaggle Submission below:\n",
    "\n",
    "<img src=\"../images/p2Kaggle.png\" alt=\"drawing\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion <a name='conclusion'></a>\n",
    "\n",
    "The goal of this project is to predict an aplicant's default risk using data from the loan application, as well as past credit accounts. This is important as it will provide a way to more equitably provide loans to people with poor credit history. With the conclusion of Phase 2, Group 10 has accomplished the following tasks:\n",
    "\n",
    "1. Analyzed the data structures and relationships through visual and numerical exploratory data analysis.\n",
    "2. Transformed the normalized data tables into a denormalized input variable and integrated with the machine learning pipeline. \n",
    "3. Laid the foundation for future hyperparameter tuning and model engineering. \n",
    "\n",
    "One challenge was building a universal transformation method to apply to the tables. Group 10 solved this issue by initially analyzing the tables separately from one another, and then collaborating intensely once their table domain was understood to find the common transformation methods - also to identify where the table transformations must be different. \n",
    "\n",
    "Another challenge overcome was working with the large (2.7 gb) high-dimensional dataset. This was overcome by simplifying code, running code chunks in batches, and using GPU-enhanced computing methods like Google Collab. Also special thanks to Pragat for training the model on his machine for *hours* overnight. \n",
    "\n",
    "With a AUC-ROC score of 0.76 on the test data using the fully integrated dataset, this baseline pipeline shows logistic regression is a decent tool that can successfully use the massive amount of data to make predictions on applicant default risk. Furthermore, it shows an improvement when using *all* of the data as opposed to just data from the applications. \n",
    "\n",
    "In the next phase, we will focus on hyperparameter tuning, additional feature engineering and feature selection, and refining the overall machine-learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography <a name='bibliography'></a>\n",
    "\n",
    "1. https://towardsdatascience.com/using-the-missingno-python-library-to-identify-and-visualise- missing-data-prior-to-machine-learning-34c8c5b5f009\n",
    "2. https://www.analyticsvidhya.com/blog/2021/04/rapid-fire-eda-process-using-python-for-ml-implementation\n",
    "3. https://www.kaggle.com/code/ekrembayar/homecredit-default-risk-step-by-step-1st-notebook/notebook#8.-Installments-Payments ",
    " -some code was directly used from this notebook, as the code was so well written, and was used as a reference for EDA, as explanations were through.\n",
    "4. https://miykael.github.io/blog/2022/advanced_eda/\n",
    "5. Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. An Introduction to Statistical Learning : with Applications in R. Chapter 3. New York :Springer, 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dictionary <a name='datadict'></a>\n",
    "\n",
    "\n",
    "|     | Table                         | Row                          | Description                                                                                                                                                                                                                                                                            | Special                               | \n",
    "|-----|-------------------------------|------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------| \n",
    "| 1   | application_{train\\|test}.csv | SK_ID_CURR                   | ID of loan in our sample                                                                                                                                                                                                                                                               |                                       | \n",
    "| 2   | application_{train\\|test}.csv | TARGET                       | \"Target variable (1 - client with payment difficulties: he/she had late payment more than X days on at least one of the first Y installments of the loan in our sample, 0 - all other cases)\"                                                                                          |                                       | \n",
    "| 5   | application_{train\\|test}.csv | NAME_CONTRACT_TYPE           | Identification if loan is cash or revolving                                                                                                                                                                                                                                            |                                       | \n",
    "| 6   | application_{train\\|test}.csv | CODE_GENDER                  | Gender of the client                                                                                                                                                                                                                                                                   |                                       | \n",
    "| 7   | application_{train\\|test}.csv | FLAG_OWN_CAR                 | Flag if the client owns a car                                                                                                                                                                                                                                                          |                                       | \n",
    "| 8   | application_{train\\|test}.csv | FLAG_OWN_REALTY              | Flag if client owns a house or flat                                                                                                                                                                                                                                                    |                                       | \n",
    "| 9   | application_{train\\|test}.csv | CNT_CHILDREN                 | Number of children the client has                                                                                                                                                                                                                                                      |                                       | \n",
    "| 10  | application_{train\\|test}.csv | AMT_INCOME_TOTAL             | Income of the client                                                                                                                                                                                                                                                                   |                                       | \n",
    "| 11  | application_{train\\|test}.csv | AMT_CREDIT                   | Credit amount of the loan                                                                                                                                                                                                                                                              |                                       | \n",
    "| 12  | application_{train\\|test}.csv | AMT_ANNUITY                  | Loan annuity                                                                                                                                                                                                                                                                           |                                       | \n",
    "| 13  | application_{train\\|test}.csv | AMT_GOODS_PRICE              | For consumer loans it is the price of the goods for which the loan is given                                                                                                                                                                                                            |                                       | \n",
    "| 14  | application_{train\\|test}.csv | NAME_TYPE_SUITE              | Who was accompanying client when he was applying for the loan                                                                                                                                                                                                                          |                                       | \n",
    "| 15  | application_{train\\|test}.csv | NAME_INCOME_TYPE             | \"Clients income type (businessman, working, maternity leave,",
    ")\"                                                                                                                                                                                                                        |                                       | \n",
    "| 16  | application_{train\\|test}.csv | NAME_EDUCATION_TYPE          | Level of highest education the client achieved                                                                                                                                                                                                                                         |                                       | \n",
    "| 17  | application_{train\\|test}.csv | NAME_FAMILY_STATUS           | Family status of the client                                                                                                                                                                                                                                                            |                                       | \n",
    "| 18  | application_{train\\|test}.csv | NAME_HOUSING_TYPE            | \"What is the housing situation of the client (renting, living with parents, ...)\"                                                                                                                                                                                                      |                                       | \n",
    "| 19  | application_{train\\|test}.csv | REGION_POPULATION_RELATIVE   | Normalized population of region where client lives (higher number means the client lives in more populated region)                                                                                                                                                                     | normalized                            | \n",
    "| 20  | application_{train\\|test}.csv | DAYS_BIRTH                   | Client's age in days at the time of application                                                                                                                                                                                                                                        | time only relative to the application | \n",
    "| 21  | application_{train\\|test}.csv | DAYS_EMPLOYED                | How many days before the application the person started current employment                                                                                                                                                                                                             | time only relative to the application | \n",
    "| 22  | application_{train\\|test}.csv | DAYS_REGISTRATION            | How many days before the application did client change his registration                                                                                                                                                                                                                | time only relative to the application | \n",
    "| 23  | application_{train\\|test}.csv | DAYS_ID_PUBLISH              | How many days before the application did client change the identity document with which he applied for the loan                                                                                                                                                                        | time only relative to the application | \n",
    "| 24  | application_{train\\|test}.csv | OWN_CAR_AGE                  | Age of client's car                                                                                                                                                                                                                                                                    |                                       | \n",
    "| 25  | application_{train\\|test}.csv | FLAG_MOBIL                   | \"Did client provide mobile phone (1=YES, 0=NO)\"                                                                                                                                                                                                                                        |                                       | \n",
    "| 26  | application_{train\\|test}.csv | FLAG_EMP_PHONE               | \"Did client provide work phone (1=YES, 0=NO)\"                                                                                                                                                                                                                                          |                                       | \n",
    "| 27  | application_{train\\|test}.csv | FLAG_WORK_PHONE              | \"Did client provide home phone (1=YES, 0=NO)\"                                                                                                                                                                                                                                          |                                       | \n",
    "| 28  | application_{train\\|test}.csv | FLAG_CONT_MOBILE             | \"Was mobile phone reachable (1=YES, 0=NO)\"                                                                                                                                                                                                                                             |                                       | \n",
    "| 29  | application_{train\\|test}.csv | FLAG_PHONE                   | \"Did client provide home phone (1=YES, 0=NO)\"                                                                                                                                                                                                                                          |                                       | \n",
    "| 30  | application_{train\\|test}.csv | FLAG_EMAIL                   | \"Did client provide email (1=YES, 0=NO)\"                                                                                                                                                                                                                                               |                                       | \n",
    "| 31  | application_{train\\|test}.csv | OCCUPATION_TYPE              | What kind of occupation does the client have                                                                                                                                                                                                                                           |                                       | \n",
    "| 32  | application_{train\\|test}.csv | CNT_FAM_MEMBERS              | How many family members does client have                                                                                                                                                                                                                                               |                                       | \n",
    "| 33  | application_{train\\|test}.csv | REGION_RATING_CLIENT         | \"Our rating of the region where client lives (1,2,3)\"                                                                                                                                                                                                                                  |                                       | \n",
    "| 34  | application_{train\\|test}.csv | REGION_RATING_CLIENT_W_CITY  | \"Our rating of the region where client lives with taking city into account (1,2,3)\"                                                                                                                                                                                                    |                                       | \n",
    "| 35  | application_{train\\|test}.csv | WEEKDAY_APPR_PROCESS_START   | On which day of the week did the client apply for the loan                                                                                                                                                                                                                             |                                       | \n",
    "| 36  | application_{train\\|test}.csv | HOUR_APPR_PROCESS_START      | Approximately at what hour did the client apply for the loan                                                                                                                                                                                                                           | rounded                               | \n",
    "| 37  | application_{train\\|test}.csv | REG_REGION_NOT_LIVE_REGION   | \"Flag if client's permanent address does not match contact address (1=different, 0=same, at region level)\"                                                                                                                                                                             |                                       | \n",
    "| 38  | application_{train\\|test}.csv | REG_REGION_NOT_WORK_REGION   | \"Flag if client's permanent address does not match work address (1=different, 0=same, at region level)\"                                                                                                                                                                                |                                       | \n",
    "| 39  | application_{train\\|test}.csv | LIVE_REGION_NOT_WORK_REGION  | \"Flag if client's contact address does not match work address (1=different, 0=same, at region level)\"                                                                                                                                                                                  |                                       | \n",
    "| 40  | application_{train\\|test}.csv | REG_CITY_NOT_LIVE_CITY       | \"Flag if client's permanent address does not match contact address (1=different, 0=same, at city level)\"                                                                                                                                                                               |                                       | \n",
    "| 41  | application_{train\\|test}.csv | REG_CITY_NOT_WORK_CITY       | \"Flag if client's permanent address does not match work address (1=different, 0=same, at city level)\"                                                                                                                                                                                  |                                       | \n",
    "| 42  | application_{train\\|test}.csv | LIVE_CITY_NOT_WORK_CITY      | \"Flag if client's contact address does not match work address (1=different, 0=same, at city level)\"                                                                                                                                                                                    |                                       | \n",
    "| 43  | application_{train\\|test}.csv | ORGANIZATION_TYPE            | Type of organization where client works                                                                                                                                                                                                                                                |                                       | \n",
    "| 44  | application_{train\\|test}.csv | EXT_SOURCE_1                 | Normalized score from external data source                                                                                                                                                                                                                                             | normalized                            | \n",
    "| 45  | application_{train\\|test}.csv | EXT_SOURCE_2                 | Normalized score from external data source                                                                                                                                                                                                                                             | normalized                            | \n",
    "| 46  | application_{train\\|test}.csv | EXT_SOURCE_3                 | Normalized score from external data source                                                                                                                                                                                                                                             | normalized                            | \n",
    "| 47  | application_{train\\|test}.csv | APARTMENTS_AVG               | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 48  | application_{train\\|test}.csv | BASEMENTAREA_AVG             | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 49  | application_{train\\|test}.csv | YEARS_BEGINEXPLUATATION_AVG  | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 50  | application_{train\\|test}.csv | YEARS_BUILD_AVG              | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 51  | application_{train\\|test}.csv | COMMONAREA_AVG               | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 52  | application_{train\\|test}.csv | ELEVATORS_AVG                | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 53  | application_{train\\|test}.csv | ENTRANCES_AVG                | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 54  | application_{train\\|test}.csv | FLOORSMAX_AVG                | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 55  | application_{train\\|test}.csv | FLOORSMIN_AVG                | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 56  | application_{train\\|test}.csv | LANDAREA_AVG                 | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 57  | application_{train\\|test}.csv | LIVINGAPARTMENTS_AVG         | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 58  | application_{train\\|test}.csv | LIVINGAREA_AVG               | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 59  | application_{train\\|test}.csv | NONLIVINGAPARTMENTS_AVG      | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 60  | application_{train\\|test}.csv | NONLIVINGAREA_AVG            | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 61  | application_{train\\|test}.csv | APARTMENTS_MODE              | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 62  | application_{train\\|test}.csv | BASEMENTAREA_MODE            | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 63  | application_{train\\|test}.csv | YEARS_BEGINEXPLUATATION_MODE | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 64  | application_{train\\|test}.csv | YEARS_BUILD_MODE             | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 65  | application_{train\\|test}.csv | COMMONAREA_MODE              | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 66  | application_{train\\|test}.csv | ELEVATORS_MODE               | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 67  | application_{train\\|test}.csv | ENTRANCES_MODE               | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 68  | application_{train\\|test}.csv | FLOORSMAX_MODE               | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 69  | application_{train\\|test}.csv | FLOORSMIN_MODE               | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 70  | application_{train\\|test}.csv | LANDAREA_MODE                | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 71  | application_{train\\|test}.csv | LIVINGAPARTMENTS_MODE        | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 72  | application_{train\\|test}.csv | LIVINGAREA_MODE              | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 73  | application_{train\\|test}.csv | NONLIVINGAPARTMENTS_MODE     | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 74  | application_{train\\|test}.csv | NONLIVINGAREA_MODE           | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 75  | application_{train\\|test}.csv | APARTMENTS_MEDI              | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 76  | application_{train\\|test}.csv | BASEMENTAREA_MEDI            | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 77  | application_{train\\|test}.csv | YEARS_BEGINEXPLUATATION_MEDI | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 78  | application_{train\\|test}.csv | YEARS_BUILD_MEDI             | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 79  | application_{train\\|test}.csv | COMMONAREA_MEDI              | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 80  | application_{train\\|test}.csv | ELEVATORS_MEDI               | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 81  | application_{train\\|test}.csv | ENTRANCES_MEDI               | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 82  | application_{train\\|test}.csv | FLOORSMAX_MEDI               | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 83  | application_{train\\|test}.csv | FLOORSMIN_MEDI               | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 84  | application_{train\\|test}.csv | LANDAREA_MEDI                | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 85  | application_{train\\|test}.csv | LIVINGAPARTMENTS_MEDI        | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 86  | application_{train\\|test}.csv | LIVINGAREA_MEDI              | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 87  | application_{train\\|test}.csv | NONLIVINGAPARTMENTS_MEDI     | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 88  | application_{train\\|test}.csv | NONLIVINGAREA_MEDI           | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 89  | application_{train\\|test}.csv | FONDKAPREMONT_MODE           | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 90  | application_{train\\|test}.csv | HOUSETYPE_MODE               | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 91  | application_{train\\|test}.csv | TOTALAREA_MODE               | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 92  | application_{train\\|test}.csv | WALLSMATERIAL_MODE           | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 93  | application_{train\\|test}.csv | EMERGENCYSTATE_MODE          | \"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\" | normalized                            | \n",
    "| 94  | application_{train\\|test}.csv | OBS_30_CNT_SOCIAL_CIRCLE     | How many observation of client's social surroundings with observable 30 DPD (days past due) default                                                                                                                                                                                    |                                       | \n",
    "| 95  | application_{train\\|test}.csv | DEF_30_CNT_SOCIAL_CIRCLE     | How many observation of client's social surroundings defaulted on 30 DPD (days past due)                                                                                                                                                                                               |                                       | \n",
    "| 96  | application_{train\\|test}.csv | OBS_60_CNT_SOCIAL_CIRCLE     | How many observation of client's social surroundings with observable 60 DPD (days past due) default                                                                                                                                                                                    |                                       | \n",
    "| 97  | application_{train\\|test}.csv | DEF_60_CNT_SOCIAL_CIRCLE     | How many observation of client's social surroundings defaulted on 60 (days past due) DPD                                                                                                                                                                                               |                                       | \n",
    "| 98  | application_{train\\|test}.csv | DAYS_LAST_PHONE_CHANGE       | How many days before application did client change phone                                                                                                                                                                                                                               |                                       | \n",
    "| 99  | application_{train\\|test}.csv | FLAG_DOCUMENT_2              | Did client provide document 2                                                                                                                                                                                                                                                          |                                       | \n",
    "| 100 | application_{train\\|test}.csv | FLAG_DOCUMENT_3              | Did client provide document 3                                                                                                                                                                                                                                                          |                                       | \n",
    "| 101 | application_{train\\|test}.csv | FLAG_DOCUMENT_4              | Did client provide document 4                                                                                                                                                                                                                                                          |                                       | \n",
    "| 102 | application_{train\\|test}.csv | FLAG_DOCUMENT_5              | Did client provide document 5                                                                                                                                                                                                                                                          |                                       | \n",
    "| 103 | application_{train\\|test}.csv | FLAG_DOCUMENT_6              | Did client provide document 6                                                                                                                                                                                                                                                          |                                       | \n",
    "| 104 | application_{train\\|test}.csv | FLAG_DOCUMENT_7              | Did client provide document 7                                                                                                                                                                                                                                                          |                                       | \n",
    "| 105 | application_{train\\|test}.csv | FLAG_DOCUMENT_8              | Did client provide document 8                                                                                                                                                                                                                                                          |                                       | \n",
    "| 106 | application_{train\\|test}.csv | FLAG_DOCUMENT_9              | Did client provide document 9                                                                                                                                                                                                                                                          |                                       | \n",
    "| 107 | application_{train\\|test}.csv | FLAG_DOCUMENT_10             | Did client provide document 10                                                                                                                                                                                                                                                         |                                       | \n",
    "| 108 | application_{train\\|test}.csv | FLAG_DOCUMENT_11             | Did client provide document 11                                                                                                                                                                                                                                                         |                                       | \n",
    "| 109 | application_{train\\|test}.csv | FLAG_DOCUMENT_12             | Did client provide document 12                                                                                                                                                                                                                                                         |                                       | \n",
    "| 110 | application_{train\\|test}.csv | FLAG_DOCUMENT_13             | Did client provide document 13                                                                                                                                                                                                                                                         |                                       | \n",
    "| 111 | application_{train\\|test}.csv | FLAG_DOCUMENT_14             | Did client provide document 14                                                                                                                                                                                                                                                         |                                       | \n",
    "| 112 | application_{train\\|test}.csv | FLAG_DOCUMENT_15             | Did client provide document 15                                                                                                                                                                                                                                                         |                                       | \n",
    "| 113 | application_{train\\|test}.csv | FLAG_DOCUMENT_16             | Did client provide document 16                                                                                                                                                                                                                                                         |                                       | \n",
    "| 114 | application_{train\\|test}.csv | FLAG_DOCUMENT_17             | Did client provide document 17                                                                                                                                                                                                                                                         |                                       | \n",
    "| 115 | application_{train\\|test}.csv | FLAG_DOCUMENT_18             | Did client provide document 18                                                                                                                                                                                                                                                         |                                       | \n",
    "| 116 | application_{train\\|test}.csv | FLAG_DOCUMENT_19             | Did client provide document 19                                                                                                                                                                                                                                                         |                                       | \n",
    "| 117 | application_{train\\|test}.csv | FLAG_DOCUMENT_20             | Did client provide document 20                                                                                                                                                                                                                                                         |                                       | \n",
    "| 118 | application_{train\\|test}.csv | FLAG_DOCUMENT_21             | Did client provide document 21                                                                                                                                                                                                                                                         |                                       | \n",
    "| 119 | application_{train\\|test}.csv | AMT_REQ_CREDIT_BUREAU_HOUR   | Number of enquiries to Credit Bureau about the client one hour before application                                                                                                                                                                                                      |                                       | \n",
    "| 120 | application_{train\\|test}.csv | AMT_REQ_CREDIT_BUREAU_DAY    | Number of enquiries to Credit Bureau about the client one day before application (excluding one hour before application)                                                                                                                                                               |                                       | \n",
    "| 121 | application_{train\\|test}.csv | AMT_REQ_CREDIT_BUREAU_WEEK   | Number of enquiries to Credit Bureau about the client one week before application (excluding one day before application)                                                                                                                                                               |                                       | \n",
    "| 122 | application_{train\\|test}.csv | AMT_REQ_CREDIT_BUREAU_MON    | Number of enquiries to Credit Bureau about the client one month before application (excluding one week before application)                                                                                                                                                             |                                       | \n",
    "| 123 | application_{train\\|test}.csv | AMT_REQ_CREDIT_BUREAU_QRT    | Number of enquiries to Credit Bureau about the client 3 month before application (excluding one month before application)                                                                                                                                                              |                                       | \n",
    "| 124 | application_{train\\|test}.csv | AMT_REQ_CREDIT_BUREAU_YEAR   | Number of enquiries to Credit Bureau about the client one day year (excluding last 3 months before application)                                                                                                                                                                        |                                       | \n",
    "| 125 | bureau.csv                    | SK_ID_CURR                   | \"ID of loan in our sample - one loan in our sample can have 0,1,2 or more related previous credits in credit bureau \"                                                                                                                                                                  | hashed                                | \n",
    "| 126 | bureau.csv                    | SK_BUREAU_ID                 | Recoded ID of previous Credit Bureau credit related to our loan (unique coding for each loan application)                                                                                                                                                                              | hashed                                | \n",
    "| 127 | bureau.csv                    | CREDIT_ACTIVE                | Status of the Credit Bureau (CB) reported credits                                                                                                                                                                                                                                      |                                       | \n",
    "| 128 | bureau.csv                    | CREDIT_CURRENCY              | Recoded currency of the Credit Bureau credit                                                                                                                                                                                                                                           | recoded                               | \n",
    "| 129 | bureau.csv                    | DAYS_CREDIT                  | How many days before current application did client apply for Credit Bureau credit                                                                                                                                                                                                     | time only relative to the application | \n",
    "| 130 | bureau.csv                    | CREDIT_DAY_OVERDUE           | Number of days past due on CB credit at the time of application for related loan in our sample                                                                                                                                                                                         |                                       | \n",
    "| 131 | bureau.csv                    | DAYS_CREDIT_ENDDATE          | Remaining duration of CB credit (in days) at the time of application in Home Credit                                                                                                                                                                                                    | time only relative to the application | \n",
    "| 132 | bureau.csv                    | DAYS_ENDDATE_FACT            | Days since CB credit ended at the time of application in Home Credit (only for closed credit)                                                                                                                                                                                          | time only relative to the application | \n",
    "| 133 | bureau.csv                    | AMT_CREDIT_MAX_OVERDUE       | Maximal amount overdue on the Credit Bureau credit so far (at application date of loan in our sample)                                                                                                                                                                                  |                                       | \n",
    "| 134 | bureau.csv                    | CNT_CREDIT_PROLONG           | How many times was the Credit Bureau credit prolonged                                                                                                                                                                                                                                  |                                       | \n",
    "| 135 | bureau.csv                    | AMT_CREDIT_SUM               | Current credit amount for the Credit Bureau credit                                                                                                                                                                                                                                     |                                       | \n",
    "| 136 | bureau.csv                    | AMT_CREDIT_SUM_DEBT          | Current debt on Credit Bureau credit                                                                                                                                                                                                                                                   |                                       | \n",
    "| 137 | bureau.csv                    | AMT_CREDIT_SUM_LIMIT         | Current credit limit of credit card reported in Credit Bureau                                                                                                                                                                                                                          |                                       | \n",
    "| 138 | bureau.csv                    | AMT_CREDIT_SUM_OVERDUE       | Current amount overdue on Credit Bureau credit                                                                                                                                                                                                                                         |                                       | \n",
    "| 139 | bureau.csv                    | CREDIT_TYPE                  | \"Type of Credit Bureau credit (Car, cash,...)\"                                                                                                                                                                                                                                         |                                       | \n",
    "| 140 | bureau.csv                    | DAYS_CREDIT_UPDATE           | How many days before loan application did last information about the Credit Bureau credit come                                                                                                                                                                                         | time only relative to the application | \n",
    "| 141 | bureau.csv                    | AMT_ANNUITY                  | Annuity of the Credit Bureau credit                                                                                                                                                                                                                                                    |                                       | \n",
    "| 142 | bureau_balance.csv            | SK_BUREAU_ID                 | Recoded ID of Credit Bureau credit (unique coding for each application) - use this to join to CREDIT_BUREAU table                                                                                                                                                                      | hashed                                | \n",
    "| 143 | bureau_balance.csv            | MONTHS_BALANCE               | Month of balance relative to application date (-1 means the freshest balance date)                                                                                                                                                                                                     | time only relative to the application | \n",
    "| 144 | bureau_balance.csv            | STATUS                       | \"Status of Credit Bureau loan during the month (active, closed, DPD0-30,",
    " [C means closed, X means status unknown, 0 means no DPD, 1 means maximal did during month between 1-30, 2 means DPD 31-60,",
    " 5 means DPD 120+ or sold or written off ] )\"                                     |                                       | \n",
    "| 145 | POS_CASH_balance.csv          | SK_ID_PREV                   | \"ID of previous credit in Home Credit related to loan in our sample. (One loan in our sample can have 0,1,2 or more previous loans in Home Credit)\"                                                                                                                                    |                                       | \n",
    "| 146 | POS_CASH_balance.csv          | SK_ID_CURR                   | ID of loan in our sample                                                                                                                                                                                                                                                               |                                       | \n",
    "| 147 | POS_CASH_balance.csv          | MONTHS_BALANCE               | \"Month of balance relative to application date (-1 means the information to the freshest monthly snapshot, 0 means the information at application - often it will be the same as -1 as many banks are not updating the information to Credit Bureau regularly )\"                       | time only relative to the application | \n",
    "| 148 | POS_CASH_balance.csv          | CNT_INSTALMENT               | Term of previous credit (can change over time)                                                                                                                                                                                                                                         |                                       | \n",
    "| 149 | POS_CASH_balance.csv          | CNT_INSTALMENT_FUTURE        | Installments left to pay on the previous credit                                                                                                                                                                                                                                        |                                       | \n",
    "| 150 | POS_CASH_balance.csv          | NAME_CONTRACT_STATUS         | Contract status during the month                                                                                                                                                                                                                                                       |                                       | \n",
    "| 151 | POS_CASH_balance.csv          | SK_DPD                       | DPD (days past due) during the month of previous credit                                                                                                                                                                                                                                |                                       | \n",
    "| 152 | POS_CASH_balance.csv          | SK_DPD_DEF                   | DPD during the month with tolerance (debts with low loan amounts are ignored) of the previous credit                                                                                                                                                                                   |                                       | \n",
    "| 153 | credit_card_balance.csv       | SK_ID_PREV                   | \"ID of previous credit in Home credit related to loan in our sample. (One loan in our sample can have 0,1,2 or more previous loans in Home Credit)\"                                                                                                                                    | hashed                                | \n",
    "| 154 | credit_card_balance.csv       | SK_ID_CURR                   | ID of loan in our sample                                                                                                                                                                                                                                                               | hashed                                | \n",
    "| 155 | credit_card_balance.csv       | MONTHS_BALANCE               | Month of balance relative to application date (-1 means the freshest balance date)                                                                                                                                                                                                     | time only relative to the application | \n",
    "| 156 | credit_card_balance.csv       | AMT_BALANCE                  | Balance during the month of previous credit                                                                                                                                                                                                                                            |                                       | \n",
    "| 157 | credit_card_balance.csv       | AMT_CREDIT_LIMIT_ACTUAL      | Credit card limit during the month of the previous credit                                                                                                                                                                                                                              |                                       | \n",
    "| 158 | credit_card_balance.csv       | AMT_DRAWINGS_ATM_CURRENT     | Amount drawing at ATM during the month of the previous credit                                                                                                                                                                                                                          |                                       | \n",
    "| 159 | credit_card_balance.csv       | AMT_DRAWINGS_CURRENT         | Amount drawing during the month of the previous credit                                                                                                                                                                                                                                 |                                       | \n",
    "| 160 | credit_card_balance.csv       | AMT_DRAWINGS_OTHER_CURRENT   | Amount of other drawings during the month of the previous credit                                                                                                                                                                                                                       |                                       | \n",
    "| 161 | credit_card_balance.csv       | AMT_DRAWINGS_POS_CURRENT     | Amount drawing or buying goods during the month of the previous credit                                                                                                                                                                                                                 |                                       | \n",
    "| 162 | credit_card_balance.csv       | AMT_INST_MIN_REGULARITY      | Minimal installment for this month of the previous credit                                                                                                                                                                                                                              |                                       | \n",
    "| 163 | credit_card_balance.csv       | AMT_PAYMENT_CURRENT          | How much did the client pay during the month on the previous credit                                                                                                                                                                                                                    |                                       | \n",
    "| 164 | credit_card_balance.csv       | AMT_PAYMENT_TOTAL_CURRENT    | How much did the client pay during the month in total on the previous credit                                                                                                                                                                                                           |                                       | \n",
    "| 165 | credit_card_balance.csv       | AMT_RECEIVABLE_PRINCIPAL     | Amount receivable for principal on the previous credit                                                                                                                                                                                                                                 |                                       | \n",
    "| 166 | credit_card_balance.csv       | AMT_RECIVABLE                | Amount receivable on the previous credit                                                                                                                                                                                                                                               |                                       | \n",
    "| 167 | credit_card_balance.csv       | AMT_TOTAL_RECEIVABLE         | Total amount receivable on the previous credit                                                                                                                                                                                                                                         |                                       | \n",
    "| 168 | credit_card_balance.csv       | CNT_DRAWINGS_ATM_CURRENT     | Number of drawings at ATM during this month on the previous credit                                                                                                                                                                                                                     |                                       | \n",
    "| 169 | credit_card_balance.csv       | CNT_DRAWINGS_CURRENT         | Number of drawings during this month on the previous credit                                                                                                                                                                                                                            |                                       | \n",
    "| 170 | credit_card_balance.csv       | CNT_DRAWINGS_OTHER_CURRENT   | Number of other drawings during this month on the previous credit                                                                                                                                                                                                                      |                                       | \n",
    "| 171 | credit_card_balance.csv       | CNT_DRAWINGS_POS_CURRENT     | Number of drawings for goods during this month on the previous credit                                                                                                                                                                                                                  |                                       | \n",
    "| 172 | credit_card_balance.csv       | CNT_INSTALMENT_MATURE_CUM    | Number of paid installments on the previous credit                                                                                                                                                                                                                                     |                                       | \n",
    "| 173 | credit_card_balance.csv       | NAME_CONTRACT_STATUS         | \"Contract status (active signed,...) on the previous credit\"                                                                                                                                                                                                                           |                                       | \n",
    "| 174 | credit_card_balance.csv       | SK_DPD                       | DPD (Days past due) during the month on the previous credit                                                                                                                                                                                                                            |                                       | \n",
    "| 175 | credit_card_balance.csv       | SK_DPD_DEF                   | DPD (Days past due) during the month with tolerance (debts with low loan amounts are ignored) of the previous credit                                                                                                                                                                   |                                       | \n",
    "| 176 | previous_application.csv      | SK_ID_PREV                   | \"ID of previous credit in Home credit related to loan in our sample. (One loan in our sample can have 0,1,2 or more previous loan applications in Home Credit, previous application could, but not necessarily have to lead to credit) \"                                               | hashed                                | \n",
    "| 177 | previous_application.csv      | SK_ID_CURR                   | ID of loan in our sample                                                                                                                                                                                                                                                               | hashed                                | \n",
    "| 178 | previous_application.csv      | NAME_CONTRACT_TYPE           | \"Contract product type (Cash loan, consumer loan [POS] ,...) of the previous application\"                                                                                                                                                                                              |                                       | \n",
    "| 179 | previous_application.csv      | AMT_ANNUITY                  | Annuity of previous application                                                                                                                                                                                                                                                        |                                       | \n",
    "| 180 | previous_application.csv      | AMT_APPLICATION              | For how much credit did client ask on the previous application                                                                                                                                                                                                                         |                                       | \n",
    "| 181 | previous_application.csv      | AMT_CREDIT                   | \"Final credit amount on the previous application. This differs from AMT_APPLICATION in a way that the AMT_APPLICATION is the amount for which the client initially applied for, but during our approval process he could have received different amount - AMT_CREDIT\"                  |                                       | \n",
    "| 182 | previous_application.csv      | AMT_DOWN_PAYMENT             | Down payment on the previous application                                                                                                                                                                                                                                               |                                       | \n",
    "| 183 | previous_application.csv      | AMT_GOODS_PRICE              | Goods price of good that client asked for (if applicable) on the previous application                                                                                                                                                                                                  |                                       | \n",
    "| 184 | previous_application.csv      | WEEKDAY_APPR_PROCESS_START   | On which day of the week did the client apply for previous application                                                                                                                                                                                                                 |                                       | \n",
    "| 185 | previous_application.csv      | HOUR_APPR_PROCESS_START      | Approximately at what day hour did the client apply for the previous application                                                                                                                                                                                                       | rounded                               | \n",
    "| 186 | previous_application.csv      | FLAG_LAST_APPL_PER_CONTRACT  | Flag if it was last application for the previous contract. Sometimes by mistake of client or our clerk there could be more applications for one single contract                                                                                                                        |                                       | \n",
    "| 187 | previous_application.csv      | NFLAG_LAST_APPL_IN_DAY       | Flag if the application was the last application per day of the client. Sometimes clients apply for more applications a day. Rarely it could also be error in our system that one application is in the database twice                                                                 |                                       | \n",
    "| 188 | previous_application.csv      | NFLAG_MICRO_CASH             | Flag Micro finance loan                                                                                                                                                                                                                                                                |                                       | \n",
    "| 189 | previous_application.csv      | RATE_DOWN_PAYMENT            | Down payment rate normalized on previous credit                                                                                                                                                                                                                                        | normalized                            | \n",
    "| 190 | previous_application.csv      | RATE_INTEREST_PRIMARY        | Interest rate normalized on previous credit                                                                                                                                                                                                                                            | normalized                            | \n",
    "| 191 | previous_application.csv      | RATE_INTEREST_PRIVILEGED     | Interest rate normalized on previous credit                                                                                                                                                                                                                                            | normalized                            | \n",
    "| 192 | previous_application.csv      | NAME_CASH_LOAN_PURPOSE       | Purpose of the cash loan                                                                                                                                                                                                                                                               |                                       | \n",
    "| 193 | previous_application.csv      | NAME_CONTRACT_STATUS         | \"Contract status (approved, cancelled, ...) of previous application\"                                                                                                                                                                                                                   |                                       | \n",
    "| 194 | previous_application.csv      | DAYS_DECISION                | Relative to current application when was the decision about previous application made                                                                                                                                                                                                  | time only relative to the application | \n",
    "| 195 | previous_application.csv      | NAME_PAYMENT_TYPE            | Payment method that client chose to pay for the previous application                                                                                                                                                                                                                   |                                       | \n",
    "| 196 | previous_application.csv      | CODE_REJECT_REASON           | Why was the previous application rejected                                                                                                                                                                                                                                              |                                       | \n",
    "| 197 | previous_application.csv      | NAME_TYPE_SUITE              | Who accompanied client when applying for the previous application                                                                                                                                                                                                                      |                                       | \n",
    "| 198 | previous_application.csv      | NAME_CLIENT_TYPE             | Was the client old or new client when applying for the previous application                                                                                                                                                                                                            |                                       | \n",
    "| 199 | previous_application.csv      | NAME_GOODS_CATEGORY          | What kind of goods did the client apply for in the previous application                                                                                                                                                                                                                |                                       | \n",
    "| 200 | previous_application.csv      | NAME_PORTFOLIO               | \"Was the previous application for CASH, POS, CAR, ",
    "\"                                                                                                                                                                                                                                   |                                       | \n",
    "| 201 | previous_application.csv      | NAME_PRODUCT_TYPE            | Was the previous application x-sell o walk-in                                                                                                                                                                                                                                          |                                       | \n",
    "| 202 | previous_application.csv      | CHANNEL_TYPE                 | Through which channel we acquired the client on the previous application                                                                                                                                                                                                               |                                       | \n",
    "| 203 | previous_application.csv      | SELLERPLACE_AREA             | Selling area of seller place of the previous application                                                                                                                                                                                                                               |                                       | \n",
    "| 204 | previous_application.csv      | NAME_SELLER_INDUSTRY         | The industry of the seller                                                                                                                                                                                                                                                             |                                       | \n",
    "| 205 | previous_application.csv      | CNT_PAYMENT                  | Term of previous credit at application of the previous application                                                                                                                                                                                                                     |                                       | \n",
    "| 206 | previous_application.csv      | NAME_YIELD_GROUP             | Grouped interest rate into small medium and high of the previous application                                                                                                                                                                                                           | grouped                               | \n",
    "| 207 | previous_application.csv      | PRODUCT_COMBINATION          | Detailed product combination of the previous application                                                                                                                                                                                                                               |                                       | \n",
    "| 208 | previous_application.csv      | DAYS_FIRST_DRAWING           | Relative to application date of current application when was the first disbursement of the previous application                                                                                                                                                                        | time only relative to the application | \n",
    "| 209 | previous_application.csv      | DAYS_FIRST_DUE               | Relative to application date of current application when was the first due supposed to be of the previous application                                                                                                                                                                  | time only relative to the application | \n",
    "| 210 | previous_application.csv      | DAYS_LAST_DUE_1ST_VERSION    | Relative to application date of current application when was the first due of the previous application                                                                                                                                                                                 | time only relative to the application | \n",
    "| 211 | previous_application.csv      | DAYS_LAST_DUE                | Relative to application date of current application when was the last due date of the previous application                                                                                                                                                                             | time only relative to the application | \n",
    "| 212 | previous_application.csv      | DAYS_TERMINATION             | Relative to application date of current application when was the expected termination of the previous application                                                                                                                                                                      | time only relative to the application | \n",
    "| 213 | previous_application.csv      | NFLAG_INSURED_ON_APPROVAL    | Did the client requested insurance during the previous application                                                                                                                                                                                                                     |                                       | \n",
    "| 214 | installments_payments.csv     | SK_ID_PREV                   | \"ID of previous credit in Home credit related to loan in our sample. (One loan in our sample can have 0,1,2 or more previous loans in Home Credit)\"                                                                                                                                    | hashed                                | \n",
    "| 215 | installments_payments.csv     | SK_ID_CURR                   | ID of loan in our sample                                                                                                                                                                                                                                                               | hashed                                | \n",
    "| 216 | installments_payments.csv     | NUM_INSTALMENT_VERSION       | Version of installment calendar (0 is for credit card) of previous credit. Change of installment version from month to month signifies that some parameter of payment calendar has changed                                                                                             |                                       | \n",
    "| 217 | installments_payments.csv     | NUM_INSTALMENT_NUMBER        | On which installment we observe payment                                                                                                                                                                                                                                                |                                       | \n",
    "| 218 | installments_payments.csv     | DAYS_INSTALMENT              | When the installment of previous credit was supposed to be paid (relative to application date of current loan)                                                                                                                                                                         | time only relative to the application | \n",
    "| 219 | installments_payments.csv     | DAYS_ENTRY_PAYMENT           | When was the installments of previous credit paid actually (relative to application date of current loan)                                                                                                                                                                              | time only relative to the application | \n",
    "| 220 | installments_payments.csv     | AMT_INSTALMENT               | What was the prescribed installment amount of previous credit on this installment                                                                                                                                                                                                      |                                       | \n",
    "| 221 | installments_payments.csv     | AMT_PAYMENT                  | What the client actually paid on previous credit on this installment                                                                                                                                                                                                                   |                                       | \n",
    "|     |                               |                              |                                                                                                                                                                                                                                                                                        |                                       | \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "329.625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
