{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0AG1yF50c0N"
   },
   "source": [
    "# Collinearity Reducer HCDR Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vW-DkS2mTZ69",
    "outputId": "0c8643ff-e18f-4fcf-9fd9-6d8317e41151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDo68G3t0gxq"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4__MiCS81mGz"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "p-dlcHT1FvM7"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9J-pHtE0jva"
   },
   "source": [
    "### Custom Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AjaTemryA3e5"
   },
   "outputs": [],
   "source": [
    "# transformer reduces the list of columns by a subset\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "# transformer produces a reduced column list by collinearity reduction\n",
    "class CollinearityReducer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    '''\n",
    "    This class reduces features by measuring collinearity between the input variables and target.\n",
    "    Works on numerical features based on the correlations between each variable pair.\n",
    "    Of the var1iable pairs with absolute correlations above the threshold value...\n",
    "    ...the variables with the lowest target variable correlation are dropped from the input X.\n",
    "    The process is repeated until there are no more colinear pairs with absolute correlations above the threshold.\n",
    "    ...Or max_iter. \n",
    "    \n",
    "    The transformation returns a subset of feature names... \n",
    "    ...to be used with the DataFrameSelector() Class. \n",
    "\n",
    "    This class is meant to be run at the end of the numerical pipeline\n",
    "    PRIOR TO THE ACTUAL PIPELINE - only returns subset for DataFrameSelector().\n",
    "\n",
    "    NOTE! The function receives a dataframe structured with the target variable in first column.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, attribute_names, threshold=0.5, max_iter=None):\n",
    "        self.attribute_names = attribute_names\n",
    "        self.threshold = threshold\n",
    "        self.max_iter = max_iter\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None): \n",
    "        \n",
    "        dataframe = pd.concat([y, pd.DataFrame(X)], axis=1)\n",
    "        \n",
    "        i = 0\n",
    "        while i <= self.max_iter:\n",
    "\n",
    "            # read-in and assign columns\n",
    "            # gets correlation matrix between variables and pivots to a longer df\n",
    "            # identify target variable\n",
    "            # drop same-name and target correlations pairs\n",
    "              \n",
    "            df = dataframe\n",
    "            features = df.iloc[:,1:].columns\n",
    "            target_name = df.iloc[:,0].name\n",
    "\n",
    "            df = pd.melt(abs(df.corr()).reset_index(), id_vars='index', value_vars=features)\n",
    "            targets = df[df['index']==target_name]\n",
    "            df = df[(df['index'] != df['variable']) & (df['index'] != target_name) & (df['variable'] != target_name)]\n",
    "\n",
    "            # combine the correlated variables into ordered pairs\n",
    "            # aggregate the max correlation and sort pairs\n",
    "            # split out the variables from the pair\n",
    "            # join the target variable correlations for each variable pair, rename columns\n",
    "\n",
    "            df['joined'] = df[['index', 'variable']].apply(lambda row: '::'.join(np.sort(row.values.astype(str))), axis=1)\n",
    "\n",
    "            df = df.groupby('joined', as_index=False) \\\n",
    "                   .agg({'value':'max'}) \\\n",
    "                   .sort_values(by='value', ascending=False)\n",
    "\n",
    "            df[['var_1','var_2']] = df['joined'].str.split(\"::\",expand=True).astype(int)\n",
    "\n",
    "            df = df.merge(targets, how='left', left_on='var_1', right_on='variable') \\\n",
    "                   .merge(targets, how='left', left_on='var_2', right_on='variable')\n",
    "            df.rename(columns = {'value_x':'var_pair_corr', 'value_y':'var_1_target_corr', 'value':'var_2_target_corr'}, inplace = True)\n",
    "\n",
    "            # This section takes all variable pairs with a correlation greater than threshold\n",
    "            # tests to determine which variable has a higher correlation with the target.\n",
    "            # The higher of the two gets marked as a win\n",
    "            # While the other gets marked as a loss\n",
    "            # the wins and losses for each variable are then grouped and summed\n",
    "\n",
    "            exceeds = df[df['var_pair_corr']>self.threshold]\n",
    "\n",
    "            # break if none above threshold\n",
    "            if len(exceeds['var_pair_corr'])==0:\n",
    "                break\n",
    "\n",
    "            # \"correlation competition\"\n",
    "            exceeds['var_1_win'] = exceeds.apply(lambda row: 1 if row[\"var_1_target_corr\"] >= row[\"var_2_target_corr\"] else 0, axis=1)\n",
    "            exceeds['var_1_loss'] = exceeds.apply(lambda row: 1 if row[\"var_2_target_corr\"] >= row[\"var_1_target_corr\"] else 0, axis=1)\n",
    "            exceeds['var_2_win'] = exceeds.apply(lambda row: 1 if row[\"var_1_target_corr\"] < row[\"var_2_target_corr\"] else 0, axis=1)\n",
    "            exceeds['var_2_loss'] = exceeds.apply(lambda row: 1 if row[\"var_2_target_corr\"] < row[\"var_1_target_corr\"] else 0, axis=1)\n",
    "\n",
    "            # aggregate scores\n",
    "            var1 = exceeds[['var_1', 'var_1_win', 'var_1_loss']].groupby('var_1', as_index=False) \\\n",
    "                                                                .agg({'var_1_win':'sum', 'var_1_loss':'sum'})\n",
    "            var1.rename(columns = {'var_1':'var', 'var_1_win':'win', 'var_1_loss':'loss'}, inplace=True)\n",
    "\n",
    "            var2 = exceeds[['var_2', 'var_2_win', 'var_2_loss']].groupby('var_2', as_index=False) \\\n",
    "                                                                .agg({'var_2_win':'sum', 'var_2_loss':'sum'})\n",
    "            var2.rename(columns = {'var_2':'var', 'var_2_win':'win', 'var_2_loss':'loss'}, inplace=True)\n",
    "\n",
    "            corrcomps = pd.concat([var1,var2], axis=0).groupby('var', as_index=False) \\\n",
    "                                                      .agg({'win':'sum', 'loss':'sum'})\n",
    "\n",
    "            # drop variables which had 0 wins - IE collinear variables which were always least related to the target\n",
    "            dropvars = corrcomps[corrcomps['win']==0]['var']\n",
    "\n",
    "            dataframe = dataframe.drop(dropvars, axis=1)  \n",
    "\n",
    "            i += 1  \n",
    "        \n",
    "        X = [self.attribute_names[col] for col in dataframe.columns]\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvEZVk640s23"
   },
   "source": [
    "### Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "70zdSCUMA30F"
   },
   "outputs": [],
   "source": [
    "# function identifies missing data\n",
    "def missing_data(data):\n",
    "    total = data.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent']) \n",
    "\n",
    "\n",
    "# function to identify different feature types and summary EDA\n",
    "def id_num_cat_feature(df,text = True):\n",
    "    numerical = df.select_dtypes(include=np.number).columns\n",
    "    categorical = df.select_dtypes(include=['object', 'bool', 'category']).columns\n",
    "    feat_num = list(numerical)\n",
    "    feat_cat = list(categorical)\n",
    "    \n",
    "    id_cols = ['SK_ID_CURR','SK_ID_BUREAU']\n",
    "    \n",
    "    id_cols = [cols for cols in  list(df.columns.intersection(id_cols))] \n",
    "    features = list(set(df.columns) - set(id_cols))\n",
    "\n",
    "    if text == True:\n",
    "          # print eda\n",
    "        print('--------')\n",
    "        print(f\"# of ID's: {len(id_cols)}\")\n",
    "        print(f\" ID's:\")\n",
    "        print(id_cols)\n",
    "        print('')\n",
    "        print('--------')\n",
    "        print(f\"# All features: {len(features)}\")\n",
    "        print(f\"All features:\")\n",
    "        print(features)\n",
    "        print('')\n",
    "        print(f\"Missing data:\")\n",
    "        print(missing_data(df[features]))\n",
    "        print('')\n",
    "        print('--------')\n",
    "        print(f\"# of Numerical features: {len(feat_num)}\")\n",
    "        print(f\"Numerical features:\")\n",
    "        print(feat_num)\n",
    "        print('')\n",
    "        print(f\"Numerical Statistical Summary:\")\n",
    "        print('')\n",
    "        print(df[feat_num].describe())\n",
    "        print('')\n",
    "        print('--------')\n",
    "        print(f\"# of Categorical features: {len(feat_cat)}\")\n",
    "        print(f\"Categorical features:\")\n",
    "        print(feat_cat)\n",
    "        print('')\n",
    "        print(f\"Categorical Statistical Summary:\")\n",
    "        print('')\n",
    "        #print(df[feat_cat].describe(include='all'))\n",
    "        print('')\n",
    "        print(\"Categories:\")\n",
    "        print('')\n",
    "        print(df[feat_cat].apply(lambda col: col.unique()))\n",
    "        print('')\n",
    "        print('--------')\n",
    "        \n",
    "    return id_cols,feat_num,feat_cat,features\n",
    "\n",
    "\n",
    "# https://pythonsimplified.com/how-to-handle-large-datasets-in-python-with-pandas/\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**3\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**3\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY-aqM5W04hl"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZ8dzHAt1pvM"
   },
   "source": [
    "### Read-In and Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWvkmBxpA32r",
    "outputId": "c5b8f562-9d36-4346-b5aa-1067a170e7f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "application_train\n",
      "Memory usage of dataframe is 0.28 MB\n",
      "Memory usage after optimization is: 0.06 MB\n",
      "Decreased by 79.2%\n",
      "---\n",
      "bureau_agg_data_trans_untrans\n",
      "Memory usage of dataframe is 0.72 MB\n",
      "Memory usage after optimization is: 0.21 MB\n",
      "Decreased by 70.6%\n",
      "---\n",
      "ip_agg_data_tr\n",
      "Memory usage of dataframe is 0.17 MB\n",
      "Memory usage after optimization is: 0.06 MB\n",
      "Decreased by 63.4%\n",
      "---\n",
      "pos_agg_data_tr\n",
      "Memory usage of dataframe is 0.34 MB\n",
      "Memory usage after optimization is: 0.09 MB\n",
      "Decreased by 73.3%\n",
      "---\n",
      "prevapp_agg_data_tr\n",
      "Memory usage of dataframe is 1.73 MB\n",
      "Memory usage after optimization is: 0.46 MB\n",
      "Decreased by 73.2%\n"
     ]
    }
   ],
   "source": [
    "# read-in\n",
    "DATA_DIR =  \"/drive/MyDrive/ColabNotebooks/\"\n",
    "\n",
    "ds_names = (\n",
    "    # [\"bureau_ip_ccb_prev_pos_merged\"]\n",
    "    \"application_train\", \"bureau_agg_data_trans_untrans\",  # \"application_test\", \n",
    "    \"ip_agg_data_tr\", \"pos_agg_data_tr\", \"prevapp_agg_data_tr\"\n",
    "    # \"ccb_agg_data_tr\",\n",
    ")  \n",
    "\n",
    "datasets_agg = {}\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    print('---')\n",
    "    print(ds_name)\n",
    "    datasets_agg[ds_name] = pd.read_csv(os.getcwd() + DATA_DIR + f'{ds_name}.csv')\n",
    "    datasets_agg[ds_name] = reduce_mem_usage(datasets_agg[ds_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kAs9q2XTUrqA"
   },
   "outputs": [],
   "source": [
    "# denormalize and clean text\n",
    "for ds_name in datasets_agg:\n",
    "    if ds_name == 'application_train':\n",
    "        agg_data = datasets_agg['application_train'].replace(to_replace='\\s+', value='_', regex=True) \\\n",
    "                                                    .replace(to_replace='\\-', value='_', regex=True) \\\n",
    "                                                    .replace(to_replace='\\/', value='_', regex=True) \\\n",
    "                                                    .replace(to_replace='\\(', value='', regex=True) \\\n",
    "                                                    .replace(to_replace='\\)', value='', regex=True) \\\n",
    "                                                    .replace(to_replace='\\:', value='', regex=True) \\\n",
    "                                                    .replace(to_replace='\\,', value='', regex=True)\n",
    "    else:\n",
    "        agg_data = agg_data.merge(datasets_agg[ds_name], on='SK_ID_CURR', how='left')\n",
    "\n",
    "\n",
    "agg_data = agg_data.loc[:,~agg_data.columns.str.startswith('Unnamed:')]\n",
    "agg_data = agg_data.loc[:,~agg_data.columns.str.startswith('SK_ID_PREV')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiZElhxhsMe_",
    "outputId": "27734fb6-9d39-444e-c464-0a97468623a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SK_ID_CURR', 'TARGET', 'NAME_CONTRACT_TYPE', 'CODE_GENDER',\n",
       "       'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL',\n",
       "       'AMT_CREDIT', 'AMT_ANNUITY',\n",
       "       ...\n",
       "       'PA_O_NAME_GOODS_CATEGORY_Other_median',\n",
       "       'PA_O_NAME_GOODS_CATEGORY_Other_mean',\n",
       "       'PA_O_NAME_GOODS_CATEGORY_Other_var',\n",
       "       'PA_O_NAME_SELLER_INDUSTRY_XNA_median',\n",
       "       'PA_O_NAME_SELLER_INDUSTRY_XNA_mean',\n",
       "       'PA_O_NAME_SELLER_INDUSTRY_XNA_var',\n",
       "       'PA_O_NAME_CASH_LOAN_PURPOSE_Urgent needs_median',\n",
       "       'PA_O_NAME_CASH_LOAN_PURPOSE_Urgent needs_mean',\n",
       "       'PA_O_NAME_CASH_LOAN_PURPOSE_Urgent needs_var',\n",
       "       'PS_O_SK_ID_PREV_count_y'],\n",
       "      dtype='object', length=1318)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7gyiRiE1JQC"
   },
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0v9NqWR1SgS"
   },
   "source": [
    "### Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "63Vsk2C1nwr7",
    "outputId": "ea796449-6d8b-4eb1-a551-10800d9bd6d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train           shape: (19680, 1316)\n",
      "X validation      shape: (4921, 1316)\n",
      "X test            shape: (6151, 1316)\n",
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "{'rf__max_depth': 100, 'rf__min_samples_leaf': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c39250b3-a267-4182-af4b-311bc2529f92\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_name</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Valid Acc</th>\n",
       "      <th>Test  Acc</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Valid AUC</th>\n",
       "      <th>Test  AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1xgb_agg_trans_no-cr_{'xgb__subsample': 0.8}</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.8590</td>\n",
       "      <td>0.7521</td>\n",
       "      <td>0.7472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1xgb_agg_trans_cr:0.5-10_{'xgb__subsample': ...</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>0.8522</td>\n",
       "      <td>0.7612</td>\n",
       "      <td>0.7438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1xgb_agg_trans_cr:0.5-25_{'xgb__subsample': ...</td>\n",
       "      <td>0.9224</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.7570</td>\n",
       "      <td>0.7492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1RF_agg_trans_{'rf__max_depth': 100, 'rf__mi...</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.7119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c39250b3-a267-4182-af4b-311bc2529f92')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c39250b3-a267-4182-af4b-311bc2529f92 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c39250b3-a267-4182-af4b-311bc2529f92');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            exp_name  Train Acc  Valid Acc  \\\n",
       "0     0.1xgb_agg_trans_no-cr_{'xgb__subsample': 0.8}     0.9227     0.9193   \n",
       "1  0.1xgb_agg_trans_cr:0.5-10_{'xgb__subsample': ...     0.9227     0.9195   \n",
       "2  0.1xgb_agg_trans_cr:0.5-25_{'xgb__subsample': ...     0.9224     0.9187   \n",
       "3  0.1RF_agg_trans_{'rf__max_depth': 100, 'rf__mi...     0.9193     0.9193   \n",
       "\n",
       "   Test  Acc  Train AUC  Valid AUC  Test  AUC  \n",
       "0     0.9192     0.8590     0.7521     0.7472  \n",
       "1     0.9187     0.8522     0.7612     0.7438  \n",
       "2     0.9185     0.8459     0.7570     0.7492  \n",
       "3     0.9192     0.9135     0.7133     0.7119  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "# create train, validation, and test sets\n",
    "y = agg_data['TARGET']\n",
    "X = agg_data.drop(['SK_ID_CURR', 'TARGET'], axis = 1) #drop some features with questionable value\n",
    "\n",
    "\n",
    "_, X, _, y = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_valid.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "print(f\"X train           shape: {X_train.shape}\")\n",
    "print(f\"X validation      shape: {X_valid.shape}\")\n",
    "print(f\"X test            shape: {X_test.shape}\")\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "### Collinear Feature Reduction\n",
    "\n",
    "# determine feature types, reduce numerical features by collinearity reduction\n",
    "id_col, feat_num, feat_cat, feature =  id_num_cat_feature(X, text = False)\n",
    "\n",
    "# cr = make_pipeline(\n",
    "#     SimpleImputer(strategy='median'),\n",
    "#     StandardScaler(),    \n",
    "#     CollinearityReducer(attribute_names=feat_num, threshold = 0.5, max_iter=25)\n",
    "# )\n",
    "\n",
    "# tic = time.perf_counter()\n",
    "# reduced_feat_num = cr.fit_transform(X_train[feat_num], y_train) \n",
    "# toc = time.perf_counter()\n",
    "\n",
    "# print(f\"Collinearity Reduction completed in {toc - tic:0.4f} seconds.\")\n",
    "# print(f'Reduced numerical column count from {len(feat_num)}...')\n",
    "# print(f'...to {len(reduced_feat_num)} by collinearity reduction.')\n",
    "\n",
    "### Main Pipeline\n",
    "\n",
    "# Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    # ('selector', DataFrameSelector(reduced_feat_num)),\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "data_pipeline = ColumnTransformer(transformers=[\n",
    "    (\"num_pipeline\", num_pipeline, feat_num),\n",
    "    (\"cat_pipeline\", cat_pipeline, feat_cat)],\n",
    "    remainder='drop',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "    (\"preparation\", data_pipeline),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "max_depth = [5, 10, 25, 50, 100]\n",
    "min_samples_leaf = [5, 10, 25, 50, 100]\n",
    "\n",
    "parameters = dict(\n",
    "    rf__max_depth = max_depth,\n",
    "    rf__min_samples_leaf = min_samples_leaf\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    full_pipeline_with_predictor, param_grid= parameters, \n",
    "    cv = 3, n_jobs=4, scoring='roc_auc', verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "# get results of pipeline from validation and test sets for accuracy and AUC-ROC\n",
    "try:\n",
    "    expLog\n",
    "except NameError:\n",
    "    expLog = pd.DataFrame(columns=[\"exp_name\", \n",
    "                                   \"Train Acc\", \n",
    "                                   \"Valid Acc\",\n",
    "                                   \"Test  Acc\",\n",
    "                                   \"Train AUC\", \n",
    "                                   \"Valid AUC\",\n",
    "                                   \"Test  AUC\"\n",
    "                                  ])\n",
    "\n",
    "exp_name = f\"0.1RF_agg_trans_{grid.best_params_}\"\n",
    "expLog.loc[len(expLog)] = [f\"{exp_name}\"] + list(np.round(\n",
    "               [accuracy_score(y_train, grid.predict(X_train)), \n",
    "                accuracy_score(y_valid, grid.predict(X_valid)),\n",
    "                accuracy_score(y_test, grid.predict(X_test)),\n",
    "                roc_auc_score(y_train, grid.predict_proba(X_train)[:, 1]),\n",
    "                roc_auc_score(y_valid, grid.predict_proba(X_valid)[:, 1]),\n",
    "                roc_auc_score(y_test, grid.predict_proba(X_test)[:, 1])],\n",
    "    4)) \n",
    "expLog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "hqk60Spjn5r7",
    "outputId": "42ff8138-671b-43b3-f8e0-61b18cb3e5b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train           shape: (19680, 1316)\n",
      "X validation      shape: (4921, 1316)\n",
      "X test            shape: (6151, 1316)\n",
      "Collinearity Reduction completed in 984.5254 seconds.\n",
      "Reduced numerical column count from 1300...\n",
      "...to 525 by collinearity reduction.\n",
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "{'rf__max_depth': 50, 'rf__min_samples_leaf': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-50c2c2c5-fae6-4c0a-aa8b-48f8afa17d30\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_name</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Valid Acc</th>\n",
       "      <th>Test  Acc</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Valid AUC</th>\n",
       "      <th>Test  AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1xgb_agg_trans_no-cr_{'xgb__subsample': 0.8}</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.8590</td>\n",
       "      <td>0.7521</td>\n",
       "      <td>0.7472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1xgb_agg_trans_cr:0.5-10_{'xgb__subsample': ...</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>0.8522</td>\n",
       "      <td>0.7612</td>\n",
       "      <td>0.7438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1xgb_agg_trans_cr:0.5-25_{'xgb__subsample': ...</td>\n",
       "      <td>0.9224</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.7570</td>\n",
       "      <td>0.7492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1RF_agg_trans_{'rf__max_depth': 100, 'rf__mi...</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.7119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1RF_agg_trans_cr:0.5-25_{'rf__max_depth': 50...</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9090</td>\n",
       "      <td>0.7188</td>\n",
       "      <td>0.7045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50c2c2c5-fae6-4c0a-aa8b-48f8afa17d30')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-50c2c2c5-fae6-4c0a-aa8b-48f8afa17d30 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-50c2c2c5-fae6-4c0a-aa8b-48f8afa17d30');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            exp_name  Train Acc  Valid Acc  \\\n",
       "0     0.1xgb_agg_trans_no-cr_{'xgb__subsample': 0.8}     0.9227     0.9193   \n",
       "1  0.1xgb_agg_trans_cr:0.5-10_{'xgb__subsample': ...     0.9227     0.9195   \n",
       "2  0.1xgb_agg_trans_cr:0.5-25_{'xgb__subsample': ...     0.9224     0.9187   \n",
       "3  0.1RF_agg_trans_{'rf__max_depth': 100, 'rf__mi...     0.9193     0.9193   \n",
       "4  0.1RF_agg_trans_cr:0.5-25_{'rf__max_depth': 50...     0.9193     0.9193   \n",
       "\n",
       "   Test  Acc  Train AUC  Valid AUC  Test  AUC  \n",
       "0     0.9192     0.8590     0.7521     0.7472  \n",
       "1     0.9187     0.8522     0.7612     0.7438  \n",
       "2     0.9185     0.8459     0.7570     0.7492  \n",
       "3     0.9192     0.9135     0.7133     0.7119  \n",
       "4     0.9192     0.9090     0.7188     0.7045  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "# create train, validation, and test sets\n",
    "y = agg_data['TARGET']\n",
    "X = agg_data.drop(['SK_ID_CURR', 'TARGET'], axis = 1) #drop some features with questionable value\n",
    "\n",
    "\n",
    "_, X, _, y = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_valid.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "print(f\"X train           shape: {X_train.shape}\")\n",
    "print(f\"X validation      shape: {X_valid.shape}\")\n",
    "print(f\"X test            shape: {X_test.shape}\")\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "### Collinear Feature Reduction\n",
    "\n",
    "# determine feature types, reduce numerical features by collinearity reduction\n",
    "id_col, feat_num, feat_cat, feature =  id_num_cat_feature(X, text = False)\n",
    "\n",
    "cr = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    StandardScaler(),    \n",
    "    CollinearityReducer(attribute_names=feat_num, threshold = 0.5, max_iter=25)\n",
    ")\n",
    "\n",
    "tic = time.perf_counter()\n",
    "reduced_feat_num = cr.fit_transform(X_train[feat_num], y_train) \n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f\"Collinearity Reduction completed in {toc - tic:0.4f} seconds.\")\n",
    "print(f'Reduced numerical column count from {len(feat_num)}...')\n",
    "print(f'...to {len(reduced_feat_num)} by collinearity reduction.')\n",
    "\n",
    "### Main Pipeline\n",
    "\n",
    "# Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(reduced_feat_num)),\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "data_pipeline = ColumnTransformer(transformers=[\n",
    "    (\"num_pipeline\", num_pipeline, feat_num),\n",
    "    (\"cat_pipeline\", cat_pipeline, feat_cat)],\n",
    "    remainder='drop',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "    (\"preparation\", data_pipeline),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "max_depth = [5, 10, 25, 50, 100]\n",
    "min_samples_leaf = [5, 10, 25, 50, 100]\n",
    "\n",
    "parameters = dict(\n",
    "    rf__max_depth = max_depth,\n",
    "    rf__min_samples_leaf = min_samples_leaf\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    full_pipeline_with_predictor, param_grid= parameters, \n",
    "    cv = 3, n_jobs=4, scoring='roc_auc', verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "# get results of pipeline from validation and test sets for accuracy and AUC-ROC\n",
    "try:\n",
    "    expLog\n",
    "except NameError:\n",
    "    expLog = pd.DataFrame(columns=[\"exp_name\", \n",
    "                                   \"Train Acc\", \n",
    "                                   \"Valid Acc\",\n",
    "                                   \"Test  Acc\",\n",
    "                                   \"Train AUC\", \n",
    "                                   \"Valid AUC\",\n",
    "                                   \"Test  AUC\"\n",
    "                                  ])\n",
    "\n",
    "exp_name = f\"0.1RF_agg_trans_cr:0.5-25_{grid.best_params_}\"\n",
    "expLog.loc[len(expLog)] = [f\"{exp_name}\"] + list(np.round(\n",
    "               [accuracy_score(y_train, grid.predict(X_train)), \n",
    "                accuracy_score(y_valid, grid.predict(X_valid)),\n",
    "                accuracy_score(y_test, grid.predict(X_test)),\n",
    "                roc_auc_score(y_train, grid.predict_proba(X_train)[:, 1]),\n",
    "                roc_auc_score(y_valid, grid.predict_proba(X_valid)[:, 1]),\n",
    "                roc_auc_score(y_test, grid.predict_proba(X_test)[:, 1])],\n",
    "    4)) \n",
    "expLog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "QzKuLQO0oCCI",
    "outputId": "0ea5e45f-364c-480d-ca94-07f7936c1a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train           shape: (19680, 1316)\n",
      "X validation      shape: (4921, 1316)\n",
      "X test            shape: (6151, 1316)\n",
      "Collinearity Reduction completed in 1245.9714 seconds.\n",
      "Reduced numerical column count from 1300...\n",
      "...to 599 by collinearity reduction.\n",
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "{'rf__max_depth': 100, 'rf__min_samples_leaf': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8dc6f66a-08dd-4315-8853-c5f79faee3f4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_name</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Valid Acc</th>\n",
       "      <th>Test  Acc</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Valid AUC</th>\n",
       "      <th>Test  AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1xgb_agg_trans_no-cr_{'xgb__subsample': 0.8}</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.8590</td>\n",
       "      <td>0.7521</td>\n",
       "      <td>0.7472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1xgb_agg_trans_cr:0.5-10_{'xgb__subsample': ...</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>0.8522</td>\n",
       "      <td>0.7612</td>\n",
       "      <td>0.7438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1xgb_agg_trans_cr:0.5-25_{'xgb__subsample': ...</td>\n",
       "      <td>0.9224</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.7570</td>\n",
       "      <td>0.7492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1RF_agg_trans_{'rf__max_depth': 100, 'rf__mi...</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.7119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1RF_agg_trans_cr:0.5-25_{'rf__max_depth': 50...</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9090</td>\n",
       "      <td>0.7188</td>\n",
       "      <td>0.7045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1RF_agg_trans_cr:0.35-25_{'rf__max_depth': 1...</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9061</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.7000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dc6f66a-08dd-4315-8853-c5f79faee3f4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8dc6f66a-08dd-4315-8853-c5f79faee3f4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8dc6f66a-08dd-4315-8853-c5f79faee3f4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            exp_name  Train Acc  Valid Acc  \\\n",
       "0     0.1xgb_agg_trans_no-cr_{'xgb__subsample': 0.8}     0.9227     0.9193   \n",
       "1  0.1xgb_agg_trans_cr:0.5-10_{'xgb__subsample': ...     0.9227     0.9195   \n",
       "2  0.1xgb_agg_trans_cr:0.5-25_{'xgb__subsample': ...     0.9224     0.9187   \n",
       "3  0.1RF_agg_trans_{'rf__max_depth': 100, 'rf__mi...     0.9193     0.9193   \n",
       "4  0.1RF_agg_trans_cr:0.5-25_{'rf__max_depth': 50...     0.9193     0.9193   \n",
       "5  0.1RF_agg_trans_cr:0.35-25_{'rf__max_depth': 1...     0.9193     0.9193   \n",
       "\n",
       "   Test  Acc  Train AUC  Valid AUC  Test  AUC  \n",
       "0     0.9192     0.8590     0.7521     0.7472  \n",
       "1     0.9187     0.8522     0.7612     0.7438  \n",
       "2     0.9185     0.8459     0.7570     0.7492  \n",
       "3     0.9192     0.9135     0.7133     0.7119  \n",
       "4     0.9192     0.9090     0.7188     0.7045  \n",
       "5     0.9192     0.9061     0.7073     0.7000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "# create train, validation, and test sets\n",
    "y = agg_data['TARGET']\n",
    "X = agg_data.drop(['SK_ID_CURR', 'TARGET'], axis = 1) #drop some features with questionable value\n",
    "\n",
    "\n",
    "_, X, _, y = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_valid.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "print(f\"X train           shape: {X_train.shape}\")\n",
    "print(f\"X validation      shape: {X_valid.shape}\")\n",
    "print(f\"X test            shape: {X_test.shape}\")\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "### Collinear Feature Reduction\n",
    "\n",
    "# determine feature types, reduce numerical features by collinearity reduction\n",
    "id_col, feat_num, feat_cat, feature =  id_num_cat_feature(X, text = False)\n",
    "\n",
    "cr = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    StandardScaler(),    \n",
    "    CollinearityReducer(attribute_names=feat_num, threshold = 0.35, max_iter=25)\n",
    ")\n",
    "\n",
    "tic = time.perf_counter()\n",
    "reduced_feat_num = cr.fit_transform(X_train[feat_num], y_train) \n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f\"Collinearity Reduction completed in {toc - tic:0.4f} seconds.\")\n",
    "print(f'Reduced numerical column count from {len(feat_num)}...')\n",
    "print(f'...to {len(reduced_feat_num)} by collinearity reduction.')\n",
    "\n",
    "### Main Pipeline\n",
    "\n",
    "# Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(reduced_feat_num)),\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "data_pipeline = ColumnTransformer(transformers=[\n",
    "    (\"num_pipeline\", num_pipeline, feat_num),\n",
    "    (\"cat_pipeline\", cat_pipeline, feat_cat)],\n",
    "    remainder='drop',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "    (\"preparation\", data_pipeline),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "max_depth = [5, 10, 25, 50, 100]\n",
    "min_samples_leaf = [5, 10, 25, 50, 100]\n",
    "\n",
    "parameters = dict(\n",
    "    rf__max_depth = max_depth,\n",
    "    rf__min_samples_leaf = min_samples_leaf\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    full_pipeline_with_predictor, param_grid= parameters, \n",
    "    cv = 3, n_jobs=4, scoring='roc_auc', verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "# get results of pipeline from validation and test sets for accuracy and AUC-ROC\n",
    "try:\n",
    "    expLog\n",
    "except NameError:\n",
    "    expLog = pd.DataFrame(columns=[\"exp_name\", \n",
    "                                   \"Train Acc\", \n",
    "                                   \"Valid Acc\",\n",
    "                                   \"Test  Acc\",\n",
    "                                   \"Train AUC\", \n",
    "                                   \"Valid AUC\",\n",
    "                                   \"Test  AUC\"\n",
    "                                  ])\n",
    "\n",
    "exp_name = f\"0.1RF_agg_trans_cr:0.35-25_{grid.best_params_}\"\n",
    "expLog.loc[len(expLog)] = [f\"{exp_name}\"] + list(np.round(\n",
    "               [accuracy_score(y_train, grid.predict(X_train)), \n",
    "                accuracy_score(y_valid, grid.predict(X_valid)),\n",
    "                accuracy_score(y_test, grid.predict(X_test)),\n",
    "                roc_auc_score(y_train, grid.predict_proba(X_train)[:, 1]),\n",
    "                roc_auc_score(y_valid, grid.predict_proba(X_valid)[:, 1]),\n",
    "                roc_auc_score(y_test, grid.prebdict_proba(X_test)[:, 1])],\n",
    "    4)) \n",
    "expLog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCXPJVkUU3Ch"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "# create train, validation, and test sets\n",
    "y = agg_data['TARGET']\n",
    "X = agg_data.drop(['SK_ID_CURR', 'TARGET'], axis = 1) #drop some features with questionable value\n",
    "\n",
    "\n",
    "_, X, _, y = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_valid.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "print(f\"X train           shape: {X_train.shape}\")\n",
    "print(f\"X validation      shape: {X_valid.shape}\")\n",
    "print(f\"X test            shape: {X_test.shape}\")\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "### Collinear Feature Reduction\n",
    "\n",
    "# determine feature types, reduce numerical features by collinearity reduction\n",
    "id_col, feat_num, feat_cat, feature =  id_num_cat_feature(X, text = False)\n",
    "\n",
    "cr = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    StandardScaler(),    \n",
    "    CollinearityReducer(attribute_names=feat_num, threshold = 0.6, max_iter=50)\n",
    ")\n",
    "\n",
    "tic = time.perf_counter()\n",
    "reduced_feat_num = cr.fit_transform(X_train[feat_num], y_train) \n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f\"Collinearity Reduction completed in {toc - tic:0.4f} seconds.\")\n",
    "print(f'Reduced numerical column count from {len(feat_num)}...')\n",
    "print(f'...to {len(reduced_feat_num)} by collinearity reduction.')\n",
    "\n",
    "### Main Pipeline\n",
    "\n",
    "# Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(reduced_feat_num)),\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "data_pipeline = ColumnTransformer(transformers=[\n",
    "    (\"num_pipeline\", num_pipeline, feat_num),\n",
    "    (\"cat_pipeline\", cat_pipeline, feat_cat)],\n",
    "    remainder='drop',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "    (\"preparation\", data_pipeline),\n",
    "    ('xgb', xgb.XGBClassifier(n_jobs=-1))\n",
    "])\n",
    "\n",
    "max_depth = [5, 10, 25, 50, 100]\n",
    "min_samples_leaf = [5, 10, 25, 50, 100]\n",
    "\n",
    "# https://www.datasnips.com/5/tuning-xgboost-with-grid-search/\n",
    "parameters = dict(\n",
    "    xgb__subsample = [0.5, 0.75, 1],\n",
    "    xgb__colsample_bytree = [0.5, 0.75, 1],\n",
    "    xgb__max_depth = [5, 15, 30],\n",
    "    xgb__min_child_weight = [1,5,15],\n",
    "    xgb__learning_rate = [0.3, 0.1, 0.03],\n",
    "    xgb__n_estimators = [100]\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    full_pipeline_with_predictor, param_grid= parameters, \n",
    "    cv = 3, n_jobs=4, scoring='roc_auc', verbose=2\n",
    ")\n",
    "\n",
    "eval_set = [(X_train, y_train), (X_valid, y_valid)]\n",
    "\n",
    "grid.fit(X_train, y_train, early_stopping_rounds=10, eval_metric=[\"error\", \"logloss\"],eval_set=eval_set, verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUxes34x8o3S"
   },
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "\n",
    "# get results of pipeline from validation and test sets for accuracy and AUC-ROC\n",
    "try:\n",
    "    expLog\n",
    "except NameError:\n",
    "    expLog = pd.DataFrame(columns=[\"exp_name\", \n",
    "                                   \"Train Acc\", \n",
    "                                   \"Valid Acc\",\n",
    "                                   \"Test  Acc\",\n",
    "                                   \"Train AUC\", \n",
    "                                   \"Valid AUC\",\n",
    "                                   \"Test  AUC\"\n",
    "                                  ])\n",
    "\n",
    "exp_name = f\"0.1xgb_agg_trans_cr:0.6-50_{grid.best_params_}\"\n",
    "expLog.loc[len(expLog)] = [f\"{exp_name}\"] + list(np.round(\n",
    "               [accuracy_score(y_train, grid.predict(X_train)), \n",
    "                accuracy_score(y_valid, grid.predict(X_valid)),\n",
    "                accuracy_score(y_test, grid.predict(X_test)),\n",
    "                roc_auc_score(y_train, grid.predict_proba(X_train)[:, 1]),\n",
    "                roc_auc_score(y_valid, grid.predict_proba(X_valid)[:, 1]),\n",
    "                roc_auc_score(y_test, grid.prebdict_proba(X_test)[:, 1])],\n",
    "    4)) \n",
    "expLog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtC13g1q9Iji"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# retrieve performance metrics\n",
    "results = grid.evals_result()\n",
    "epochs = len(results['validation_0']['error'])\n",
    "x_axis = range(0, epochs)\n",
    "# plot log loss\n",
    "fig, ax = pyplot.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['logloss'], label='Valid')\n",
    "ax.legend()\n",
    "pyplot.ylabel('Log Loss')\n",
    "pyplot.title('XGBoost Log Loss')\n",
    "pyplot.grid()\n",
    "pyplot.show()\n",
    "# plot classification error\n",
    "fig, ax = pyplot.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['error'], label='Valid')\n",
    "ax.legend()\n",
    "pyplot.ylabel('Classification Error')\n",
    "pyplot.title('XGBoost Classification Error')\n",
    "pyplot.grid()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "mEexhGtY-BGE",
    "outputId": "61a17b1b-177a-4e42-e99f-eb5a33255d1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train           shape: (19680, 1316)\n",
      "X validation      shape: (4921, 1316)\n",
      "X test            shape: (6151, 1316)\n",
      "Collinearity Reduction completed in 1473.1862 seconds.\n",
      "Reduced numerical column count from 1300...\n",
      "...to 481 by collinearity reduction.\n",
      "Fitting 3 folds for each of 675 candidates, totalling 2025 fits\n",
      "{'rf__bootstrap': False, 'rf__max_depth': 26, 'rf__max_features': 5, 'rf__min_samples_leaf': 10, 'rf__min_samples_split': 10, 'rf__n_estimators': 300}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-92727fbf-d67c-4e46-a2b4-028d7aa97f3e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_name</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Valid Acc</th>\n",
       "      <th>Test  Acc</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Valid AUC</th>\n",
       "      <th>Test  AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1xgb_agg_trans_no-cr_{'xgb__subsample': 0.8}</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.8590</td>\n",
       "      <td>0.7521</td>\n",
       "      <td>0.7472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1xgb_agg_trans_cr:0.5-10_{'xgb__subsample': ...</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.9195</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>0.8522</td>\n",
       "      <td>0.7612</td>\n",
       "      <td>0.7438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1xgb_agg_trans_cr:0.5-25_{'xgb__subsample': ...</td>\n",
       "      <td>0.9224</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.7570</td>\n",
       "      <td>0.7492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1RF_agg_trans_{'rf__max_depth': 100, 'rf__mi...</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.7119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1RF_agg_trans_cr:0.5-25_{'rf__max_depth': 50...</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9090</td>\n",
       "      <td>0.7188</td>\n",
       "      <td>0.7045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1RF_agg_trans_cr:0.35-25_{'rf__max_depth': 1...</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9061</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1RF_agg_trans_cr:0.5-50_{'rf__bootstrap': Fa...</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9192</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>0.6873</td>\n",
       "      <td>0.6828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92727fbf-d67c-4e46-a2b4-028d7aa97f3e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-92727fbf-d67c-4e46-a2b4-028d7aa97f3e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-92727fbf-d67c-4e46-a2b4-028d7aa97f3e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            exp_name  Train Acc  Valid Acc  \\\n",
       "0     0.1xgb_agg_trans_no-cr_{'xgb__subsample': 0.8}     0.9227     0.9193   \n",
       "1  0.1xgb_agg_trans_cr:0.5-10_{'xgb__subsample': ...     0.9227     0.9195   \n",
       "2  0.1xgb_agg_trans_cr:0.5-25_{'xgb__subsample': ...     0.9224     0.9187   \n",
       "3  0.1RF_agg_trans_{'rf__max_depth': 100, 'rf__mi...     0.9193     0.9193   \n",
       "4  0.1RF_agg_trans_cr:0.5-25_{'rf__max_depth': 50...     0.9193     0.9193   \n",
       "5  0.1RF_agg_trans_cr:0.35-25_{'rf__max_depth': 1...     0.9193     0.9193   \n",
       "6  0.1RF_agg_trans_cr:0.5-50_{'rf__bootstrap': Fa...     0.9193     0.9193   \n",
       "\n",
       "   Test  Acc  Train AUC  Valid AUC  Test  AUC  \n",
       "0     0.9192     0.8590     0.7521     0.7472  \n",
       "1     0.9187     0.8522     0.7612     0.7438  \n",
       "2     0.9185     0.8459     0.7570     0.7492  \n",
       "3     0.9192     0.9135     0.7133     0.7119  \n",
       "4     0.9192     0.9090     0.7188     0.7045  \n",
       "5     0.9192     0.9061     0.7073     0.7000  \n",
       "6     0.9192     0.9953     0.6873     0.6828  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "# create train, validation, and test sets\n",
    "y = agg_data['TARGET']\n",
    "X = agg_data.drop(['SK_ID_CURR', 'TARGET'], axis = 1) #drop some features with questionable value\n",
    "\n",
    "\n",
    "_, X, _, y = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_valid.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "print(f\"X train           shape: {X_train.shape}\")\n",
    "print(f\"X validation      shape: {X_valid.shape}\")\n",
    "print(f\"X test            shape: {X_test.shape}\")\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "### Collinear Feature Reduction\n",
    "\n",
    "# determine feature types, reduce numerical features by collinearity reduction\n",
    "id_col, feat_num, feat_cat, feature =  id_num_cat_feature(X, text = False)\n",
    "\n",
    "cr = make_pipeline(\n",
    "    SimpleImputer(strategy='median'),\n",
    "    StandardScaler(),    \n",
    "    CollinearityReducer(attribute_names=feat_num, threshold = 0.5, max_iter=50)\n",
    ")\n",
    "\n",
    "tic = time.perf_counter()\n",
    "reduced_feat_num = cr.fit_transform(X_train[feat_num], y_train) \n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(f\"Collinearity Reduction completed in {toc - tic:0.4f} seconds.\")\n",
    "print(f'Reduced numerical column count from {len(feat_num)}...')\n",
    "print(f'...to {len(reduced_feat_num)} by collinearity reduction.')\n",
    "\n",
    "### Main Pipeline\n",
    "\n",
    "# Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(reduced_feat_num)),\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "data_pipeline = ColumnTransformer(transformers=[\n",
    "    (\"num_pipeline\", num_pipeline, feat_num),\n",
    "    (\"cat_pipeline\", cat_pipeline, feat_cat)],\n",
    "    remainder='drop',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "    (\"preparation\", data_pipeline),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "max_depth = [5, 10, 25, 50, 100]\n",
    "min_samples_leaf = [5, 10, 25, 50, 100]\n",
    "\n",
    "parameters = dict(\n",
    "            rf__max_depth = [9, 15, 22, 26, 30],\n",
    "            rf__max_features = [1, 3, 5],\n",
    "            rf__min_samples_split= [5, 10, 15],\n",
    "            rf__min_samples_leaf = [3, 5, 10],\n",
    "            rf__bootstrap = [False],\n",
    "            rf__n_estimators = [20, 80, 150, 200, 300]\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    full_pipeline_with_predictor, param_grid= parameters, \n",
    "    cv = 3, n_jobs=4, scoring='roc_auc', verbose=2\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "# get results of pipeline from validation and test sets for accuracy and AUC-ROC\n",
    "try:\n",
    "    expLog\n",
    "except NameError:\n",
    "    expLog = pd.DataFrame(columns=[\"exp_name\", \n",
    "                                   \"Train Acc\", \n",
    "                                   \"Valid Acc\",\n",
    "                                   \"Test  Acc\",\n",
    "                                   \"Train AUC\", \n",
    "                                   \"Valid AUC\",\n",
    "                                   \"Test  AUC\"\n",
    "                                  ])\n",
    "\n",
    "exp_name = f\"0.1RF_agg_trans_cr:0.5-50_{grid.best_params_}\"\n",
    "expLog.loc[len(expLog)] = [f\"{exp_name}\"] + list(np.round(\n",
    "               [accuracy_score(y_train, grid.predict(X_train)), \n",
    "                accuracy_score(y_valid, grid.predict(X_valid)),\n",
    "                accuracy_score(y_test, grid.predict(X_test)),\n",
    "                roc_auc_score(y_train, grid.predict_proba(X_train)[:, 1]),\n",
    "                roc_auc_score(y_valid, grid.predict_proba(X_valid)[:, 1]),\n",
    "                roc_auc_score(y_test, grid.predict_proba(X_test)[:, 1])],\n",
    "    4)) \n",
    "expLog\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
